{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113879a7",
   "metadata": {},
   "source": [
    "# [GD-12]ChatBot(Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff2d238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# í•œêµ­ì–´í°íŠ¸ì§€ì›\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager.findfont(font)\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fd8347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "\n",
    "import seaborn # Attention ì‹œê°í™”ë¥¼ ìœ„í•´ í•„ìš”!\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bef2b4",
   "metadata": {},
   "source": [
    "##  1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea89d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = os.getenv('HOME')+'/aiffel/transformer_chatbot'\n",
    "data_path = os.getenv('HOME')+'/aiffel/transformer_chatbot/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f13cf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12ì‹œ ë•¡!</td>\n",
       "      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n",
       "      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL ì‹¬í•˜ë„¤</td>\n",
       "      <td>ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12ì‹œ ë•¡!   í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.      0\n",
       "1      1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´    ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.      0\n",
       "2     3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "3  3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "4          PPL ì‹¬í•˜ë„¤   ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_path+'/ChatbotData .csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a237b224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a9bf8",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ì •ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "665be8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q        0\n",
       "A        0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b52df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label ì‚­ì œ\n",
    "data.drop(['label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c728c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12ì‹œ ë•¡!</td>\n",
       "      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n",
       "      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL ì‹¬í•˜ë„¤</td>\n",
       "      <td>ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A\n",
       "0           12ì‹œ ë•¡!   í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.\n",
       "1      1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´    ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.\n",
       "2     3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .\n",
       "3  3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .\n",
       "4          PPL ì‹¬í•˜ë„¤   ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ ."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db321902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : 12ì‹œ ë•¡!\n",
      "A : í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.\n",
      "\n",
      "Q : 1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´\n",
      "A : ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "Q : 3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤\n",
      "A : ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .\n",
      "\n",
      "Q : 3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤\n",
      "A : ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .\n",
      "\n",
      "Q : PPL ì‹¬í•˜ë„¤\n",
      "A : ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ìƒ˜í”Œ í™•ì¸\n",
    "for i in range(5):\n",
    "    print('Q :', data['Q'][i])\n",
    "    print('A :', data['A'][i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d74c8d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ì •ì œ\n",
    "# í† í°í™”\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    # ì˜ë¬¸ ì†Œë¬¸ì ë³€í™˜\n",
    "    sentence = sentence.lower().strip()\n",
    "    # ì˜ë¬¸ìì™€ í•œê¸€, ìˆ«ì, ê·¸ë¦¬ê³  ì£¼ìš” íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œì™¸í•˜ê³¤ ëª¨ë‘ ì œê±°\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!ê°€-í£ã„±-ã…ã…-ã…£0-9]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    corpus = mecab.morphs(sentence)\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5763bfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions data size : 11823\n",
      "answer data size : 11823\n",
      "\n",
      "ì „ì²˜ë¦¬ í›„ ì§ˆë¬¸ ìƒ˜í”Œ : ['12', 'ì‹œ', 'ë•¡', '!']\n",
      "ì „ì²˜ë¦¬ í›„ ë‹µë³€ ìƒ˜í”Œ : ['í•˜ë£¨', 'ê°€', 'ë˜', 'ê°€', 'ë„¤ìš”', '.']\n"
     ]
    }
   ],
   "source": [
    "# questions ì™€ answers ì €ì¥\n",
    "questions = [preprocess_sentence(q) for q in data['Q']]\n",
    "answers = [preprocess_sentence(a) for a in data['A']]\n",
    "\n",
    "print('questions data size :', len(questions))\n",
    "print('answer data size :', len(answers))\n",
    "print()\n",
    "print('ì „ì²˜ë¦¬ í›„ ì§ˆë¬¸ ìƒ˜í”Œ : {}'.format(questions[0]))\n",
    "print('ì „ì²˜ë¦¬ í›„ ë‹µë³€ ìƒ˜í”Œ : {}'.format(answers[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddafb6b4",
   "metadata": {},
   "source": [
    "## 3. ë°ì´í„° í† í°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf897562",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus = []\n",
    "ans_corpus = []\n",
    "\n",
    "token_limit = 40\n",
    "\n",
    "def build_corpus():\n",
    "    for i in range(len(questions)):\n",
    "        if len(questions[i]) <= token_limit and len(answers[i]) <= 40:\n",
    "            que_corpus.append(questions[i])\n",
    "            ans_corpus.append(answers[i])\n",
    "            \n",
    "    return\n",
    "\n",
    "build_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "864e5d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12', 'ì‹œ', 'ë•¡', '!'],\n",
       " ['1', 'ì§€ë§', 'í•™êµ', 'ë–¨ì–´ì¡Œ', 'ì–´'],\n",
       " ['3', 'ë°•', '4', 'ì¼', 'ë†€', 'ëŸ¬', 'ê°€', 'ê³ ', 'ì‹¶', 'ë‹¤'],\n",
       " ['3', 'ë°•', '4', 'ì¼', 'ì •ë„', 'ë†€', 'ëŸ¬', 'ê°€', 'ê³ ', 'ì‹¶', 'ë‹¤'],\n",
       " ['ppl', 'ì‹¬í•˜', 'ë„¤'],\n",
       " ['sd', 'ì¹´ë“œ', 'ë§ê°€ì¡Œ', 'ì–´'],\n",
       " ['sd', 'ì¹´ë“œ', 'ì•ˆ', 'ë¼'],\n",
       " ['sns', 'ë§', 'íŒ”', 'ì™œ', 'ì•ˆ', 'í•˜', 'ì§€', 'ã… ã… '],\n",
       " ['sns', 'ì‹œê°„', 'ë‚­ë¹„', 'ì¸', 'ê±°', 'ì•„', 'ëŠ”ë°', 'ë§¤ì¼', 'í•˜', 'ëŠ”', 'ì¤‘'],\n",
       " ['sns', 'ì‹œê°„', 'ë‚­ë¹„', 'ì¸ë°', 'ìê¾¸', 'ë³´', 'ê²Œ', 'ë¨']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a4ebee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['í•˜ë£¨', 'ê°€', 'ë˜', 'ê°€', 'ë„¤ìš”', '.'],\n",
       " ['ìœ„ë¡œ', 'í•´', 'ë“œë¦½ë‹ˆë‹¤', '.'],\n",
       " ['ì—¬í–‰', 'ì€', 'ì–¸ì œë‚˜', 'ì¢‹', 'ì£ ', '.'],\n",
       " ['ì—¬í–‰', 'ì€', 'ì–¸ì œë‚˜', 'ì¢‹', 'ì£ ', '.'],\n",
       " ['ëˆˆì‚´', 'ì´', 'ì°Œí‘¸ë ¤', 'ì§€', 'ì£ ', '.'],\n",
       " ['ë‹¤ì‹œ', 'ìƒˆë¡œ', 'ì‚¬', 'ëŠ”', 'ê²Œ', 'ë§ˆìŒ', 'í¸í•´ìš”', '.'],\n",
       " ['ë‹¤ì‹œ', 'ìƒˆë¡œ', 'ì‚¬', 'ëŠ”', 'ê²Œ', 'ë§ˆìŒ', 'í¸í•´ìš”', '.'],\n",
       " ['ì˜', 'ëª¨ë¥´', 'ê³ ', 'ìˆ', 'ì„', 'ìˆ˜', 'ë„', 'ìˆ', 'ì–´ìš”', '.'],\n",
       " ['ì‹œê°„', 'ì„', 'ì •í•˜', 'ê³ ', 'í•´', 'ë³´', 'ì„¸ìš”', '.'],\n",
       " ['ì‹œê°„', 'ì„', 'ì •í•˜', 'ê³ ', 'í•´', 'ë³´', 'ì„¸ìš”', '.']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef7bb7",
   "metadata": {},
   "source": [
    "## 4. Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8b1d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical Subsitution ì ìš©\n",
    "w2v_path = data_path + '/ko.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d60390cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==3.8.3 in /opt/conda/lib/python3.9/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.7.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (5.2.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.21.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af38da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "word2vec = Word2Vec.load(w2v_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c81efb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "def lexical_sub(sentence, word2vec):\n",
    "    res = \"\"\n",
    "    # toks = sentence.split()\n",
    "    toks = sentence\n",
    "\n",
    "    try:\n",
    "        _from = random.choice(toks)\n",
    "        _to = word2vec.most_similar(_from)[0][0]\n",
    "\n",
    "    except:   # ë‹¨ì–´ì¥ì— ì—†ëŠ” ë‹¨ì–´\n",
    "        return None\n",
    "\n",
    "    for tok in toks:\n",
    "        if tok is _from: res += _to + \" \"\n",
    "        else: res += tok + \" \"\n",
    "\n",
    "    return res\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c64b880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì›ë³¸: ['12', 'ì‹œ', 'ë•¡', '!']\n",
      "ê²°ê³¼: 12 ì‹œê°€ ë•¡ ! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_192/2717891471.py:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  _to = word2vec.most_similar(_from)[0][0]\n"
     ]
    }
   ],
   "source": [
    "print(\"ì›ë³¸:\", que_corpus[0])\n",
    "print(\"ê²°ê³¼:\", lexical_sub(que_corpus[0], word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50f9d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_192/3267747900.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx in tqdm_notebook(range(len(que_corpus))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aad1661b2c342a38562b096cf1541c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_192/2717891471.py:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  _to = word2vec.most_similar(_from)[0][0]\n",
      "/tmp/ipykernel_192/3267747900.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for idx in tqdm_notebook(range(len(ans_corpus))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ffd20584d84230a4e55a1086af9682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20555\n",
      "20555 \n",
      "\n",
      "['12', 'ì‹œ', 'ë•¡', 'ìºì¹˜']\n",
      "['í•˜ë£¨', 'ê°€', 'ë˜', 'ê°€', 'ë„¤ìš”', '.'] \n",
      "\n",
      "['ê³ ì–‘ì´', 'í‚¤ìš°', 'ê³ ', 'ì‹¶', 'ì–´']\n",
      "['ì±…ì„', 'ì§ˆ', 'ìˆ˜', 'ìˆ', 'ì„', 'ë•Œ', 'í‚¤ì›Œ', 'ë³´', 'ì„¸ìš”', '.'] \n",
      "\n",
      "32378\n",
      "32378 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "new_que_corpus = []\n",
    "new_ans_corpus = []\n",
    "\n",
    "# Augmentationëœ que_corpus ì™€ ì›ë³¸ ans_corpus ê°€ ë³‘ë ¬ì„ ì´ë£¨ë„ë¡\n",
    "for idx in tqdm_notebook(range(len(que_corpus))):\n",
    "    que_augmented = lexical_sub(que_corpus[idx], word2vec)\n",
    "    ans = ans_corpus[idx]\n",
    "    \n",
    "    if que_augmented is not None:\n",
    "        new_que_corpus.append(que_augmented.split())\n",
    "        new_ans_corpus.append(ans)\n",
    "        # print(\"[que]\", que_corpus[idx], \"->\", que_augmented, \"/\", ans)\n",
    "    else:\n",
    "        # print(\"[que] Augmentation is None:\", que_corpus[idx], \"/\", ans_corpus[idx])\n",
    "        continue\n",
    "    \n",
    "for idx in tqdm_notebook(range(len(ans_corpus))):\n",
    "    que = que_corpus[idx]\n",
    "    ans_augmented = lexical_sub(ans_corpus[idx], word2vec)\n",
    "    \n",
    "    if ans_augmented is not None:\n",
    "        new_que_corpus.append(que)\n",
    "        new_ans_corpus.append(ans_augmented.split())\n",
    "        # print(\"[ans]\", que, \"/\", ans_corpus[idx], \"->\", ans_augmented)\n",
    "    else:\n",
    "        # print(\"[ans] Augmentation is None:\", que_corpus[idx], \"/\", ans_corpus[idx])\n",
    "        continue\n",
    "\n",
    "print(len(new_que_corpus))\n",
    "print(len(new_ans_corpus), '\\n')\n",
    "\n",
    "print(new_que_corpus[0])\n",
    "print(new_ans_corpus[0], '\\n')\n",
    "\n",
    "print(new_que_corpus[56])\n",
    "print(new_ans_corpus[56], '\\n')\n",
    "\n",
    "que_corpus = que_corpus + new_que_corpus\n",
    "ans_corpus = ans_corpus + new_ans_corpus\n",
    "\n",
    "print(len(que_corpus))\n",
    "print(len(ans_corpus), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd82550",
   "metadata": {},
   "source": [
    "## 5. ë°ì´í„° ë²¡í„°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ae8d90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', '12', 'ì‹œ', 'ë•¡', '!', '<end>']\n"
     ]
    }
   ],
   "source": [
    "# <start> í† í°ê³¼ <end> í† í°ì´ ì¶”ê°€\n",
    "sample_data = [\"12\", \"ì‹œ\", \"ë•¡\", \"!\"]\n",
    "\n",
    "print([\"<start>\"] + sample_data + [\"<end>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88a71a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start>', 'ê³µë¶€', 'í•˜', 'ë©´', 'ë”', 'ë§', 'ì€', 'ì„ íƒ', 'ì„', 'í• ', 'ìˆ˜', 'ìˆ', 'ì£ ', '.', '<end>']\n",
      "['<start>', 'ë‹¤', 'ë“¤', 'ë°”ë¹ ì„œ', 'ì´ì•¼ê¸°', 'í• ', 'ì‹œê°„', 'ì´', 'ë¶€ì¡±', 'í–ˆ', 'ë‚˜', 'ë´ìš”', '.', '<end>']\n"
     ]
    }
   ],
   "source": [
    "tgt_corpus = []\n",
    "\n",
    "for corpus in ans_corpus:\n",
    "    tgt_corpus.append([\"<start>\"] + corpus + [\"<end>\"])\n",
    "    \n",
    "print(tgt_corpus[221])\n",
    "print(tgt_corpus[31])\n",
    "\n",
    "ans_corpus = tgt_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a482ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "voc_data = que_corpus + ans_corpus\n",
    "\n",
    "words = np.concatenate(voc_data).tolist()\n",
    "counter = Counter(words)\n",
    "counter = counter.most_common(30000-2)\n",
    "vocab = ['<pad>', '<unk>'] + [key for key, _ in counter]\n",
    "word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41759399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32378\n",
      "32378\n",
      "[2751, 185, 4148, 96]\n",
      "[3, 273, 10, 164, 10, 39, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index[word] if word in word_to_index else word_to_index['<unk>'] for word in sentence]\n",
    "\n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<unk>' for index in encoded_sentence[1:])  #[1:]ë¥¼ í†µí•´ <BOS>ë¥¼ ì œì™¸\n",
    "\n",
    "def vectorize(corpus, word_to_index):\n",
    "    data = []\n",
    "    for sen in corpus:\n",
    "        sen = get_encoded_sentence(sen, word_to_index)\n",
    "        data.append(sen)\n",
    "    return data\n",
    "\n",
    "que_train = vectorize(que_corpus, word_to_index)\n",
    "ans_train = vectorize(ans_corpus, word_to_index)\n",
    "\n",
    "print(len(que_train))\n",
    "print(len(ans_train))\n",
    "print(que_train[0])\n",
    "print(ans_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d938453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32054 324 32054 324\n"
     ]
    }
   ],
   "source": [
    "enc_tensor = tf.keras.preprocessing.sequence.pad_sequences(que_train, padding='post')\n",
    "dec_tensor = tf.keras.preprocessing.sequence.pad_sequences(ans_train, padding='post')\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = \\\n",
    "train_test_split(enc_tensor, dec_tensor, test_size=0.01) # test setì€ 1%ë§Œ\n",
    "\n",
    "print(len(enc_train), len(enc_val), len(dec_train), len(dec_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e2a027c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  23,   30,  216,    7,   29,    8,   98,    7,   94, 1779,   63,\n",
       "         15,   87,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "906f272d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,  200,   36,  127,    7,   94, 2293,    5,   37,    2,    4,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c2a34",
   "metadata": {},
   "source": [
    "## 6. í›ˆë ¨í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb839882",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03be1a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "# Positional Encoding êµ¬í˜„\n",
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "    \n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "    \n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    \n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    \n",
    "    return sinusoid_table\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "748b6139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "# Multi-head Attention\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "\n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "\n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, attention_weights\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92ff4d",
   "metadata": {},
   "source": [
    "### Position-wise Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00ee2cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "# Position-wise Feed Forward Network\n",
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcc02a6",
   "metadata": {},
   "source": [
    "### Encoder/Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e10afa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "# Encoder Layer\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, enc_attn\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20a0542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "# Decoder Layer\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.dec_self_attn(out, enc_out, enc_out, causality_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e84964",
   "metadata": {},
   "source": [
    "### Encoder/Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bc6913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "\n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "\n",
    "        return out, enc_attns\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd818ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "\n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns\n",
    "    \n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043b7c9",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb03ef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "\n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "\n",
    "        logits = self.fc(dec_out)\n",
    "\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5e7a4",
   "metadata": {},
   "source": [
    "### Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f78e10ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541497a5",
   "metadata": {},
   "source": [
    "### Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1d2e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "learning_rate = LearningRateScheduler(512)\n",
    "oprimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144a346",
   "metadata": {},
   "source": [
    "### í›ˆë ¨ ë° í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5232eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 20000\n",
    "\n",
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=VOCAB_SIZE,\n",
    "    tgt_vocab_size=VOCAB_SIZE,\n",
    "    pos_len=200,\n",
    "    dropout=0.3,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n",
    "\n",
    "d_model = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd1d82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a323afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6a89507",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoderì˜ input\n",
    "    gold = tgt[:, 1:]     # Decoderì˜ outputê³¼ ë¹„êµí•˜ê¸° ìœ„í•´ right shiftë¥¼ í†µí•´ ìƒì„±í•œ ìµœì¢… íƒ€ê²Ÿ\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d110dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_192/1661432966.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  t = tqdm_notebook(idx_list)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59622849907e49649037451207eded74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c51baa37964298b715284f6452deeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b99e4caaecd4510bcf96bcee7774673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54587ba54a3349208e0ada341285a0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d2ed1b53ea4093bb1846b4f94f9ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c611f154e4d0466b91b114947d9fd4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dd47420498449191404af677764cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece020a0b4ba440da1876a38e2052d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ea8430c978467c9eb1e7ecef351e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81002158a05643bc83104b31b29575ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c9e16b43ac48bdb86aa011b62667a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d368a6c91844e5baae7fd6ffa9b8722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31cc5738e9740da92f4b71e38cf69b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b196d6e15b8f4599b890f5174ba4fca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2159c2aecb674930af00b654a28bd1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7565058956c43f09cf098a3da283ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933f8a6cdbcd4e8580acaa41e38dfcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c357a73a771447b2b25781e3ac77392b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64fae6ab95c4408b86d38b1ddaf109a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89a1d681f8a4abf8eec8c0ed51f2ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "\n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm_notebook(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6954096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "pieces = None\n",
    "sentence = None\n",
    "\n",
    "def evaluate(model):\n",
    "    \n",
    "#    sentence = preprocess_sentence(sentence)\n",
    "#    pieces = mecab.morphs(sentence)\n",
    "    \n",
    "    tokens = []\n",
    "    for sen in pieces:\n",
    "        sen= get_encoded_sentence(sen, word_to_index)\n",
    "        tokens.append(sen)\n",
    "    \n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences(tokens,\n",
    "                                                        value=word_to_index[\"<pad>\"],\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=20)\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([word_to_index[\"<start>\"]], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if word_to_index[\"<end>\"] == predicted_id:\n",
    "            result = get_decoded_sentence(ids, index_to_word)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = get_decoded_sentence(ids, index_to_word)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "def translate(model):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(model)\n",
    "\n",
    "    return result\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3983a8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´.\n",
      "answered: ë°› ì•„ ë³´ ë©´ ì‚¬ë‘ ì´ ë¼ê³  ìƒê° í•˜ ì§€ ë§ ì•„ìš” .\n",
      "source: ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤.\n",
      "answered: ì¢‹ ì€ ì‚¬ëŒ ë§Œë‚  ìˆ˜ ìˆ ì„ ê±° ì˜ˆìš” .\n",
      "source: ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´.\n",
      "answered: ë„¤ìš” .\n",
      "source: ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼.\n",
      "answered: ì°¾ì•„ê°€ ëŠ” ê²ƒ ì´ ë˜ ê²  ì£  .\n"
     ]
    }
   ],
   "source": [
    "sample_sentences = [\n",
    "    \"ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´.\",\n",
    "    \"ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤.\",\n",
    "    \"ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´.\",\n",
    "    \"ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼.\",\n",
    "]\n",
    "\n",
    "for sen in sample_sentences:\n",
    "    sentence = sen\n",
    "    pieces = mecab.morphs(sentence)\n",
    "    print(\"source:\", sen)\n",
    "    print(\"answered:\", translate(transformer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e2d478",
   "metadata": {},
   "source": [
    "# íšŒê³ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f8a0a",
   "metadata": {},
   "source": [
    "- ì˜ˆë¬¸\n",
    "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´.\n",
    "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤.\n",
    "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´.\n",
    "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼.\n",
    "\n",
    "---\n",
    "\n",
    "- ì œì¶œ\n",
    "\n",
    "Translations   \n",
    "1. ë°› ì•„ ë³´ ë©´ ì‚¬ë‘ ì´ ë¼ê³  ìƒê° í•˜ ì§€ ë§ ì•„ìš” .\n",
    "2. ì¢‹ ì€ ì‚¬ëŒ ë§Œë‚  ìˆ˜ ìˆ ì„ ê±° ì˜ˆìš” .\n",
    "3. ë„¤ìš” .\n",
    "4. ì°¾ì•„ê°€ ëŠ” ê²ƒ ì´ ë˜ ê²  ì£  .\n",
    "\n",
    "Hyperparameters\n",
    "> n_layers: 2  \n",
    "> d_model: 512  \n",
    "> n_heads: 8  \n",
    "> d_ff: 2048  \n",
    "> dropout: 0.3  \n",
    "\n",
    "Training Parameters\n",
    "> Batch Size: 64  \n",
    "> Epoch At: 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3d75da",
   "metadata": {},
   "source": [
    "- í•œ ê°€ì§€ ì§ˆë¬¸ì„ ì œì™¸í•˜ê³  ì±—ë´‡ì´ ë¬¸ì¥ì„ êµ¬ì‚¬í•œë‹¤.\n",
    "- í•˜ì§€ë§Œ ëŒ€í™”í•˜ê³  ìˆë‹¤ê³  ë³¼ ìˆ˜ ì—†ë‹¤.\n",
    "- ì¡°ê¸ˆ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ë‹µë„ ìˆë‹¤.\n",
    "- ì•„ì§ Transformer ëª¨ë¸ êµ¬ì¡°ë¥¼ ì •í™•íˆ ì´í•´í•  ìˆ˜ ì—†ì–´ì„œ ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•œ ë°©ë²•ì´ ë– ì˜¤ë¥´ì§€ ì•ŠëŠ”ë‹¤.\n",
    "- ë” ë§ì€ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ë©´ ì •í™•í•œ ëŒ€ë‹µì„ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒì´ë¼ ìƒê°í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3a652",
   "metadata": {},
   "source": [
    "# ì°¸ê³ ì‚¬ì´íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8da903",
   "metadata": {},
   "source": [
    "[ì°¸ê³ ê¹ƒí—ˆë¸Œì£¼ì†Œ](https://github.com/nevermet/AIFFEL/blob/master/G12_NiceChatBot.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
