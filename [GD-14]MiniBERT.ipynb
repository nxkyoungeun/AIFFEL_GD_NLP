{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6030a4",
   "metadata": {},
   "source": [
    "# [GD-14]MiniBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6beb52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "1.3.3\n",
      "2.0.9\n",
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import re\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(json.__version__)\n",
    "print(re.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7648b73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ»\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import shutil\n",
    "import zipfile\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import sentencepiece as spm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "print(\"ğŸ»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7326df7a",
   "metadata": {},
   "source": [
    "## 1. Tokenizer ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c35542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì™„ë£Œ=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/bert_pretrain/data/kowiki.txt --model_prefix=ko_8000 --vocab_size=8007 --model_type=bpe --max_sentence_length=999999 --pad_id=0 --pad_piece=[PAD] --unk_id=1 --unk_piece=[UNK] --bos_id=2 --bos_piece=[BOS] --eos_id=3 --eos_piece=[EOS] --user_defined_symbols=[SEP],[CLS],[MASK]\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/bert_pretrain/data/kowiki.txt\n",
      "  input_format: \n",
      "  model_prefix: ko_8000\n",
      "  model_type: BPE\n",
      "  vocab_size: 8007\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 999999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: [SEP]\n",
      "  user_defined_symbols: [CLS]\n",
      "  user_defined_symbols: [MASK]\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: [UNK]\n",
      "  bos_piece: [BOS]\n",
      "  eos_piece: [EOS]\n",
      "  pad_piece: [PAD]\n",
      "  unk_surface:  â‡ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/bert_pretrain/data/kowiki.txt\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(140) LOG(INFO) Loaded 2000000 lines\n",
      "trainer_interface.cc(117) LOG(WARNING) Too many sentences are loaded! (2451287), which may slow down training.\n",
      "trainer_interface.cc(119) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(122) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2451287 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [PAD]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [UNK]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [BOS]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [EOS]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [SEP]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [CLS]\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: [MASK]\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=287452241\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.95% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=4411\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.9995\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2450254 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2450254\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 7050692\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1781571 min_freq=424\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=576838 size=20 all=581927 active=38577 piece=â–ì•„\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=390836 size=40 all=591445 active=48095 piece=â–ìœ \n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=297873 size=60 all=601378 active=58028 piece=ì—ëŠ”\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=244712 size=80 all=609974 active=66624 piece=â–ì„±\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=194372 size=100 all=616449 active=73099 piece=ê¹Œì§€\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=193674 min_freq=462\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=176838 size=120 all=625299 active=38770 piece=â–ìš°\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=154294 size=140 all=632274 active=45745 piece=â–íŒŒ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=140625 size=160 all=639734 active=53205 piece=00\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=125983 size=180 all=645481 active=58952 piece=â–ìš”\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=114855 size=200 all=649839 active=63310 piece=ë¦¬ì•„\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=114086 min_freq=457\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=106760 size=220 all=657338 active=39316 piece=â–ê°™ì€\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=100770 size=240 all=662564 active=44542 piece=â–ì™•\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=96037 size=260 all=670536 active=52514 piece=â–ëª©\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=88392 size=280 all=675441 active=57419 piece=â–f\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=81678 size=300 all=681701 active=63679 piece=â–ì„ ìˆ˜\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=80870 min_freq=446\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=77144 size=320 all=686930 active=39163 piece=â–ë•Œë¬¸ì—\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=73218 size=340 all=691000 active=43233 piece=â–ì¡°ì„ \n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=68829 size=360 all=695717 active=47950 piece=â–ì²œ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=64009 size=380 all=700839 active=53072 piece=â–196\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=60953 size=400 all=706675 active=58908 piece=â–ëŒ\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=60762 min_freq=435\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=58542 size=420 all=711350 active=39712 piece=â–ë‹¤ì‹œ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=55779 size=440 all=715377 active=43739 piece=â–K\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=52528 size=460 all=721839 active=50201 piece=â–ëª¨ë‘\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=49784 size=480 all=727356 active=55718 piece=â–íˆ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=47637 size=500 all=733038 active=61400 piece=â–ì „ìŸ\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=47558 min_freq=423\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=45919 size=520 all=738287 active=41703 piece=â–ìˆì–´\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=44025 size=540 all=743886 active=47302 piece=â–ì¤‘ì‹¬\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=42378 size=560 all=748357 active=51773 piece=â–N\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=40922 size=580 all=752114 active=55530 piece=â–H\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=39922 size=600 all=755142 active=58558 piece=le\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=39768 min_freq=414\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38924 size=620 all=761204 active=43650 piece=â–ê²€\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=37771 size=640 all=767376 active=49822 piece=ë€ë“œ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=36292 size=660 all=772837 active=55283 piece=ì •ì„\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=35134 size=680 all=778715 active=61161 piece=â–ì„¤ë¦½\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34016 size=700 all=783719 active=66165 piece=â–ì—­ì‚¬\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=34003 min_freq=400\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=33144 size=720 all=787243 active=42507 piece=â–ë§Œë“¤ì–´\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=32383 size=740 all=791538 active=46802 piece=â–ì‹œê°„\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=31645 size=760 all=795131 active=50395 piece=â–ì¸¡\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30941 size=780 all=798845 active=54109 piece=ê³¼ì˜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30041 size=800 all=803050 active=58314 piece=ë„ëŠ”\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=30023 min_freq=392\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29448 size=820 all=808546 active=45099 piece=â–ë‚œ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28836 size=840 all=813895 active=50448 piece=â–21\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=28270 size=860 all=818654 active=55207 piece=â–ì°¾\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27299 size=880 all=824625 active=61177 piece=ë˜ì§€\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26862 size=900 all=828285 active=64837 piece=í•˜ì\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=26833 min_freq=381\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=26060 size=920 all=832595 active=45199 piece=ë¶€ì—\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25504 size=940 all=838824 active=51428 piece=ìˆ˜ì˜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24726 size=960 all=843322 active=55926 piece=â–ë‚¨ì•„\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24083 size=980 all=848416 active=61020 piece=â–ì•ŠëŠ”ë‹¤\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23647 size=1000 all=853601 active=66205 piece=ì¸ë¯¼\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=23602 min_freq=368\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23176 size=1020 all=859529 active=48367 piece=â–ë§ˆì§€\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22849 size=1040 all=863129 active=51967 piece=â–ì‹œë¦¬ì¦ˆ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22293 size=1060 all=868678 active=57516 piece=ì œë¡œ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21851 size=1080 all=873075 active=61913 piece=ì‹œì˜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21377 size=1100 all=878277 active=67115 piece=í•´ì•¼\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=21369 min_freq=355\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21043 size=1120 all=882003 active=47093 piece=â–ë…¹\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20625 size=1140 all=886266 active=51356 piece=â–ì¸êµ¬ëŠ”\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20185 size=1160 all=889382 active=54472 piece=ac\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19762 size=1180 all=894738 active=59828 piece=ì¸ì€\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19447 size=1200 all=899565 active=64655 piece=50\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=19432 min_freq=347\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19118 size=1220 all=903215 active=48471 piece=ê´‘ì—­\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18777 size=1240 all=908007 active=53263 piece=ìˆ˜ëŠ”\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18396 size=1260 all=913268 active=58524 piece=ì¸ë¯¼ê³µ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18040 size=1280 all=917389 active=62645 piece=â–ê¸´\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17659 size=1300 all=922177 active=67433 piece=â–ì „í†µ\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq"
     ]
    }
   ],
   "source": [
    "# entencePiece ëª¨ë¸ì„ ì´ìš©í•´ BERTì˜ MLM í•™ìŠµìš© ë°ì´í„°ë¥¼ ë§Œë“¤ê¸°\n",
    "import sentencepiece as spm\n",
    "import os\n",
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "prefix = 'ko_8000'\n",
    "vocab_size = 8000\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus_file} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" + # ë¬¸ì¥ ìµœëŒ€ ê¸¸ì´\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # ì‚¬ìš©ì ì •ì˜ í† í°\n",
    "\n",
    "print(\"ì™„ë£Œ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770e6990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=17629 min_freq=335\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17404 size=1320 all=926354 active=50086 piece=â–ë§\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17093 size=1340 all=929494 active=53226 piece=ë‹¨ì˜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16931 size=1360 all=934269 active=58001 piece=â–ì¸ê°„\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16719 size=1380 all=939872 active=63604 piece=â–ë°”ë¡œ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16586 size=1400 all=943447 active=67179 piece=â–íƒ‘\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16584 min_freq=327\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16331 size=1420 all=947545 active=51069 piece=â–íƒœì–‘\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16086 size=1440 all=952041 active=55565 piece=â–ê²½ê¸°ì—ì„œ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15873 size=1460 all=957568 active=61092 piece=â–ë™ì¼\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15577 size=1480 all=962681 active=66205 piece=ë“œë¥¼\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15352 size=1500 all=966310 active=69834 piece=â–ë®¤\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=15328 min_freq=318\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15103 size=1520 all=968851 active=50741 piece=id\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14971 size=1540 all=972545 active=54435 piece=â–ì˜¥\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14723 size=1560 all=977306 active=59196 piece=ë¹„ì „\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14495 size=1580 all=982182 active=64072 piece=â–ëŒ€ë¶€ë¶„ì˜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14292 size=1600 all=985970 active=67860 piece=â–ê°‘\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=14280 min_freq=311\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14118 size=1620 all=990010 active=53173 piece=íšŒëŠ”\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13982 size=1640 all=993514 active=56677 piece=â–ì‚¬ê³ \n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13729 size=1660 all=997224 active=60387 piece=cm\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13567 size=1680 all=1001600 active=64762 piece=â–ë›°ì–´\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13433 size=1700 all=1006574 active=69736 piece=â–ë”ìš±\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=13420 min_freq=303\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13135 size=1720 all=1011076 active=54820 piece=ì§€ì—­\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12940 size=1740 all=1015431 active=59175 piece=â–ì„ ì–¸\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12821 size=1760 all=1020339 active=64083 piece=â–ì–´ë ¤\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12640 size=1780 all=1023221 active=66965 piece=â–ì¹­\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12505 size=1800 all=1028177 active=71921 piece=â–ì˜›\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=12503 min_freq=295\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12409 size=1820 all=1033793 active=56931 piece=ce\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12253 size=1840 all=1037183 active=60321 piece=â–ê·¸ë“¤ì˜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12091 size=1860 all=1041900 active=65038 piece=â–ë‹¨ì²´\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11934 size=1880 all=1045379 active=68517 piece=â–ì˜ˆìˆ \n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11799 size=1900 all=1048007 active=71145 piece=ë¼ì˜\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11799 min_freq=288\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11693 size=1920 all=1050313 active=54358 piece=â–ë¶ˆêµ¬í•˜ê³ \n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11594 size=1940 all=1053703 active=57748 piece=â–ë¶„ë¦¬\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11496 size=1960 all=1057998 active=62043 piece=â–ì‚¬ì´ì˜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11381 size=1980 all=1063418 active=67463 piece=ë‹¨ì´\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11289 size=2000 all=1067885 active=71930 piece=im\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=11277 min_freq=281\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11133 size=2020 all=1071888 active=57167 piece=â–ë“±ê³¼\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10994 size=2040 all=1077153 active=62432 piece=ë²•ì„\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10895 size=2060 all=1081334 active=66613 piece=â–ê´´\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10776 size=2080 all=1084885 active=70164 piece=ëŸ¬ìŠ¤\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10692 size=2100 all=1089330 active=74609 piece=â–ê¹¨\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10688 min_freq=274\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10597 size=2120 all=1091576 active=56585 piece=ë¦­í„°\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10496 size=2140 all=1095180 active=60189 piece=â–í™•ì¥\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10396 size=2160 all=1100510 active=65519 piece=ì—ˆë˜\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10271 size=2180 all=1104334 active=69343 piece=â–ë‚¨ë¶€\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10143 size=2200 all=1108628 active=73637 piece=â–ìŠ¤í¬ì¸ \n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=10136 min_freq=268\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10057 size=2220 all=1111848 active=58430 piece=â–ì´ì™¸\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9957 size=2240 all=1115235 active=61817 piece=â–ì„œì‹\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9848 size=2260 all=1120216 active=66798 piece=â–ì‘ìš©\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9732 size=2280 all=1124443 active=71025 piece=â–ì´ì•¼ê¸°\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9655 size=2300 all=1129106 active=75688 piece=â–ì„±ë¦½\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9653 min_freq=261\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9570 size=2320 all=1132064 active=59284 piece=â–ë–¨ì–´ì§„\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9473 size=2340 all=1135883 active=63103 piece=ì‹œë¥¼\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9352 size=2360 all=1139681 active=66901 piece=â–íˆë¡œ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9289 size=2380 all=1142636 active=69856 piece=â–ë¶€ì •\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9219 size=2400 all=1147544 active=74764 piece=â–2020\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9217 min_freq=256\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9137 size=2420 all=1150230 active=60032 piece=â–ìƒì§•\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9028 size=2440 all=1153890 active=63692 piece=â–1950\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8965 size=2460 all=1157151 active=66953 piece=â–í‘œì‹œ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8889 size=2480 all=1162268 active=72070 piece=â–ì‚¬ìš©ëœë‹¤\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8828 size=2500 all=1165804 active=75606 piece=â–ì•„ì¼ëœë“œ\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8826 min_freq=251\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8738 size=2520 all=1169223 active=61615 piece=â–ë™ìƒ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8694 size=2540 all=1173546 active=65938 piece=ie\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8641 size=2560 all=1176802 active=69194 piece=â–ê²½ìƒë¶ë„\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8570 size=2580 all=1180886 active=73278 piece=â–ê³„ìŠ¹\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8489 size=2600 all=1184747 active=77139 piece=â–1985\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8487 min_freq=246\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8434 size=2620 all=1188193 active=62666 piec"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/data'\n",
    "model_dir = os.getenv('HOME')+'/aiffel/bert_pretrain/models'\n",
    "\n",
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_32000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "978735cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â–1', 'â–ì´', 'ìœ¼ë¡œ', 'ì—ì„œ', 'â–ìˆ', 'â–2', 'â–ê·¸', 'â–ëŒ€', 'â–ì‚¬', 'ì´ë‹¤', 'ì—ˆë‹¤', 'â–ì§€', 'â–ìˆ˜', 'â–19', 'â–ê°€', 'â–ì‹œ', 'â–20', 'â–ê¸°', 'â–ì „', 'â–ì•„', 'â–í•˜', 'â–ìˆë‹¤', 'â–ë‹¤', 'â–ì œ', 'í–ˆë‹¤', 'í•˜ì˜€', 'â–ì¼', 'â–í•œ', 'â–ì¤‘', 'â–ì •', 'â–ì£¼', 'í•˜ëŠ”', 'â–ê²ƒ', 'â–ì', 'â–ê³µ', 'â–ì¸', 'ë˜ì—ˆë‹¤', 'â–ê²½', 'â–ìœ„', 'â–ìœ ', 'â–ë³´', 'í•˜ê³ ', 'â–3', 'â–ë“±', 'â–ë¶€', 'í•˜ì˜€ë‹¤', 'â–ì¡°', 'í•˜ì—¬', 'â–ë¯¸', 'â–ë™']\n"
     ]
    }
   ],
   "source": [
    "# íŠ¹ìˆ˜ token 7ê°œë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ tokens ë“¤\n",
    "vocab_list = []\n",
    "for id in range(7, len(vocab)):\n",
    "    if not vocab.is_unknown(id):\n",
    "        vocab_list.append(vocab.id_to_piece(id))\n",
    "print(vocab_list[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e16bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´', 'â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„', 'â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—', '[SEP]', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬', 'â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”', 'â–ëª‡', 'â–ë‹¬', 'â–í¬', 'â–ì „ë¶€í„°', 'â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”', 'â–ì•„ë‚´', 'â–ìƒê°ì—', 'â–ê·¸', 'í† ë¡', 'â–ë¨¹ê³ ', 'â–ì‹¶ë‹¤', 'ë˜', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# [CLS], tokens a, [SEP], tokens b, [SEP] í˜•íƒœì˜ token ìƒì„±\n",
    "string_a = \"ì¶”ì ì¶”ì  ë¹„ê°€ ë‚´ë¦¬ëŠ” ë‚ ì´ì—ˆì–´ ê·¸ë‚ ì€ ì™ ì§€ ì†ë‹˜ì´ ë§ì•„ ì²« ë²ˆì— ì‚¼ì‹­ ì „ ë‘˜ì§¸ë²ˆ ì˜¤ì‹­ ì „ ì˜¤ëœë§Œì— ë°›ì•„ë³´ëŠ” ì‹­ ì „ì§œë¦¬ ë°±í†µí™” ì„œí‘¼ì—\"\n",
    "string_b = \"ì†ë°”ë‹¥ ìœ„ì—” ê¸°ì¨ì˜ ëˆˆë¬¼ì´ í˜ëŸ¬ ì»¬ì»¬í•œ ëª©ì— ëª¨ì£¼ í•œì”ì„ ì ì…” ëª‡ ë‹¬ í¬ ì „ë¶€í„° ì½œë¡ê±°ë¦¬ëŠ” ì•„ë‚´ ìƒê°ì— ê·¸í† ë¡ ë¨¹ê³  ì‹¶ë‹¤ë˜\"\n",
    "tokens_org = [\"[CLS]\"] + vocab.encode_as_pieces(string_a) + [\"[SEP]\"] + vocab.encode_as_pieces(string_b) + [\"[SEP]\"]\n",
    "print(tokens_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36580e3c",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ì „ì²˜ë¦¬ (1) MASK ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f67865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERTì˜ MLMì— í•„ìš”í•œ ë¹ˆì¹¸(mask)ì„ í•™ìŠµ ë°ì´í„° ì „ì²´ í† í°ì˜ 15% ì •ë„ë¡œ ë§Œë“¤ê¸°\n",
    "# ê·¸ ì¤‘ 80%ëŠ” [MASK] í† í°, 10%ëŠ” ëœë¤í•œ í† í°, ë‚˜ë¨¸ì§€ 10%ëŠ” ì›ë˜ì˜ í† í°ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "\n",
    "# ì „ì²´ tokenì˜ 15% mask\n",
    "mask_cnt = int((len(tokens_org) - 3) * 0.15)\n",
    "mask_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f5c88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] ['â–ì¶”ì ', 'ì¶”', 'ì ']\n",
      "[4] ['â–ë¹„ê°€']\n",
      "[5] ['â–ë‚´ë¦¬ëŠ”']\n",
      "[6, 7, 8] ['â–ë‚ ', 'ì´ì—ˆ', 'ì–´']\n",
      "[9, 10] ['â–ê·¸ë‚ ', 'ì€']\n",
      "[11, 12, 13] ['â–', 'ì™ ', 'ì§€']\n",
      "[14, 15] ['â–ì†', 'ë‹˜ì´']\n",
      "[16] ['â–ë§ì•„']\n",
      "[17] ['â–ì²«']\n",
      "[18] ['â–ë²ˆì—']\n",
      "[19, 20] ['â–ì‚¼', 'ì‹­']\n",
      "[21] ['â–ì „']\n",
      "[22, 23] ['â–ë‘˜ì§¸', 'ë²ˆ']\n",
      "[24, 25] ['â–ì˜¤', 'ì‹­']\n",
      "[26] ['â–ì „']\n",
      "[27, 28] ['â–ì˜¤ëœ', 'ë§Œì—']\n",
      "[29, 30] ['â–ë°›ì•„', 'ë³´ëŠ”']\n",
      "[31] ['â–ì‹­']\n",
      "[32, 33] ['â–ì „', 'ì§œë¦¬']\n",
      "[34, 35, 36] ['â–ë°±', 'í†µ', 'í™”']\n",
      "[37, 38, 39] ['â–ì„œ', 'í‘¼', 'ì—']\n",
      "[41] ['â–ì†ë°”ë‹¥']\n",
      "[42, 43] ['â–ìœ„', 'ì—”']\n",
      "[44, 45] ['â–ê¸°ì¨', 'ì˜']\n",
      "[46, 47] ['â–ëˆˆ', 'ë¬¼ì´']\n",
      "[48] ['â–í˜ëŸ¬']\n",
      "[49, 50, 51] ['â–ì»¬', 'ì»¬', 'í•œ']\n",
      "[52] ['â–ëª©ì—']\n",
      "[53, 54] ['â–ëª¨', 'ì£¼']\n",
      "[55, 56, 57] ['â–í•œ', 'ì”', 'ì„']\n",
      "[58, 59] ['â–ì ', 'ì…”']\n",
      "[60] ['â–ëª‡']\n",
      "[61] ['â–ë‹¬']\n",
      "[62] ['â–í¬']\n",
      "[63] ['â–ì „ë¶€í„°']\n",
      "[64, 65, 66] ['â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”']\n",
      "[67] ['â–ì•„ë‚´']\n",
      "[68] ['â–ìƒê°ì—']\n",
      "[69, 70] ['â–ê·¸', 'í† ë¡']\n",
      "[71] ['â–ë¨¹ê³ ']\n",
      "[72, 73] ['â–ì‹¶ë‹¤', 'ë˜']\n"
     ]
    }
   ],
   "source": [
    "# ë„ì–´ì“°ê¸° ë‹¨ìœ„ë¡œ mask í•˜ê¸° ìœ„í•´ì„œ index ë¶„í• \n",
    "cand_idx = []  # word ë‹¨ìœ„ì˜ index array\n",
    "for (i, token) in enumerate(tokens_org):\n",
    "    if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "        continue\n",
    "    if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
    "        cand_idx[-1].append(i)\n",
    "    else:\n",
    "        cand_idx.append([i])\n",
    "\n",
    "# ê²°ê³¼í™•ì¸\n",
    "for cand in cand_idx:\n",
    "    print(cand, [tokens_org[i] for i in cand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9525ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[18],\n",
       " [44, 45],\n",
       " [24, 25],\n",
       " [49, 50, 51],\n",
       " [31],\n",
       " [63],\n",
       " [41],\n",
       " [52],\n",
       " [22, 23],\n",
       " [71],\n",
       " [17],\n",
       " [19, 20],\n",
       " [60],\n",
       " [32, 33],\n",
       " [62],\n",
       " [46, 47],\n",
       " [29, 30],\n",
       " [72, 73],\n",
       " [6, 7, 8],\n",
       " [64, 65, 66],\n",
       " [67],\n",
       " [9, 10],\n",
       " [26],\n",
       " [55, 56, 57],\n",
       " [61],\n",
       " [34, 35, 36],\n",
       " [37, 38, 39],\n",
       " [21],\n",
       " [58, 59],\n",
       " [48],\n",
       " [69, 70],\n",
       " [4],\n",
       " [27, 28],\n",
       " [42, 43],\n",
       " [14, 15],\n",
       " [68],\n",
       " [5],\n",
       " [11, 12, 13],\n",
       " [1, 2, 3],\n",
       " [16],\n",
       " [53, 54]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random maskë¥¼ ìœ„í•´ì„œ ìˆœì„œë¥¼ ì„ìŒ\n",
    "random.shuffle(cand_idx)\n",
    "cand_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a85d2021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´', 'â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„', 'â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—', '[SEP]', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬', 'â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”', 'â–ëª‡', 'â–ë‹¬', 'â–í¬', 'â–ì „ë¶€í„°', 'â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”', 'â–ì•„ë‚´', 'â–ìƒê°ì—', 'â–ê·¸', 'í† ë¡', 'â–ë¨¹ê³ ', 'â–ì‹¶ë‹¤', 'ë˜', '[SEP]']\n",
      "['[CLS]', 'â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´', 'â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„', 'â–ì²«', '[MASK]', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', '[MASK]', '[MASK]', 'â–ì „', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ê·¸ë ˆì´íŠ¸', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—', '[SEP]', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', '[MASK]', '[MASK]', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬', '[MASK]', '[MASK]', '[MASK]', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”', 'â–ëª‡', 'â–ë‹¬', 'â–í¬', 'â–ì „ë¶€í„°', 'â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”', 'â–ì•„ë‚´', 'â–ìƒê°ì—', 'â–ê·¸', 'í† ë¡', 'â–ë¨¹ê³ ', 'â–ì‹¶ë‹¤', 'ë˜', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# tokensê°€ maskë˜ë¯€ë¡œ ì¬ ì‹¤í–‰ì„ ìœ„í•´ì„œ ë„£ì–´ì¤Œ (í…ŒìŠ¤íŠ¸ìš©)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "mask_lms = []  # mask ëœ ê°’\n",
    "for index_set in cand_idx:\n",
    "    if len(mask_lms) >= mask_cnt:  # í•¸ì¬ maskëœ ê°œìˆ˜ê°€ 15%ë¥¼ ë„˜ìœ¼ë©´ ì¤‘ì§€\n",
    "          break\n",
    "    if len(mask_lms) + len(index_set) > mask_cnt:  # ì´ë²ˆì— maskí•  ê°œìˆ˜ë¥¼ í¬í•¨í•´ 15%ë¥¼ ë„˜ìœ¼ë©´ skip\n",
    "          continue\n",
    "    dice = random.random()  # 0..1 ì‚¬ì´ì˜ í™•ë¥  ê°’\n",
    "\n",
    "    for index in index_set:\n",
    "        masked_token = None\n",
    "        if dice < 0.8:  # 80% replace with [MASK]\n",
    "            masked_token = \"[MASK]\"\n",
    "        elif dice < 0.9: # 10% keep original\n",
    "            masked_token = tokens[index]\n",
    "        else:  # 10% random word\n",
    "            masked_token = random.choice(vocab_list)\n",
    "        mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "        tokens[index] = masked_token\n",
    "\n",
    "print(tokens_org)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48bb03ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 24, 25, 31, 44, 45, 49, 50, 51, 63]\n",
      "['â–ë²ˆì—', 'â–ì˜¤', 'ì‹­', 'â–ì‹­', 'â–ê¸°ì¨', 'ì˜', 'â–ì»¬', 'ì»¬', 'í•œ', 'â–ì „ë¶€í„°']\n"
     ]
    }
   ],
   "source": [
    "# ìˆœì„œ ì •ë ¬ ë° mask_idx, mask_label ìƒì„±\n",
    "mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "print(mask_idx)\n",
    "print(mask_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f070c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    \"\"\"\n",
    "    ë§ˆìŠ¤í¬ ìƒì„±\n",
    "    :param tokens: tokens\n",
    "    :param mask_cnt: mask ê°œìˆ˜ (ì „ì²´ tokensì˜ 15%)\n",
    "    :param vocab_list: vocab list (random token ìš©)\n",
    "    :return tokens: maskëœ tokens\n",
    "    :return mask_idx: maskëœ tokenì˜ index\n",
    "    :return mask_label: maskëœ tokenì˜ ì›ë˜ ê°’\n",
    "    \"\"\"\n",
    "    # ë‹¨ì–´ ë‹¨ìœ„ë¡œ mask í•˜ê¸° ìœ„í•´ì„œ index ë¶„í• \n",
    "    cand_idx = []  # word ë‹¨ìœ„ì˜ index array\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
    "            cand_idx[-1].append(i)\n",
    "        else:\n",
    "            cand_idx.append([i])\n",
    "    # random maskë¥¼ ìœ„í•´ì„œ ìˆœì„œë¥¼ ì„ìŒ\n",
    "    random.shuffle(cand_idx)\n",
    "\n",
    "    mask_lms = []  # mask ëœ ê°’\n",
    "    for index_set in cand_idx:\n",
    "        if len(mask_lms) >= mask_cnt:  # í•¸ì¬ maskëœ ê°œìˆ˜ê°€ 15%ë¥¼ ë„˜ìœ¼ë©´ ì¤‘ì§€\n",
    "            break\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:  # ì´ë²ˆì— maskí•  ê°œìˆ˜ë¥¼ í¬í•¨í•´ 15%ë¥¼ ë„˜ìœ¼ë©´ skip\n",
    "            continue\n",
    "        dice = random.random()  # 0..1 ì‚¬ì´ì˜ í™•ë¥  ê°’\n",
    "        for index in index_set:\n",
    "            masked_token = None\n",
    "            if dice < 0.8:  # 80% replace with [MASK]\n",
    "                masked_token = \"[MASK]\"\n",
    "            elif dice < 0.9: # 10% keep original\n",
    "                masked_token = tokens[index]\n",
    "            else:  # 10% random word\n",
    "                masked_token = random.choice(vocab_list)\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "    # mask_lms ì •ë ¬ í›„ mask_idx, mask_label ì¶”ì¶œ\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]  # maskëœ tokenì˜ index\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]  # maskëœ tokenì˜ ì›ë˜ ê°’\n",
    "\n",
    "    return tokens, mask_idx, mask_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd93a275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´', 'â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„', 'â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—', '[SEP]', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬', 'â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”', 'â–ëª‡', 'â–ë‹¬', 'â–í¬', 'â–ì „ë¶€í„°', 'â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”', 'â–ì•„ë‚´', 'â–ìƒê°ì—', 'â–ê·¸', 'í† ë¡', 'â–ë¨¹ê³ ', 'â–ì‹¶ë‹¤', 'ë˜', '[SEP]']\n",
      "['[CLS]', 'â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´', 'â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', '[MASK]', '[MASK]', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', '[MASK]', '[MASK]', '[MASK]', '[SEP]', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', '[MASK]', 'â–ì»¬', 'ì»¬', 'í•œ', '[MASK]', 'ëŠ', 'â–ê·œì¥', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”', 'â–ëª‡', 'â–ë‹¬', 'â–í¬', 'â–ì „ë¶€í„°', 'â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”', '[MASK]', 'â–ìƒê°ì—', 'â–ê·¸', 'í† ë¡', 'â–ë¨¹ê³ ', 'â–ì‹¶ë‹¤', 'ë˜', '[SEP]']\n",
      "[16, 17, 37, 38, 39, 48, 52, 53, 54, 67]\n",
      "['â–ë§ì•„', 'â–ì²«', 'â–ì„œ', 'í‘¼', 'ì—', 'â–í˜ëŸ¬', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–ì•„ë‚´']\n"
     ]
    }
   ],
   "source": [
    "# tokensê°€ maskë˜ë¯€ë¡œ ì¬ ì‹¤í–‰ì„ ìœ„í•´ì„œ ë„£ì–´ì¤Œ (í…ŒìŠ¤íŠ¸ìš©)\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "tokens, mask_idx, mask_label = create_pretrain_mask(tokens, mask_cnt, vocab_list)\n",
    "print(tokens_org)\n",
    "print(tokens)\n",
    "print(mask_idx)\n",
    "print(mask_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55223b96",
   "metadata": {},
   "source": [
    "## 3. ë°ì´í„° ì „ì²˜ë¦¬ (2) NSP pair ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21e82881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSPëŠ” ë‘ ë¬¸ì¥ì´ ì—°ì†í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒ\n",
    "# 2ê°œì˜ ë¬¸ì¥ì„ ì§ì§€ì–´ 50%ì˜ í™•ë¥ ë¡œ TRUEì™€ FALSEë¥¼ ì§€ì •\n",
    "\n",
    "# ë‘ ë¬¸ì¥ ì‚¬ì´ì— segment ì²˜ë¦¬\n",
    "# ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ segmentëŠ” 0, ë‘ ë²ˆì§¸ ë¬¸ì¥ì€ 1ë¡œ ì±„ì›Œì¤€ í›„ \n",
    "# ë‘˜ ì‚¬ì´ì— êµ¬ë¶„ìì¸ [SEP] ë“±ì„ ë„£ì–´ì£¼ê¸°\n",
    "\n",
    "# MLMê³¼ NSPëŠ” ë™ì‹œì— í•™ìŠµëœë‹¤\n",
    "\n",
    "string = \"\"\"ì¶”ì ì¶”ì  ë¹„ê°€ ë‚´ë¦¬ëŠ” ë‚ ì´ì—ˆì–´\n",
    "ê·¸ë‚ ì€ ì™ ì§€ ì†ë‹˜ì´ ë§ì•„\n",
    "ì²« ë²ˆì— ì‚¼ì‹­ ì „ ë‘˜ì§¸ë²ˆ ì˜¤ì‹­ ì „\n",
    "ì˜¤ëœë§Œì— ë°›ì•„ë³´ëŠ” ì‹­ ì „ì§œë¦¬ ë°±í†µí™” ì„œí‘¼ì—\n",
    "ì†ë°”ë‹¥ ìœ„ì—” ê¸°ì¨ì˜ ëˆˆë¬¼ì´ í˜ëŸ¬\n",
    "ì»¬ì»¬í•œ ëª©ì— ëª¨ì£¼ í•œì”ì„ ì ì…”\n",
    "ëª‡ ë‹¬ í¬ ì „ë¶€í„° ì½œë¡ê±°ë¦¬ëŠ” ì•„ë‚´\n",
    "ìƒê°ì— ê·¸í† ë¡ ë¨¹ê³  ì‹¶ë‹¤ë˜\n",
    "ì„¤ë íƒ• í•œ ê·¸ë¦‡ì„ ì´ì œëŠ” ì‚´ ìˆ˜ ìˆì–´\n",
    "ì§‘ìœ¼ë¡œ ëŒì•„ê°€ëŠ” ê¸¸ ë‚œ ë¬¸ë“ ë– ì˜¬ë¼\n",
    "ì•„ë‚´ì˜ ëª©ì†Œë¦¬ê°€ ê±°ì¹ ì–´ë§Œ ê°€ëŠ” í¬ë°•í•œ ìˆ¨ì†Œë¦¬ê°€\n",
    "ì˜¤ëŠ˜ì€ ì™ ì§€ ë‚˜ê°€ì§€ ë§ë¼ë˜ ë‚´ ì˜†ì— ìˆì–´ ë‹¬ë¼ë˜\n",
    "ê·¸ë¦¬ë„ ë‚˜ê°€ê³  ì‹¶ìœ¼ë©´ ì¼ì°ì´ë¼ë„ ë“¤ì–´ì™€ ë‹¬ë¼ë˜\n",
    "ì•„ë‚´ì˜ ê°„ì ˆí•œ ëª©ì†Œë¦¬ê°€ ë“¤ë ¤ì™€\n",
    "ë‚˜ë¥¼ ì›ë§í•˜ë“¯ ë¹„ëŠ” ì ì  ê±°ì„¸ì ¸\n",
    "ì‹¸ëŠ˜íˆ ì‹ì–´ê°€ëŠ” ì•„ë‚´ê°€ ë– ì˜¬ë¼ ê±±ì •ì€ ë”í•´ì ¸\n",
    "ë‚œ ëª°ë¼ ì˜¤ëŠ˜ì€ ìš´ìˆ˜ ì¢‹ì€ ë‚ \n",
    "ë‚œ ë§¨ë‚  ì´ë ‡ê²Œ ì‚´ ìˆ˜ ìˆìœ¼ë©´ ì–¼ë§ˆë‚˜ ì¢‹ì„ê¹Œ\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9bd4f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´'],\n",
       " ['â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„'],\n",
       " ['â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì¤„ ë‹¨ìœ„ë¡œ tokenize\n",
    "doc = [vocab.encode_as_pieces(line) for line in string.split(\"\\n\")]\n",
    "doc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d404a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœëŒ€ ê¸¸ì´\n",
    "n_test_seq = 64\n",
    "# ìµœì†Œ ê¸¸ì´\n",
    "min_seq = 8\n",
    "# [CLS], tokens_a, [SEB], tokens_b, [SEP]\n",
    "max_seq = n_test_seq - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd6a65ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 7 66 [['â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´'], ['â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„'], ['â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „'], ['â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—'], ['â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬'], ['â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”'], ['â–ëª‡', 'â–ë‹¬', 'â–í¬', 'â–ì „ë¶€í„°', 'â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”', 'â–ì•„ë‚´']]\n",
      "tokens_a: 16 ['â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´', 'â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„']\n",
      "tokens_b: 50 ['â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬', 'â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”', 'â–ëª‡', 'â–ë‹¬', 'â–í¬', 'â–ì „ë¶€í„°', 'â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”', 'â–ì•„ë‚´']\n",
      "\n",
      "current_chunk: 7 65 [['â–ìƒê°ì—', 'â–ê·¸', 'í† ë¡', 'â–ë¨¹ê³ ', 'â–ì‹¶ë‹¤', 'ë˜'], ['â–ì„¤', 'ë ', 'íƒ•', 'â–í•œ', 'â–ê·¸ë¦‡', 'ì„', 'â–ì´ì œëŠ”', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆì–´'], ['â–ì§‘ìœ¼ë¡œ', 'â–ëŒì•„ê°€ëŠ”', 'â–ê¸¸', 'â–ë‚œ', 'â–ë¬¸', 'ë“', 'â–ë– ì˜¬', 'ë¼'], ['â–ì•„ë‚´ì˜', 'â–ëª©ì†Œë¦¬ê°€', 'â–ê±°ì¹ ', 'ì–´', 'ë§Œ', 'â–ê°€ëŠ”', 'â–í¬', 'ë°•í•œ', 'â–ìˆ¨', 'ì†Œ', 'ë¦¬ê°€'], ['â–ì˜¤ëŠ˜', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ë‚˜ê°€ì§€', 'â–ë§ë¼', 'ë˜', 'â–ë‚´', 'â–ì˜†ì—', 'â–ìˆì–´', 'â–ë‹¬ë¼', 'ë˜'], ['â–ê·¸ë¦¬', 'ë„', 'â–ë‚˜ê°€', 'ê³ ', 'â–ì‹¶', 'ìœ¼ë©´', 'â–ì¼ì°', 'ì´ë¼ë„', 'â–ë“¤ì–´ì™€', 'â–ë‹¬ë¼', 'ë˜'], ['â–ì•„ë‚´ì˜', 'â–ê°„', 'ì ˆí•œ', 'â–ëª©ì†Œë¦¬ê°€', 'â–ë“¤ë ¤', 'ì™€']]\n",
      "tokens_a: 35 ['â–ìƒê°ì—', 'â–ê·¸', 'í† ë¡', 'â–ë¨¹ê³ ', 'â–ì‹¶ë‹¤', 'ë˜', 'â–ì„¤', 'ë ', 'íƒ•', 'â–í•œ', 'â–ê·¸ë¦‡', 'ì„', 'â–ì´ì œëŠ”', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆì–´', 'â–ì§‘ìœ¼ë¡œ', 'â–ëŒì•„ê°€ëŠ”', 'â–ê¸¸', 'â–ë‚œ', 'â–ë¬¸', 'ë“', 'â–ë– ì˜¬', 'ë¼', 'â–ì•„ë‚´ì˜', 'â–ëª©ì†Œë¦¬ê°€', 'â–ê±°ì¹ ', 'ì–´', 'ë§Œ', 'â–ê°€ëŠ”', 'â–í¬', 'ë°•í•œ', 'â–ìˆ¨', 'ì†Œ', 'ë¦¬ê°€']\n",
      "tokens_b: 30 ['â–ì˜¤ëŠ˜', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ë‚˜ê°€ì§€', 'â–ë§ë¼', 'ë˜', 'â–ë‚´', 'â–ì˜†ì—', 'â–ìˆì–´', 'â–ë‹¬ë¼', 'ë˜', 'â–ê·¸ë¦¬', 'ë„', 'â–ë‚˜ê°€', 'ê³ ', 'â–ì‹¶', 'ìœ¼ë©´', 'â–ì¼ì°', 'ì´ë¼ë„', 'â–ë“¤ì–´ì™€', 'â–ë‹¬ë¼', 'ë˜', 'â–ì•„ë‚´ì˜', 'â–ê°„', 'ì ˆí•œ', 'â–ëª©ì†Œë¦¬ê°€', 'â–ë“¤ë ¤', 'ì™€']\n",
      "\n",
      "current_chunk: 4 41 [['â–ë‚˜ë¥¼', 'â–ì›', 'ë§', 'í•˜', 'ë“¯', 'â–ë¹„ëŠ”', 'â–ì ì ', 'â–ê±°ì„¸', 'ì ¸'], ['â–ì‹¸', 'ëŠ˜', 'íˆ', 'â–ì‹', 'ì–´', 'ê°€ëŠ”', 'â–ì•„ë‚´ê°€', 'â–ë– ì˜¬', 'ë¼', 'â–ê±±', 'ì •ì€', 'â–ë”', 'í•´ì ¸'], ['â–ë‚œ', 'â–ëª°', 'ë¼', 'â–ì˜¤ëŠ˜', 'ì€', 'â–ìš´ìˆ˜', 'â–ì¢‹ì€', 'â–ë‚ '], ['â–ë‚œ', 'â–ë§¨', 'ë‚ ', 'â–ì´ë ‡ê²Œ', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆìœ¼ë©´', 'â–ì–¼ë§ˆë‚˜', 'â–ì¢‹', 'ì„', 'ê¹Œ']]\n",
      "tokens_a: 30 ['â–ë‚˜ë¥¼', 'â–ì›', 'ë§', 'í•˜', 'ë“¯', 'â–ë¹„ëŠ”', 'â–ì ì ', 'â–ê±°ì„¸', 'ì ¸', 'â–ì‹¸', 'ëŠ˜', 'íˆ', 'â–ì‹', 'ì–´', 'ê°€ëŠ”', 'â–ì•„ë‚´ê°€', 'â–ë– ì˜¬', 'ë¼', 'â–ê±±', 'ì •ì€', 'â–ë”', 'í•´ì ¸', 'â–ë‚œ', 'â–ëª°', 'ë¼', 'â–ì˜¤ëŠ˜', 'ì€', 'â–ìš´ìˆ˜', 'â–ì¢‹ì€', 'â–ë‚ ']\n",
      "tokens_b: 11 ['â–ë‚œ', 'â–ë§¨', 'ë‚ ', 'â–ì´ë ‡ê²Œ', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆìœ¼ë©´', 'â–ì–¼ë§ˆë‚˜', 'â–ì¢‹', 'ì„', 'ê¹Œ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_chunk = []  # line ë‹¨ìœ„ tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)):  # doc ì „ì²´ë¥¼ loop\n",
    "    current_chunk.append(doc[i])  # line ë‹¨ìœ„ë¡œ ì¶”ê°€\n",
    "    current_length += len(doc[i])  # current_chunkì˜ token ìˆ˜\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # ë§ˆì§€ë§‰ ì¤„ ì´ê±°ë‚˜ ê¸¸ì´ê°€ max_seq ì´ìƒ ì¸ ê²½ìš°\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "        #######################################\n",
    "        # token a\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "          \n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        #######################################\n",
    "        print()\n",
    "\n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35569d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    tokens_a, tokens_bì˜ ê¸¸ì´ë¥¼ ì¤„ì„ ìµœëŒ€ ê¸¸ì´: max_seq\n",
    "    :param tokens_a: tokens A\n",
    "    :param tokens_b: tokens B\n",
    "    :param max_seq: ë‘ tokens ê¸¸ì´ì˜ ìµœëŒ€ ê°’\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "670bf48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 7 66 [['â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´'], ['â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„'], ['â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „'], ['â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—'], ['â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬'], ['â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”'], ['â–ëª‡', 'â–ë‹¬', 'â–í¬', 'â–ì „ë¶€í„°', 'â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”', 'â–ì•„ë‚´']]\n",
      "is_next: 1\n",
      "tokens_a: 42 ['â–ë‚ ', 'ì´ì—ˆ', 'ì–´', 'â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„', 'â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬']\n",
      "tokens_b: 19 ['â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”', 'â–ëª‡', 'â–ë‹¬', 'â–í¬', 'â–ì „ë¶€í„°', 'â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”', 'â–ì•„ë‚´']\n",
      "\n",
      "current_chunk: 7 65 [['â–ìƒê°ì—', 'â–ê·¸', 'í† ë¡', 'â–ë¨¹ê³ ', 'â–ì‹¶ë‹¤', 'ë˜'], ['â–ì„¤', 'ë ', 'íƒ•', 'â–í•œ', 'â–ê·¸ë¦‡', 'ì„', 'â–ì´ì œëŠ”', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆì–´'], ['â–ì§‘ìœ¼ë¡œ', 'â–ëŒì•„ê°€ëŠ”', 'â–ê¸¸', 'â–ë‚œ', 'â–ë¬¸', 'ë“', 'â–ë– ì˜¬', 'ë¼'], ['â–ì•„ë‚´ì˜', 'â–ëª©ì†Œë¦¬ê°€', 'â–ê±°ì¹ ', 'ì–´', 'ë§Œ', 'â–ê°€ëŠ”', 'â–í¬', 'ë°•í•œ', 'â–ìˆ¨', 'ì†Œ', 'ë¦¬ê°€'], ['â–ì˜¤ëŠ˜', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ë‚˜ê°€ì§€', 'â–ë§ë¼', 'ë˜', 'â–ë‚´', 'â–ì˜†ì—', 'â–ìˆì–´', 'â–ë‹¬ë¼', 'ë˜'], ['â–ê·¸ë¦¬', 'ë„', 'â–ë‚˜ê°€', 'ê³ ', 'â–ì‹¶', 'ìœ¼ë©´', 'â–ì¼ì°', 'ì´ë¼ë„', 'â–ë“¤ì–´ì™€', 'â–ë‹¬ë¼', 'ë˜'], ['â–ì•„ë‚´ì˜', 'â–ê°„', 'ì ˆí•œ', 'â–ëª©ì†Œë¦¬ê°€', 'â–ë“¤ë ¤', 'ì™€']]\n",
      "is_next: 0\n",
      "tokens_a: 37 ['ë§Œ', 'â–ê°€ëŠ”', 'â–í¬', 'ë°•í•œ', 'â–ìˆ¨', 'ì†Œ', 'ë¦¬ê°€', 'â–ì˜¤ëŠ˜', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ë‚˜ê°€ì§€', 'â–ë§ë¼', 'ë˜', 'â–ë‚´', 'â–ì˜†ì—', 'â–ìˆì–´', 'â–ë‹¬ë¼', 'ë˜', 'â–ê·¸ë¦¬', 'ë„', 'â–ë‚˜ê°€', 'ê³ ', 'â–ì‹¶', 'ìœ¼ë©´', 'â–ì¼ì°', 'ì´ë¼ë„', 'â–ë“¤ì–´ì™€', 'â–ë‹¬ë¼', 'ë˜', 'â–ì•„ë‚´ì˜', 'â–ê°„', 'ì ˆí•œ', 'â–ëª©ì†Œë¦¬ê°€', 'â–ë“¤ë ¤', 'ì™€']\n",
      "tokens_b: 24 ['â–ìƒê°ì—', 'â–ê·¸', 'í† ë¡', 'â–ë¨¹ê³ ', 'â–ì‹¶ë‹¤', 'ë˜', 'â–ì„¤', 'ë ', 'íƒ•', 'â–í•œ', 'â–ê·¸ë¦‡', 'ì„', 'â–ì´ì œëŠ”', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆì–´', 'â–ì§‘ìœ¼ë¡œ', 'â–ëŒì•„ê°€ëŠ”', 'â–ê¸¸', 'â–ë‚œ', 'â–ë¬¸', 'ë“', 'â–ë– ì˜¬', 'ë¼']\n",
      "\n",
      "current_chunk: 4 41 [['â–ë‚˜ë¥¼', 'â–ì›', 'ë§', 'í•˜', 'ë“¯', 'â–ë¹„ëŠ”', 'â–ì ì ', 'â–ê±°ì„¸', 'ì ¸'], ['â–ì‹¸', 'ëŠ˜', 'íˆ', 'â–ì‹', 'ì–´', 'ê°€ëŠ”', 'â–ì•„ë‚´ê°€', 'â–ë– ì˜¬', 'ë¼', 'â–ê±±', 'ì •ì€', 'â–ë”', 'í•´ì ¸'], ['â–ë‚œ', 'â–ëª°', 'ë¼', 'â–ì˜¤ëŠ˜', 'ì€', 'â–ìš´ìˆ˜', 'â–ì¢‹ì€', 'â–ë‚ '], ['â–ë‚œ', 'â–ë§¨', 'ë‚ ', 'â–ì´ë ‡ê²Œ', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆìœ¼ë©´', 'â–ì–¼ë§ˆë‚˜', 'â–ì¢‹', 'ì„', 'ê¹Œ']]\n",
      "is_next: 0\n",
      "tokens_a: 32 ['â–ì‹¸', 'ëŠ˜', 'íˆ', 'â–ì‹', 'ì–´', 'ê°€ëŠ”', 'â–ì•„ë‚´ê°€', 'â–ë– ì˜¬', 'ë¼', 'â–ê±±', 'ì •ì€', 'â–ë”', 'í•´ì ¸', 'â–ë‚œ', 'â–ëª°', 'ë¼', 'â–ì˜¤ëŠ˜', 'ì€', 'â–ìš´ìˆ˜', 'â–ì¢‹ì€', 'â–ë‚ ', 'â–ë‚œ', 'â–ë§¨', 'ë‚ ', 'â–ì´ë ‡ê²Œ', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆìœ¼ë©´', 'â–ì–¼ë§ˆë‚˜', 'â–ì¢‹', 'ì„', 'ê¹Œ']\n",
      "tokens_b: 9 ['â–ë‚˜ë¥¼', 'â–ì›', 'ë§', 'í•˜', 'ë“¯', 'â–ë¹„ëŠ”', 'â–ì ì ', 'â–ê±°ì„¸', 'ì ¸']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_chunk = []  # line ë‹¨ìœ„ tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)):  # doc ì „ì²´ë¥¼ loop\n",
    "    current_chunk.append(doc[i])  # line ë‹¨ìœ„ë¡œ ì¶”ê°€\n",
    "    current_length += len(doc[i])  # current_chunkì˜ token ìˆ˜\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # ë§ˆì§€ë§‰ ì¤„ ì´ê±°ë‚˜ ê¸¸ì´ê°€ max_seq ì´ìƒ ì¸ ê²½ìš°\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "        # token a\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "\n",
    "        #######################################\n",
    "        if random.random() < 0.5:  # 50% í™•ë¥ ë¡œ swap\n",
    "            is_next = 0\n",
    "            tokens_t = tokens_a\n",
    "            tokens_a = tokens_b\n",
    "            tokens_b = tokens_t\n",
    "        else:\n",
    "            is_next = 1\n",
    "        # max_seq ë³´ë‹¤ í° ê²½ìš° ê¸¸ì´ ì¡°ì ˆ\n",
    "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "        assert 0 < len(tokens_a)\n",
    "        assert 0 < len(tokens_b)\n",
    "\n",
    "        print(\"is_next:\", is_next)\n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        #######################################\n",
    "        print()\n",
    "\n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ebdf466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_chunk: 7 66 [['â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´'], ['â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„'], ['â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „'], ['â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—'], ['â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬'], ['â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”'], ['â–ëª‡', 'â–ë‹¬', 'â–í¬', 'â–ì „ë¶€í„°', 'â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”', 'â–ì•„ë‚´']]\n",
      "is_next: 1\n",
      "tokens_a: 8 ['â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´']\n",
      "tokens_b: 53 ['â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„', 'â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬', 'â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”', 'â–ëª‡', 'â–ë‹¬', 'â–í¬']\n",
      "tokens: 64 ['[CLS]', 'â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´', '[SEP]', 'â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', 'â–ë§ì•„', 'â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬', 'â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”', 'â–ëª‡', 'â–ë‹¬', 'â–í¬', '[SEP]']\n",
      "segment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "masked tokens: 64 ['[CLS]', 'â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´', '[SEP]', 'â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', '[MASK]', 'â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „', '[MASK]', '[MASK]', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ë°©ì‹ìœ¼ë¡œ', 'â–ì „', 'ì§œë¦¬', '[MASK]', '[MASK]', '[MASK]', 'â–ì„œ', 'í‘¼', 'ì—', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬', 'â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”', 'â–ëª‡', '[MASK]', 'â–í¬', '[SEP]']\n",
      "masked index: 9 [17, 19, 28, 29, 32, 35, 36, 37, 61]\n",
      "masked label: 9 ['â–ë§ì•„', 'â–ë²ˆì—', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ì‹­', 'â–ë°±', 'í†µ', 'í™”', 'â–ë‹¬']\n",
      "\n",
      "current_chunk: 7 65 [['â–ìƒê°ì—', 'â–ê·¸', 'í† ë¡', 'â–ë¨¹ê³ ', 'â–ì‹¶ë‹¤', 'ë˜'], ['â–ì„¤', 'ë ', 'íƒ•', 'â–í•œ', 'â–ê·¸ë¦‡', 'ì„', 'â–ì´ì œëŠ”', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆì–´'], ['â–ì§‘ìœ¼ë¡œ', 'â–ëŒì•„ê°€ëŠ”', 'â–ê¸¸', 'â–ë‚œ', 'â–ë¬¸', 'ë“', 'â–ë– ì˜¬', 'ë¼'], ['â–ì•„ë‚´ì˜', 'â–ëª©ì†Œë¦¬ê°€', 'â–ê±°ì¹ ', 'ì–´', 'ë§Œ', 'â–ê°€ëŠ”', 'â–í¬', 'ë°•í•œ', 'â–ìˆ¨', 'ì†Œ', 'ë¦¬ê°€'], ['â–ì˜¤ëŠ˜', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ë‚˜ê°€ì§€', 'â–ë§ë¼', 'ë˜', 'â–ë‚´', 'â–ì˜†ì—', 'â–ìˆì–´', 'â–ë‹¬ë¼', 'ë˜'], ['â–ê·¸ë¦¬', 'ë„', 'â–ë‚˜ê°€', 'ê³ ', 'â–ì‹¶', 'ìœ¼ë©´', 'â–ì¼ì°', 'ì´ë¼ë„', 'â–ë“¤ì–´ì™€', 'â–ë‹¬ë¼', 'ë˜'], ['â–ì•„ë‚´ì˜', 'â–ê°„', 'ì ˆí•œ', 'â–ëª©ì†Œë¦¬ê°€', 'â–ë“¤ë ¤', 'ì™€']]\n",
      "is_next: 1\n",
      "tokens_a: 31 ['â–ì‹¶ë‹¤', 'ë˜', 'â–ì„¤', 'ë ', 'íƒ•', 'â–í•œ', 'â–ê·¸ë¦‡', 'ì„', 'â–ì´ì œëŠ”', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆì–´', 'â–ì§‘ìœ¼ë¡œ', 'â–ëŒì•„ê°€ëŠ”', 'â–ê¸¸', 'â–ë‚œ', 'â–ë¬¸', 'ë“', 'â–ë– ì˜¬', 'ë¼', 'â–ì•„ë‚´ì˜', 'â–ëª©ì†Œë¦¬ê°€', 'â–ê±°ì¹ ', 'ì–´', 'ë§Œ', 'â–ê°€ëŠ”', 'â–í¬', 'ë°•í•œ', 'â–ìˆ¨', 'ì†Œ', 'ë¦¬ê°€']\n",
      "tokens_b: 30 ['â–ì˜¤ëŠ˜', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ë‚˜ê°€ì§€', 'â–ë§ë¼', 'ë˜', 'â–ë‚´', 'â–ì˜†ì—', 'â–ìˆì–´', 'â–ë‹¬ë¼', 'ë˜', 'â–ê·¸ë¦¬', 'ë„', 'â–ë‚˜ê°€', 'ê³ ', 'â–ì‹¶', 'ìœ¼ë©´', 'â–ì¼ì°', 'ì´ë¼ë„', 'â–ë“¤ì–´ì™€', 'â–ë‹¬ë¼', 'ë˜', 'â–ì•„ë‚´ì˜', 'â–ê°„', 'ì ˆí•œ', 'â–ëª©ì†Œë¦¬ê°€', 'â–ë“¤ë ¤', 'ì™€']\n",
      "tokens: 64 ['[CLS]', 'â–ì‹¶ë‹¤', 'ë˜', 'â–ì„¤', 'ë ', 'íƒ•', 'â–í•œ', 'â–ê·¸ë¦‡', 'ì„', 'â–ì´ì œëŠ”', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆì–´', 'â–ì§‘ìœ¼ë¡œ', 'â–ëŒì•„ê°€ëŠ”', 'â–ê¸¸', 'â–ë‚œ', 'â–ë¬¸', 'ë“', 'â–ë– ì˜¬', 'ë¼', 'â–ì•„ë‚´ì˜', 'â–ëª©ì†Œë¦¬ê°€', 'â–ê±°ì¹ ', 'ì–´', 'ë§Œ', 'â–ê°€ëŠ”', 'â–í¬', 'ë°•í•œ', 'â–ìˆ¨', 'ì†Œ', 'ë¦¬ê°€', '[SEP]', 'â–ì˜¤ëŠ˜', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ë‚˜ê°€ì§€', 'â–ë§ë¼', 'ë˜', 'â–ë‚´', 'â–ì˜†ì—', 'â–ìˆì–´', 'â–ë‹¬ë¼', 'ë˜', 'â–ê·¸ë¦¬', 'ë„', 'â–ë‚˜ê°€', 'ê³ ', 'â–ì‹¶', 'ìœ¼ë©´', 'â–ì¼ì°', 'ì´ë¼ë„', 'â–ë“¤ì–´ì™€', 'â–ë‹¬ë¼', 'ë˜', 'â–ì•„ë‚´ì˜', 'â–ê°„', 'ì ˆí•œ', 'â–ëª©ì†Œë¦¬ê°€', 'â–ë“¤ë ¤', 'ì™€', '[SEP]']\n",
      "segment: 64 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "masked tokens: 64 ['[CLS]', 'â–ì‹¶ë‹¤', 'ë˜', 'â–ì„¤', 'ë ', 'íƒ•', 'â–í•œ', 'â–ì–´ë¨¸ë‹ˆì™€', 'â–ì´ì™€í…Œ', 'â–ì´ì œëŠ”', 'â–ì‚´', 'â–ìˆ˜', '[MASK]', 'â–ì§‘ìœ¼ë¡œ', 'â–ëŒì•„ê°€ëŠ”', 'â–ê¸¸', 'â–ë‚œ', 'â–ë¬¸', 'ë“', 'â–ë– ì˜¬', 'ë¼', 'â–ì•„ë‚´ì˜', 'â–ëª©ì†Œë¦¬ê°€', 'â–ê±°ì¹ ', 'ì–´', 'ë§Œ', 'â–ê°€ëŠ”', 'â–í¬', 'ë°•í•œ', 'â–ìˆ¨', 'ì†Œ', 'ë¦¬ê°€', '[SEP]', 'â–ì˜¤ëŠ˜', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ë‚˜ê°€ì§€', 'â–ë§ë¼', 'ë˜', 'â–ë‚´', 'â–ì˜†ì—', 'â–ìˆì–´', 'â–ë‹¬ë¼', 'ë˜', 'â–ê·¸ë¦¬', 'ë„', 'â–ë‚˜ê°€', 'ê³ ', 'â–ì‹¶', 'ìœ¼ë©´', 'â–ì¼ì°', 'ì´ë¼ë„', 'â–ë“¤ì–´ì™€', 'â–ë‹¬ë¼', 'ë˜', 'â–ì•„ë‚´ì˜', '[MASK]', '[MASK]', 'â–ëª©ì†Œë¦¬ê°€', 'â–ë“¤ë ¤', 'ì™€', '[SEP]']\n",
      "masked index: 9 [7, 8, 11, 12, 23, 24, 25, 58, 59]\n",
      "masked label: 9 ['â–ê·¸ë¦‡', 'ì„', 'â–ìˆ˜', 'â–ìˆì–´', 'â–ê±°ì¹ ', 'ì–´', 'ë§Œ', 'â–ê°„', 'ì ˆí•œ']\n",
      "\n",
      "current_chunk: 4 41 [['â–ë‚˜ë¥¼', 'â–ì›', 'ë§', 'í•˜', 'ë“¯', 'â–ë¹„ëŠ”', 'â–ì ì ', 'â–ê±°ì„¸', 'ì ¸'], ['â–ì‹¸', 'ëŠ˜', 'íˆ', 'â–ì‹', 'ì–´', 'ê°€ëŠ”', 'â–ì•„ë‚´ê°€', 'â–ë– ì˜¬', 'ë¼', 'â–ê±±', 'ì •ì€', 'â–ë”', 'í•´ì ¸'], ['â–ë‚œ', 'â–ëª°', 'ë¼', 'â–ì˜¤ëŠ˜', 'ì€', 'â–ìš´ìˆ˜', 'â–ì¢‹ì€', 'â–ë‚ '], ['â–ë‚œ', 'â–ë§¨', 'ë‚ ', 'â–ì´ë ‡ê²Œ', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆìœ¼ë©´', 'â–ì–¼ë§ˆë‚˜', 'â–ì¢‹', 'ì„', 'ê¹Œ']]\n",
      "is_next: 0\n",
      "tokens_a: 19 ['â–ë‚œ', 'â–ëª°', 'ë¼', 'â–ì˜¤ëŠ˜', 'ì€', 'â–ìš´ìˆ˜', 'â–ì¢‹ì€', 'â–ë‚ ', 'â–ë‚œ', 'â–ë§¨', 'ë‚ ', 'â–ì´ë ‡ê²Œ', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆìœ¼ë©´', 'â–ì–¼ë§ˆë‚˜', 'â–ì¢‹', 'ì„', 'ê¹Œ']\n",
      "tokens_b: 22 ['â–ë‚˜ë¥¼', 'â–ì›', 'ë§', 'í•˜', 'ë“¯', 'â–ë¹„ëŠ”', 'â–ì ì ', 'â–ê±°ì„¸', 'ì ¸', 'â–ì‹¸', 'ëŠ˜', 'íˆ', 'â–ì‹', 'ì–´', 'ê°€ëŠ”', 'â–ì•„ë‚´ê°€', 'â–ë– ì˜¬', 'ë¼', 'â–ê±±', 'ì •ì€', 'â–ë”', 'í•´ì ¸']\n",
      "tokens: 44 ['[CLS]', 'â–ë‚œ', 'â–ëª°', 'ë¼', 'â–ì˜¤ëŠ˜', 'ì€', 'â–ìš´ìˆ˜', 'â–ì¢‹ì€', 'â–ë‚ ', 'â–ë‚œ', 'â–ë§¨', 'ë‚ ', 'â–ì´ë ‡ê²Œ', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆìœ¼ë©´', 'â–ì–¼ë§ˆë‚˜', 'â–ì¢‹', 'ì„', 'ê¹Œ', '[SEP]', 'â–ë‚˜ë¥¼', 'â–ì›', 'ë§', 'í•˜', 'ë“¯', 'â–ë¹„ëŠ”', 'â–ì ì ', 'â–ê±°ì„¸', 'ì ¸', 'â–ì‹¸', 'ëŠ˜', 'íˆ', 'â–ì‹', 'ì–´', 'ê°€ëŠ”', 'â–ì•„ë‚´ê°€', 'â–ë– ì˜¬', 'ë¼', 'â–ê±±', 'ì •ì€', 'â–ë”', 'í•´ì ¸', '[SEP]']\n",
      "segment: 44 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "masked tokens: 44 ['[CLS]', 'â–ë‚œ', 'â–ëª°', 'ë¼', 'â–ì˜¤ëŠ˜', 'ì€', 'â–ìš´ìˆ˜', 'â–ì¢‹ì€', '[MASK]', 'â–ë‚œ', '[MASK]', '[MASK]', 'â–ì´ë ‡ê²Œ', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆìœ¼ë©´', 'â–ì–¼ë§ˆë‚˜', 'â–ì¢‹', 'ì„', 'ê¹Œ', '[SEP]', '[MASK]', 'â–ì›', 'ë§', 'í•˜', 'ë“¯', 'â–ë¹„ëŠ”', 'â–ì ì ', 'â–ê±°ì„¸', 'ì ¸', 'â–ì‹¸', 'ëŠ˜', 'íˆ', 'â–ì‹', 'ì–´', 'ê°€ëŠ”', 'â–ì•„ë‚´ê°€', 'â–ë– ì˜¬', 'ë¼', 'â–ê±±', 'ì •ì€', '[MASK]', '[MASK]', '[SEP]']\n",
      "masked index: 6 [8, 10, 11, 21, 41, 42]\n",
      "masked label: 6 ['â–ë‚ ', 'â–ë§¨', 'ë‚ ', 'â–ë‚˜ë¥¼', 'â–ë”', 'í•´ì ¸']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instances = []\n",
    "current_chunk = []  # line ë‹¨ìœ„ tokens\n",
    "current_length = 0\n",
    "for i in range(len(doc)):  # doc ì „ì²´ë¥¼ loop\n",
    "    current_chunk.append(doc[i])  # line ë‹¨ìœ„ë¡œ ì¶”ê°€\n",
    "    current_length += len(doc[i])  # current_chunkì˜ token ìˆ˜\n",
    "    if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # ë§ˆì§€ë§‰ ì¤„ ì´ê±°ë‚˜ ê¸¸ì´ê°€ max_seq ì´ìƒ ì¸ ê²½ìš°\n",
    "        print(\"current_chunk:\", len(current_chunk), current_length, current_chunk)\n",
    "\n",
    "        # token a\n",
    "        a_end = 1\n",
    "        if 1 < len(current_chunk):\n",
    "            a_end = random.randrange(1, len(current_chunk))\n",
    "        tokens_a = []\n",
    "        for j in range(a_end):\n",
    "            tokens_a.extend(current_chunk[j])\n",
    "        # token b\n",
    "        tokens_b = []\n",
    "        for j in range(a_end, len(current_chunk)):\n",
    "            tokens_b.extend(current_chunk[j])\n",
    "\n",
    "        if random.random() < 0.5:  # 50% í™•ë¥ ë¡œ swap\n",
    "            is_next = 0\n",
    "            tokens_t = tokens_a\n",
    "            tokens_a = tokens_b\n",
    "            tokens_b = tokens_t\n",
    "        else:\n",
    "            is_next = 1\n",
    "        # max_seq ë³´ë‹¤ í° ê²½ìš° ê¸¸ì´ ì¡°ì ˆ\n",
    "        trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "        assert 0 < len(tokens_a)\n",
    "        assert 0 < len(tokens_b)\n",
    "\n",
    "        print(\"is_next:\", is_next)\n",
    "        print(\"tokens_a:\", len(tokens_a), tokens_a)\n",
    "        print(\"tokens_b:\", len(tokens_b), tokens_b)\n",
    "        #######################################\n",
    "        # tokens & aegment ìƒì„±\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "        segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "        print(\"tokens:\", len(tokens), tokens)\n",
    "        print(\"segment:\", len(segment), segment)\n",
    "        # mask\n",
    "        tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * 0.15), vocab_list)\n",
    "        print(\"masked tokens:\", len(tokens), tokens)\n",
    "        print(\"masked index:\", len(mask_idx), mask_idx)\n",
    "        print(\"masked label:\", len(mask_label), mask_label)\n",
    "\n",
    "        instance = {\n",
    "            \"tokens\": tokens,\n",
    "            \"segment\": segment,\n",
    "            \"is_next\": is_next,\n",
    "            \"mask_idx\": mask_idx,\n",
    "            \"mask_label\": mask_label\n",
    "        }\n",
    "        instances.append(instance)\n",
    "        #######################################\n",
    "        print()\n",
    "\n",
    "        current_chunk = []\n",
    "        current_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b596fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', 'â–ì¶”ì ', 'ì¶”', 'ì ', 'â–ë¹„ê°€', 'â–ë‚´ë¦¬ëŠ”', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´', '[SEP]', 'â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', '[MASK]', 'â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', 'â–ì˜¤', 'ì‹­', 'â–ì „', '[MASK]', '[MASK]', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ë°©ì‹ìœ¼ë¡œ', 'â–ì „', 'ì§œë¦¬', '[MASK]', '[MASK]', '[MASK]', 'â–ì„œ', 'í‘¼', 'ì—', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', 'â–ëˆˆ', 'ë¬¼ì´', 'â–í˜ëŸ¬', 'â–ì»¬', 'ì»¬', 'í•œ', 'â–ëª©ì—', 'â–ëª¨', 'ì£¼', 'â–í•œ', 'ì”', 'ì„', 'â–ì ', 'ì…”', 'â–ëª‡', '[MASK]', 'â–í¬', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [17, 19, 28, 29, 32, 35, 36, 37, 61], 'mask_label': ['â–ë§ì•„', 'â–ë²ˆì—', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ì‹­', 'â–ë°±', 'í†µ', 'í™”', 'â–ë‹¬']}\n",
      "{'tokens': ['[CLS]', 'â–ì‹¶ë‹¤', 'ë˜', 'â–ì„¤', 'ë ', 'íƒ•', 'â–í•œ', 'â–ì–´ë¨¸ë‹ˆì™€', 'â–ì´ì™€í…Œ', 'â–ì´ì œëŠ”', 'â–ì‚´', 'â–ìˆ˜', '[MASK]', 'â–ì§‘ìœ¼ë¡œ', 'â–ëŒì•„ê°€ëŠ”', 'â–ê¸¸', 'â–ë‚œ', 'â–ë¬¸', 'ë“', 'â–ë– ì˜¬', 'ë¼', 'â–ì•„ë‚´ì˜', 'â–ëª©ì†Œë¦¬ê°€', 'â–ê±°ì¹ ', 'ì–´', 'ë§Œ', 'â–ê°€ëŠ”', 'â–í¬', 'ë°•í•œ', 'â–ìˆ¨', 'ì†Œ', 'ë¦¬ê°€', '[SEP]', 'â–ì˜¤ëŠ˜', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ë‚˜ê°€ì§€', 'â–ë§ë¼', 'ë˜', 'â–ë‚´', 'â–ì˜†ì—', 'â–ìˆì–´', 'â–ë‹¬ë¼', 'ë˜', 'â–ê·¸ë¦¬', 'ë„', 'â–ë‚˜ê°€', 'ê³ ', 'â–ì‹¶', 'ìœ¼ë©´', 'â–ì¼ì°', 'ì´ë¼ë„', 'â–ë“¤ì–´ì™€', 'â–ë‹¬ë¼', 'ë˜', 'â–ì•„ë‚´ì˜', '[MASK]', '[MASK]', 'â–ëª©ì†Œë¦¬ê°€', 'â–ë“¤ë ¤', 'ì™€', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [7, 8, 11, 12, 23, 24, 25, 58, 59], 'mask_label': ['â–ê·¸ë¦‡', 'ì„', 'â–ìˆ˜', 'â–ìˆì–´', 'â–ê±°ì¹ ', 'ì–´', 'ë§Œ', 'â–ê°„', 'ì ˆí•œ']}\n",
      "{'tokens': ['[CLS]', 'â–ë‚œ', 'â–ëª°', 'ë¼', 'â–ì˜¤ëŠ˜', 'ì€', 'â–ìš´ìˆ˜', 'â–ì¢‹ì€', '[MASK]', 'â–ë‚œ', '[MASK]', '[MASK]', 'â–ì´ë ‡ê²Œ', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆìœ¼ë©´', 'â–ì–¼ë§ˆë‚˜', 'â–ì¢‹', 'ì„', 'ê¹Œ', '[SEP]', '[MASK]', 'â–ì›', 'ë§', 'í•˜', 'ë“¯', 'â–ë¹„ëŠ”', 'â–ì ì ', 'â–ê±°ì„¸', 'ì ¸', 'â–ì‹¸', 'ëŠ˜', 'íˆ', 'â–ì‹', 'ì–´', 'ê°€ëŠ”', 'â–ì•„ë‚´ê°€', 'â–ë– ì˜¬', 'ë¼', 'â–ê±±', 'ì •ì€', '[MASK]', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [8, 10, 11, 21, 41, 42], 'mask_label': ['â–ë‚ ', 'â–ë§¨', 'ë‚ ', 'â–ë‚˜ë¥¼', 'â–ë”', 'í•´ì ¸']}\n"
     ]
    }
   ],
   "source": [
    "# ìµœì¢… ë°ì´í„°ì…‹ ê²°ê³¼ í™•ì¸\n",
    "for instance in instances:\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "537cb431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    docë³„ pretrain ë°ì´í„° ìƒì„±\n",
    "    \"\"\"\n",
    "    # for CLS], [SEP], [SEP]\n",
    "    max_seq = n_seq - 3\n",
    "\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i])  # line\n",
    "        current_length += len(doc[i])\n",
    "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):\n",
    "            # token a\n",
    "            a_end = 1\n",
    "            if 1 < len(current_chunk):\n",
    "                a_end = random.randrange(1, len(current_chunk))\n",
    "            tokens_a = []\n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "            # token b\n",
    "            tokens_b = []\n",
    "            for j in range(a_end, len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "\n",
    "            if random.random() < 0.5:  # 50% í™•ë¥ ë¡œ swap\n",
    "                is_next = 0\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1\n",
    "            # max_seq ë³´ë‹¤ í° ê²½ìš° ê¸¸ì´ ì¡°ì ˆ\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "            assert 0 < len(tokens_a)\n",
    "            assert 0 < len(tokens_b)\n",
    "            # tokens & aegment ìƒì„±\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "            # mask\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
    "\n",
    "            instance = {\n",
    "                \"tokens\": tokens,\n",
    "                \"segment\": segment,\n",
    "                \"is_next\": is_next,\n",
    "                \"mask_idx\": mask_idx,\n",
    "                \"mask_label\": mask_label\n",
    "            }\n",
    "            instances.append(instance)\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    return instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17bd719d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', 'â–ë‚ ', 'ì´ì—ˆ', 'ì–´', 'â–ê·¸ë‚ ', 'ì€', 'â–', 'ì™ ', 'ì§€', 'â–ì†', 'ë‹˜ì´', '[MASK]', 'â–ì²«', 'â–ë²ˆì—', 'â–ì‚¼', 'ì‹­', 'â–ì „', 'â–ë‘˜ì§¸', 'ë²ˆ', '[MASK]', '[MASK]', 'â–ì „', 'â–ì˜¤ëœ', 'ë§Œì—', 'â–ë°›ì•„', 'ë³´ëŠ”', 'â–ì‹­', 'â–ì „', 'ì§œë¦¬', 'â–ë°±', 'í†µ', 'í™”', 'â–ì„œ', 'í‘¼', 'ì—', 'â–ì†ë°”ë‹¥', 'â–ìœ„', 'ì—”', 'â–ê¸°ì¨', 'ì˜', '[MASK]', '[MASK]', 'â–í˜ëŸ¬', 'â–ì»¬', 'ì»¬', 'í•œ', '[MASK]', 'â–ëª¨', 'ì£¼', '[MASK]', '[MASK]', '[MASK]', 'â–ì ', 'ì…”', '[SEP]', 'â–ëª‡', 'â–ë‹¬', 'â–í¬', 'â–ì „ë¶€í„°', 'â–ì½œ', 'ë¡', 'ê±°ë¦¬ëŠ”', 'â–ì•„ë‚´', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [11, 19, 20, 40, 41, 46, 49, 50, 51], 'mask_label': ['â–ë§ì•„', 'â–ì˜¤', 'ì‹­', 'â–ëˆˆ', 'ë¬¼ì´', 'â–ëª©ì—', 'â–í•œ', 'ì”', 'ì„']}\n",
      "{'tokens': ['[CLS]', 'â–ë¬¸', 'ë“', 'â–ë– ì˜¬', 'ë¼', 'â–ì•„ë‚´ì˜', '[MASK]', 'â–ê±°ì¹ ', 'ì–´', 'ë§Œ', 'â–ê°€ëŠ”', 'â–í¬', 'ë°•í•œ', 'â–ìˆ¨', 'ì†Œ', 'ë¦¬ê°€', 'â–ì˜¤ëŠ˜', 'ì€', '[MASK]', '[MASK]', '[MASK]', 'â–ë‚˜ê°€ì§€', 'â–ë§ë¼', 'ë˜', 'â–ë‚´', 'â–ì˜†ì—', 'â–ìˆì–´', 'ê¾¹', 'â–ëŒ€ê¸°', 'â–ê·¸ë¦¬', 'ë„', 'â–ë‚˜ê°€', 'ê³ ', 'â–ì‹¶', 'ìœ¼ë©´', 'â–ì¼ì°', 'ì´ë¼ë„', 'â–ë“¤ì–´ì™€', 'â–ë‹¬ë¼', 'ë˜', 'â–ì•„ë‚´ì˜', 'â–ê°„', 'ì ˆí•œ', '[MASK]', 'â–ë“¤ë ¤', 'ì™€', '[SEP]', 'â–ìƒê°ì—', 'â–ê·¸', 'í† ë¡', 'â–ë¨¹ê³ ', 'â–ì‹¶ë‹¤', 'ë˜', 'â–ì„¤', 'ë ', 'íƒ•', 'â–í•œ', 'â–ê·¸ë¦‡', 'ì„', 'â–ì´ì œëŠ”', 'â–ì‚´', '[MASK]', 'â–ìˆì–´', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [5, 6, 18, 19, 20, 27, 28, 43, 61], 'mask_label': ['â–ì•„ë‚´ì˜', 'â–ëª©ì†Œë¦¬ê°€', 'â–', 'ì™ ', 'ì§€', 'â–ë‹¬ë¼', 'ë˜', 'â–ëª©ì†Œë¦¬ê°€', 'â–ìˆ˜']}\n",
      "{'tokens': ['[CLS]', 'â–ë‚˜ë¥¼', 'â–ì›', 'ë§', 'í•˜', 'ë“¯', 'â–ë¹„ëŠ”', '[MASK]', 'â–ê±°ì„¸', 'ì ¸', 'â–ì‹¸', 'ëŠ˜', 'íˆ', 'â–ì‹', 'ì–´', 'ê°€ëŠ”', 'â–ì•„ë‚´ê°€', 'â–ë– ì˜¬', 'ë¼', '[MASK]', '[MASK]', 'â–ë”', 'í•´ì ¸', 'â–ë‚œ', 'â–ëª°', 'ë¼', 'â–ì˜¤ëŠ˜', 'ì€', 'â–ìš´ìˆ˜', 'â–ì¢‹ì€', 'â–ë‚ ', '[SEP]', 'â–ë‚œ', 'â–ë§¨', 'ë‚ ', 'â–ì´ë ‡ê²Œ', 'â–ì‚´', 'â–ìˆ˜', 'â–ìˆìœ¼ë©´', 'â–ì–¼ë§ˆë‚˜', 'ë‚˜ëŠ”', 'â–ì„¸ê¸°', '01', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [7, 19, 20, 40, 41, 42], 'mask_label': ['â–ì ì ', 'â–ê±±', 'ì •ì€', 'â–ì¢‹', 'ì„', 'ê¹Œ']}\n"
     ]
    }
   ],
   "source": [
    "instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "\n",
    "# ìµœì¢… ë°ì´í„°ì…‹ ê²°ê³¼ í™•ì¸\n",
    "for instance in instances:\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c768d11e",
   "metadata": {},
   "source": [
    "## 4. ë°ì´í„° ì „ì²˜ë¦¬ (3) ë°ì´í„°ì…‹ ì™„ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90b563bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3957761"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT pretrain ë°ì´í„°ì…‹ì„ ìƒì„±í•´, json í¬ë§·ìœ¼ë¡œ ì €ì¥\n",
    "\n",
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "\n",
    "# line count í™•ì¸\n",
    "total = 0\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    for line in in_f:\n",
    "        total += 1\n",
    "\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ebe74d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d78b69d63c4eb6ae6b0ae71ffa0187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 lines : ['â–ì§€ë¯¸', 'â–ì¹´í„°']\n",
      "['â–ì œì„ìŠ¤', 'â–ì–¼', 'â–\"', 'ì§€', 'ë¯¸', '\"', 'â–ì¹´í„°', 'â–ì£¼ë‹ˆì–´', '(,', 'â–1924', 'ë…„', 'â–10', 'ì›”', 'â–1', 'ì¼', 'â–~', 'â–)', 'ëŠ”', 'â–ë¯¼ì£¼ë‹¹', 'â–ì¶œì‹ ', 'â–ë¯¸êµ­', 'â–39', 'ë²ˆì§¸', 'â–ëŒ€í†µë ¹', 'â–(19', '77', 'ë…„', 'â–~', 'â–1981', 'ë…„', ')', 'ì´ë‹¤', '.']\n",
      "['â–ê·¸ëŠ”', 'â–2002', 'ë…„', 'â–ë§', 'â–ì¸ê¶Œ', 'ê³¼', 'â–ì¤‘ì¬', 'â–ì—­í• ì—', 'â–ëŒ€í•œ', 'â–ê³µë¡œë¥¼', 'â–ì¸ì •ë°›ì•„', 'â–ë…¸ë²¨', 'â–í‰í™”', 'ìƒì„', 'â–ë°›ê²Œ', 'â–ë˜ì—ˆë‹¤', '.']\n",
      "\n",
      "14 lines : ['â–ìˆ˜í•™']\n",
      "['â–ìˆ˜í•™', '(', 'æ•¸', 'å­¸', ',', 'â–)', 'ì€', 'â–ì–‘', ',', 'â–êµ¬ì¡°', ',', 'â–ê³µê°„', ',', 'â–ë³€í™”', ',', 'â–ë¯¸', 'ì ', 'ë¶„', 'â–ë“±ì˜', 'â–ê°œë…ì„', 'â–ë‹¤ë£¨ëŠ”', 'â–í•™ë¬¸ì´ë‹¤', '.', 'â–í˜„ëŒ€', 'â–ìˆ˜í•™', 'ì€', 'â–í˜•ì‹', 'â–ë…¼', 'ë¦¬ë¥¼', 'â–ì´ìš©í•´ì„œ', 'â–ê³µ', 'ë¦¬ë¡œ', 'â–êµ¬ì„±ëœ', 'â–ì¶”ìƒ', 'ì ', 'â–êµ¬ì¡°ë¥¼', 'â–ì—°êµ¬í•˜ëŠ”', 'â–í•™ë¬¸', 'ìœ¼ë¡œ', 'â–ì—¬ê²¨', 'ì§€ê¸°ë„', 'â–í•œë‹¤', '.', 'â–ìˆ˜í•™', 'ì€', 'â–ê·¸', 'â–êµ¬ì¡°ì™€', 'â–ë°œì „', 'â–ê³¼ì •', 'ì—ì„œëŠ”', 'â–ìì—°', 'ê³¼í•™', 'ì—', 'â–ì†í•˜ëŠ”', 'â–ë¬¼ë¦¬', 'í•™ì„', 'â–ë¹„ë¡¯í•œ', 'â–ë‹¤ë¥¸', 'â–í•™ë¬¸', 'ë“¤ê³¼', 'â–ê¹Šì€', 'â–ì—°', 'ê´€ì„', 'â–ë§ºê³ ', 'â–ìˆë‹¤', '.', 'â–í•˜ì§€ë§Œ', ',', 'â–ì–´ëŠ', 'â–ê³¼í•™ì˜', 'â–ë¶„ì•¼', 'ë“¤ê³¼ëŠ”', 'â–ë‹¬ë¦¬', ',', 'â–ìì—°', 'ê³„ì—ì„œ', 'â–ê´€ì¸¡', 'ë˜ì§€', 'â–ì•ŠëŠ”', 'â–ê°œë…', 'ë“¤ì—', 'â–ëŒ€í•´ì„œ', 'ê¹Œì§€', 'â–ì´ë¡ ì„', 'â–ì¼ë°˜í™”', 'â–ë°', 'â–ì¶”ìƒ', 'í™”', 'ì‹œí‚¬', 'â–ìˆ˜', 'â–ìˆë‹¤ëŠ”', 'â–ì°¨ì´ê°€', 'â–ìˆë‹¤ê³ ', 'â–í•œë‹¤', '.', 'â–ìˆ˜', 'í•™ìë“¤ì€', 'â–ê·¸ëŸ¬í•œ', 'â–ê°œë…', 'ë“¤ì—', 'â–ëŒ€í•´ì„œ', 'â–ì¶”ì¸¡', 'ì„', 'â–í•˜ê³ ', ',', 'â–ì ì ˆ', 'í•˜ê²Œ', 'â–ì„ íƒ', 'ëœ', 'â–ì •ì˜', 'ì™€', 'â–ê³µë¦¬', 'ë¡œë¶€í„°ì˜', 'â–ì—„', 'ë°€í•œ', 'â–ì—°', 'ì—­ì„', 'â–í†µí•´ì„œ', 'â–ì¶”ì¸¡', 'ë“¤ì˜', 'â–ì§„', 'ìœ„ë¥¼', 'â–íŒŒì•…', 'í•œë‹¤', '.']\n",
      "['â–ìˆ˜', 'í•™ì˜', 'â–ê¸°ì´ˆë¥¼', 'â–í™•ì‹¤íˆ', 'â–ì„¸ìš°', 'ê¸°', 'â–ìœ„í•´', ',', 'â–ìˆ˜ë¦¬', 'ë…¼', 'ë¦¬', 'í•™ê³¼', 'â–ì§‘í•©', 'ë¡ ì´', 'â–ë°œì „', 'í•˜ì˜€ê³ ', ',', 'â–ì´ì™€', 'â–ë”ë¶ˆì–´', 'â–ë²”ì£¼', 'ë¡ ì´', 'â–ìµœê·¼', 'ì—ë„', 'â–ë°œì „', 'ë˜ê³ ', 'â–ìˆë‹¤', '.', 'â–â€œ', 'ê·¼', 'ë³¸', 'â–ìœ„ê¸°', 'â€', 'ë¼ëŠ”', 'â–ë§ì€', 'â–ëŒ€ëµ', 'â–1900', 'ë…„ì—ì„œ', 'â–1930', 'ë…„', 'â–ì‚¬ì´ì—', 'â–ì¼ì–´ë‚œ', ',', 'â–ìˆ˜', 'í•™ì˜', 'â–ì—„', 'ë°€í•œ', 'â–ê¸°ì´ˆ', 'ì—', 'â–ëŒ€í•œ', 'â–íƒ', 'êµ¬ë¥¼', 'â–ìƒì§•', 'ì ìœ¼ë¡œ', 'â–ë³´ì—¬ì£¼ëŠ”', 'â–ë§ì´ë‹¤', '.', 'â–ìˆ˜', 'í•™ì˜', 'â–ì—„', 'ë°€í•œ', 'â–ê¸°ì´ˆ', 'ì—', 'â–ëŒ€í•œ', 'â–ëª‡', 'â–ê°€ì§€', 'â–ì˜ê²¬', 'â–ë¶ˆ', 'ì¼', 'ì¹˜ëŠ”', 'â–ì˜¤ëŠ˜ë‚ ì—ë„', 'â–ê³„ì†ë˜ê³ ', 'â–ìˆë‹¤', '.', 'â–ìˆ˜', 'í•™ì˜', 'â–ê¸°ì´ˆ', 'ì—', 'â–ëŒ€í•œ', 'â–ìœ„', 'ê¸°ëŠ”', 'â–ê·¸', 'â–ë‹¹ì‹œ', 'â–ìˆ˜ë§ì€', 'â–ë…¼ìŸ', 'ì—', 'â–ì˜í•´', 'â–ì´‰ë°œ', 'ë˜ì—ˆìœ¼ë©°', ',', 'â–ê·¸', 'â–ë…¼ìŸ', 'ì—ëŠ”', 'â–ì¹¸', 'í† ', 'ì–´ì˜', 'â–ì§‘í•©', 'ë¡ ê³¼', 'â–ë¸Œë¼ìš°', 'ì–´', '-', 'í', 'ë² ë¥´íŠ¸', 'â–ë…¼ìŸì´', 'â–í¬í•¨ë˜ì—ˆë‹¤', '.']\n",
      "\n",
      "4 lines : ['â–ìˆ˜í•™', 'â–ìƒìˆ˜']\n",
      "['â–ìˆ˜í•™ì—ì„œ', 'â–ìƒìˆ˜', 'ë€', 'â–ê·¸', 'â–ê°’ì´', 'â–ë³€í•˜ì§€', 'â–ì•ŠëŠ”', 'â–ë¶ˆë³€', 'ëŸ‰ìœ¼ë¡œ', ',', 'â–ë³€', 'ìˆ˜ì˜', 'â–ë°˜ëŒ€', 'ë§', 'ì´ë‹¤', '.', 'â–ë¬¼ë¦¬', 'â–ìƒìˆ˜', 'ì™€ëŠ”', 'â–ë‹¬ë¦¬', ',', 'â–ìˆ˜í•™', 'â–ìƒ', 'ìˆ˜ëŠ”', 'â–ë¬¼ë¦¬ì ', 'â–ì¸¡ì •', 'ê³¼ëŠ”', 'â–ìƒê´€ì—†ì´', 'â–ì •ì˜ëœë‹¤', '.']\n",
      "['â–íŠ¹ì •', 'â–ìˆ˜í•™', 'â–ìƒìˆ˜', ',', 'â–ì˜ˆë¥¼', 'â–ë“¤ë©´', 'â–ê³¨', 'ë¡¬', '-', 'ë”•', 'ë§¨', 'â–ìƒìˆ˜', ',', 'â–í”„ë‘', 'ì„¸', 'ì¦ˆ', '-', 'ë¡œ', 'ë¹ˆ', 'ìŠ¨', 'â–ìƒìˆ˜', ',', 'â–formula', '_1', ',', 'â–ë ˆ', 'ë¹„', 'â–ìƒìˆ˜', 'ê°™ì€', 'â–ìƒ', 'ìˆ˜ëŠ”', 'â–ë‹¤ë¥¸', 'â–ìˆ˜í•™', 'ìƒìˆ˜', 'â–ë˜ëŠ”', 'â–í•¨ìˆ˜', 'ì™€', 'â–ì•½í•œ', 'â–ìƒê´€', 'ê´€ê³„', 'â–ë˜ëŠ”', 'â–ê°•í•œ', 'â–ìƒê´€', 'ê´€ê³„ë¥¼', 'â–ê°–ëŠ”ë‹¤', '.']\n",
      "\n",
      "10 lines : ['â–ë¬¸í•™']\n",
      "['â–ë¬¸í•™', '(', 'æ–‡', 'å­¸', ')', 'ì€', 'â–ì–¸ì–´ë¥¼', 'â–ì˜ˆìˆ ì ', 'â–í‘œí˜„ì˜', 'â–ì œ', 'ì¬ë¡œ', 'â–ì‚¼ì•„', 'â–ìƒˆë¡œìš´', 'â–ì˜ë¯¸ë¥¼', 'â–ì°½ì¶œ', 'í•˜ì—¬', ',', 'â–ì¸ê°„ê³¼', 'â–ì‚¬íšŒë¥¼', 'â–ì§„ì‹¤', 'ë˜ê²Œ', 'â–ë¬˜ì‚¬', 'í•˜ëŠ”', 'â–ì˜ˆìˆ ì˜', 'â–í•˜ìœ„', 'ë¶„ì•¼', 'ì´ë‹¤', '.', 'â–ê°„ë‹¨í•˜ê²Œ', 'â–ì„¤ëª…', 'í•˜ë©´', ',', 'â–ì–¸ì–´ë¥¼', 'â–í†µí•´', 'â–ì¸ê°„ì˜', 'â–ì‚¶ì„', 'â–ë¯¸', 'ì ', '(', 'ç¾', 'çš„', ')', 'ìœ¼ë¡œ', 'â–í˜•ìƒ', 'í™”í•œ', 'â–ê²ƒì´ë¼ê³ ', 'â–ë³¼', 'â–ìˆ˜', 'â–ìˆë‹¤', '.', 'â–ë¬¸í•™', 'ì€', 'â–ì›ë˜', 'â–ë¬¸ì˜ˆ', '(', 'æ–‡', 'è—', ')', 'ë¼ê³ ', 'â–ë¶€ë¥´ëŠ”', 'â–ê²ƒì´', 'â–ì˜³', 'ìœ¼ë©°', ',', 'â–ë¬¸í•™ì„', 'â–í•™ë¬¸ì˜', 'â–ëŒ€ìƒ', 'ìœ¼ë¡œì„œ', 'â–íƒêµ¬', 'í•˜ëŠ”', 'â–í•™ë¬¸ì˜', 'â–ëª…ì¹­', 'â–ì—­ì‹œ', 'â–ë¬¸ì˜ˆ', 'í•™', 'ì´ë‹¤', '.', 'â–ë¬¸ì˜ˆ', 'í•™ì€', 'â–ìŒì•…', 'ì‚¬', 'í•™', ',', 'â–ë¯¸ìˆ ', 'ì‚¬', 'í•™', 'â–ë“±ê³¼', 'â–í•¨ê»˜', 'â–ì˜ˆìˆ ', 'í•™ì˜', 'â–í•µì‹¬', 'ë¶„ì•¼', 'ë¡œì„œ', 'â–ì¸ë¬¸', 'í•™ì˜', 'â–í•˜ìœ„', 'ë²”', 'ì£¼ì—', 'â–í¬í•¨ëœë‹¤', '.']\n",
      "['â–ë°˜ì˜', 'ë¡ ì ', 'â–ê´€', 'ì ì—', 'â–ì˜í•œ', 'â–ê°', 'ìƒì€', 'â–ì‘í’ˆì„', 'â–ì°½ì‘', 'ëœ', 'â–ë‹¹ì‹œ', 'â–ì‹œëŒ€', 'â–ì •', 'í™©', 'ê³¼', 'â–ì—°ê²°', 'ì‹œì¼œ', 'â–ê°ìƒ', 'í•˜ëŠ”', 'â–ì…ì¥', 'ì´ê³ ', ',', 'â–ë‚´ì¬', 'ì ', 'â–ê´€', 'ì ì˜', 'â–ê°', 'ìƒì€', 'â–ì‘í’ˆì˜', 'â–í˜•ì‹', ',', 'â–ë‚´ìš©ì—', 'â–êµ­í•œ', 'í•˜ì—¬', 'â–ê°ìƒ', 'í•˜ëŠ”', 'â–ê²ƒì´ë‹¤', '.', 'â–í‘œí˜„', 'ë¡ ì ', 'â–ê´€', 'ì ì˜', 'â–ê°', 'ìƒì€', 'â–ì‘ê°€ì˜', 'â–ì „ê¸°', 'ì ', 'â–ì‚¬ì‹¤ê³¼', 'â–ì‘í’ˆì„', 'â–ì—°ê²°', 'ì‹œì¼œ', 'â–ê°ìƒ', 'í•˜ëŠ”', 'â–ê²ƒì´ê³ ', ',', 'â–ìˆ˜ìš©', 'ë¡ ì ', 'â–ê´€', 'ì ì˜', 'â–ê°', 'ìƒì€', 'â–ë…', 'ìì™€', 'â–ì‘í’ˆì„', 'â–ì—°ê²°', 'ì‹œì¼œ', 'â–ê°ìƒ', 'í•˜ëŠ”', 'â–ê²ƒì„', 'â–ë§í•œë‹¤', '.']\n",
      "\n",
      "10 lines : ['â–ë‚˜ë¼', 'â–ëª©ë¡']\n",
      "['â–ì´', 'â–ë¬¸ì„œëŠ”', 'â–ë‚˜ë¼', 'â–ëª©ë¡', 'ì´ë©°', ',', 'â–ì „', 'â–ì„¸ê³„', 'â–20', '6', 'ê°œ', 'â–ë‚˜ë¼ì˜', 'â–ê°', 'â–í˜„í™©', 'ê³¼', 'â–ì£¼ê¶Œ', 'â–ìŠ¹ì¸', 'â–ì •ë³´ë¥¼', 'â–ê°œ', 'ìš”', 'â–í˜•íƒœë¡œ', 'â–ë‚˜ì—´', 'í•˜ê³ ', 'â–ìˆë‹¤', '.']\n",
      "['â–ìœ„', 'â–ëª©ë¡ì—', 'â–í¬í•¨ë˜ì§€', 'â–ì•Šì€', 'â–ë‹¤ìŒ', 'â–êµ­ê°€ëŠ”', 'â–ëª¬í…Œ', 'ë¹„', 'ë°ì˜¤', 'â–í˜‘ì•½', 'ì˜', 'â–ëª¨ë“ ', 'â–ì¡°ê±´ì„', 'â–ë§Œì¡±', 'í•˜ì§€', 'â–ëª»', 'í•˜ê±°ë‚˜', ',', 'â–ìì£¼', 'ì ì´ê³ ', 'â–ë…ë¦½', 'ì ', 'ì„ì„', 'â–ì£¼ì¥', 'í•˜ì§€', 'â–ì•ŠëŠ”', 'â–êµ­ê°€ì´ë‹¤', '.']\n",
      "\n",
      "['â–í™”í•™']\n",
      "['â–í™”í•™', '(', 'åŒ–', 'å­¸', ',', 'â–)', 'ì€', 'â–ë¬¼ì§ˆì˜', 'â–ì„±ì§ˆ', ',', 'â–ì¡°ì„±', ',', 'â–êµ¬ì¡°', ',', 'â–ë³€í™”', 'â–ë°', 'â–ê·¸ì—', 'â–ìˆ˜ë°˜', 'í•˜ëŠ”', 'â–ì—ë„ˆì§€ì˜', 'â–ë³€í™”ë¥¼', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ìì—°ê³¼', 'í•™ì˜', 'â–í•œ', 'â–ë¶„ì•¼ì´ë‹¤', '.', 'â–ë¬¼ë¦¬í•™', 'ë„', 'â–ì—­ì‹œ', 'â–ë¬¼ì§ˆì„', 'â–ë‹¤ë£¨ëŠ”', 'â–í•™ë¬¸', 'ì´ì§€ë§Œ', ',', 'â–ë¬¼ë¦¬í•™', 'ì´', 'â–ì›', 'ì†Œì™€', 'â–í™”í•©', 'ë¬¼ì„', 'â–ëª¨ë‘', 'â–í¬í•¨í•œ', 'â–ë¬¼ì²´ì˜', 'â–ìš´ë™ê³¼', 'â–ì—ë„ˆì§€', ',', 'â–ì—´', 'ì ', 'Â·', 'ì „ê¸°', 'ì ', 'Â·', 'ê´‘', 'í•™ì ', 'Â·', 'ê¸°ê³„', 'ì ', 'â–ì†', 'ì„±ì„', 'â–ë‹¤ë£¨ê³ ', 'â–ì´ëŸ¬í•œ', 'â–í˜„ìƒ', 'ìœ¼ë¡œë¶€í„°', 'â–í†µì¼ëœ', 'â–ì´ë¡ ì„', 'â–êµ¬ì¶•', 'í•˜ë ¤ëŠ”', 'â–ê²ƒê³¼ëŠ”', 'â–ë‹¬ë¦¬', 'â–í™”í•™', 'ì—ì„œëŠ”', 'â–ë¬¼ì§ˆ', 'â–ìì²´ë¥¼', 'â–ì—°êµ¬', 'â–ëŒ€ìƒìœ¼ë¡œ', 'â–í•œë‹¤', '.', 'â–í™”í•™', 'ì€', 'â–ì´ë¯¸', 'â–ì¡´ì¬í•˜ëŠ”', 'â–ë¬¼ì§ˆì„', 'â–ì´ìš©í•˜ì—¬', 'â–íŠ¹ì •í•œ', 'â–ëª©ì ì—', 'â–ë§ëŠ”', 'â–ìƒˆë¡œìš´', 'â–ë¬¼ì§ˆì„', 'â–í•©ì„±', 'í•˜ëŠ”', 'â–ê¸¸ì„', 'â–ì œê³µí•˜ë©°', ',', 'â–ì´ëŠ”', 'â–ë†ì‘', 'ë¬¼ì˜', 'â–ì¦', 'ì‚°', ',', 'â–ì§ˆë³‘ì˜', 'â–ì¹˜ë£Œ', 'â–ë°', 'â–ì˜ˆë°©', ',', 'â–ì—ë„ˆì§€', 'â–íš¨ìœ¨', 'â–ì¦ëŒ€', ',', 'â–í™˜ê²½', 'ì˜¤', 'ì—¼', 'â–ê°ì†Œ', 'â–ë“±', 'â–ì—¬ëŸ¬', 'â–ê°€ì§€', 'â–ì´', 'ì ì„', 'â–ì œê³µí•œë‹¤', '.']\n",
      "['â–ìœ ê¸°', 'í™”', 'í•™ì€', 'â–íƒ„', 'ì†Œë¡œ', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì€', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜', 'â–ì§€ê¸ˆì€', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì˜', 'â–ë²”ìœ„ê°€', 'â–í¬ê²Œ', 'â–ë„“', 'ì–´ì ¸', 'â–íƒ„ì†Œ', 'â–ì‚¬ìŠ¬', 'â–ë˜ëŠ”', 'â–íƒ„ì†Œ', 'â–ê³ ', 'ë¦¬ë¥¼', 'â–ê°€ì§„', 'â–ëª¨ë“ ', 'â–í™”í•©', 'ë¬¼ì„', 'â–ëœ»í•œë‹¤', '.', 'â–ìœ ê¸°', 'í™”', 'í•™ì˜', 'â–ì˜¤ëœ', 'â–ê´€ì‹¬', 'ì‚¬ëŠ”', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì˜', 'â–í•©ì„±', 'â–ë©”ì»¤ë‹ˆì¦˜', 'ì´ë‹¤', '.', 'â–í˜„ëŒ€ì—', 'â–ë“¤ì–´ì„œ', 'â–í•µ', 'ìê¸°', 'â–ê³µëª…', 'ë²•ê³¼', 'â–X', 'ì„ ', 'â–ê²°ì •', 'í•™', 'â–ë“±ì´', 'â–ê°œë°œë˜ì–´', 'â–ìœ ê¸°', 'â–í™”í•©ë¬¼', 'â–ë¶„ì„', 'ì—', 'â–ìˆì–´ì„œ', 'â–ë§¤ìš°', 'â–ì¤‘ìš”í•œ', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', 'â–ë“±ë„', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.']\n"
     ]
    }
   ],
   "source": [
    "# ìœ„í‚¤ê°€ ì£¼ì œë³„ë¡œ ì˜ ë‚˜ëˆ ì§€ëŠ”ì§€ ì—¬ë¶€ í™•ì¸\n",
    "count = 5\n",
    "\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = []  # ë‹¨ë½ ë‹¨ìœ„ë¡œ ë¬¸ì„œ ì €ì¥\n",
    "    for line in tqdm(in_f, total=total):\n",
    "        line = line.strip()\n",
    "        if line == \"\":  # lineì´ ë¹ˆì¤„ ì¼ ê²½ìš° (ìƒˆë¡œìš´ ë‹¨ë½ì„ ì˜ë¯¸ í•¨)\n",
    "            if 0 < len(doc):\n",
    "                if 0 < count:\n",
    "                    count -= 1\n",
    "                    print(len(doc), \"lines :\", doc[0])\n",
    "                    print(doc[1])\n",
    "                    print(doc[-1])\n",
    "                    print()\n",
    "                else:\n",
    "                    break\n",
    "                doc = []\n",
    "        else:  # docì— ì €ì¥\n",
    "            pieces = vocab.encode_as_pieces(line)\n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "    if 0 < len(doc):  # ë§ˆì§€ë§‰ì— ì²˜ë¦¬ë˜ì§€ ì•Šì€ docê°€ ìˆëŠ” ê²½ìš°\n",
    "        print(doc[0])\n",
    "        print(doc[1])\n",
    "        print(doc[-1])\n",
    "        doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8462b6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9bd1748f2a48efb10ed24105e043b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: 21 instances: 10\n",
      "{'tokens': ['[CLS]', 'â–X', 'ì„ ', '[MASK]', '[MASK]', 'â–ë“±ì´', 'â–ê°œë°œë˜ì–´', '[MASK]', 'â–í™”í•©ë¬¼', 'â–ë¶„ì„', 'ì—', 'â–ìˆì–´ì„œ', 'â–ë§¤ìš°', 'â–ì¤‘ìš”í•œ', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', '[MASK]', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', '[MASK]', '[MASK]', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì€', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜', 'â–ì§€ê¸ˆì€', 'â–ìœ ê¸°', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [3, 4, 7, 25, 26, 27, 28, 36, 37], 'mask_label': ['â–ê²°ì •', 'í•™', 'â–ìœ ê¸°', 'â–ë“±ë„', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–íƒ„', 'ì†Œë¡œ']}\n",
      "{'tokens': ['[CLS]', 'â–X', 'ì„ ', 'â–ê²°ì •', 'í•™', 'â–ë“±ì´', 'â–ê°œë°œë˜ì–´', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'â–ìˆì–´ì„œ', 'â–ë§¤ìš°', 'â–ì¤‘ìš”í•œ', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', '[MASK]', '[MASK]', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', 'â–ë“±ë„', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', 'â–íƒ„', 'ì†Œë¡œ', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì€', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜', 'â–ì§€ê¸ˆì€', 'â–ìœ ê¸°', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [7, 8, 9, 10, 17, 18, 26, 27, 28], 'mask_label': ['â–ìœ ê¸°', 'â–í™”í•©ë¬¼', 'â–ë¶„ì„', 'ì—', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ']}\n",
      "\n",
      "doc: 14 instances: 7\n",
      "{'tokens': ['[CLS]', 'â–X', 'ì„ ', 'â–ê²°ì •', 'í•™', 'â–ë“±ì´', 'â–ê°œë°œë˜ì–´', 'â–ìœ ê¸°', 'â–í™”í•©ë¬¼', 'â–ë¶„ì„', 'ì—', '[MASK]', '[MASK]', 'â–ì¤‘ìš”í•œ', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', 'â–íƒ„', 'ì†Œë¡œ', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', '[MASK]', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì€', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', '[MASK]', '[MASK]', 'â–ì§€ê¸ˆì€', 'â–ìœ ê¸°', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [11, 12, 25, 26, 27, 28, 41, 59, 60], 'mask_label': ['â–ìˆì–´ì„œ', 'â–ë§¤ìš°', 'â–ë“±ë„', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜']}\n",
      "{'tokens': ['[CLS]', 'â–X', 'ì„ ', 'â–ê²°ì •', 'í•™', 'â–ë“±ì´', '[MASK]', 'â–ë‹¬ë¦°ë‹¤', 'â–í™”í•©ë¬¼', 'â–ë¶„ì„', 'ì—', 'â–ìˆì–´ì„œ', 'â–ë§¤ìš°', 'â–ì¤‘ìš”í•œ', '[MASK]', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', 'â–ë“±ë„', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', 'â–íƒ„', 'ì†Œë¡œ', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜', 'â–ì§€ê¸ˆì€', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [6, 7, 14, 47, 48, 49, 50, 51, 62], 'mask_label': ['â–ê°œë°œë˜ì–´', 'â–ìœ ê¸°', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì€', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ìœ ê¸°']}\n",
      "\n",
      "doc: 4 instances: 2\n",
      "{'tokens': ['[CLS]', 'â–X', 'ì„ ', 'â–ê²°ì •', 'í•™', '[MASK]', '[MASK]', 'â–ìœ ê¸°', '[MASK]', 'â–ë¶„ì„', 'ì—', '[MASK]', 'â–ë§¤ìš°', 'â–ì¤‘ìš”í•œ', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', 'â–ë“±ë„', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', '[MASK]', '[MASK]', '[MASK]', 'â–íƒ„', 'ì†Œë¡œ', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì€', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', '[MASK]', '[MASK]', 'â–ì§€ê¸ˆì€', 'â–ìœ ê¸°', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [5, 6, 8, 11, 33, 34, 35, 59, 60], 'mask_label': ['â–ë“±ì´', 'â–ê°œë°œë˜ì–´', 'â–í™”í•©ë¬¼', 'â–ìˆì–´ì„œ', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜']}\n",
      "{'tokens': ['[CLS]', 'â–X', 'ì„ ', 'â–ê²°ì •', 'í•™', 'â–ë“±ì´', 'â–ê°œë°œë˜ì–´', 'â–ìœ ê¸°', 'â–í™”í•©ë¬¼', 'â–ë¶„ì„', 'ì—', 'â–ìˆì–´ì„œ', 'â–ë§¤ìš°', 'â–ì¤‘ìš”í•œ', 'â–ë°©ë²•ìœ¼ë¡œ', '[MASK]', '[MASK]', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', 'â–ë“±ë„', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', 'â–íƒ„', 'ì†Œë¡œ', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', 'â–ì—°êµ¬í•˜ëŠ”', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'â–ì›ë˜', '[MASK]', 'â–í™”í•©', 'ë¬¼ì€', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜', 'â–ì§€ê¸ˆì€', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [15, 16, 25, 42, 43, 44, 45, 47, 62], 'mask_label': ['â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–ë“±ë„', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ìœ ê¸°', 'â–ìœ ê¸°']}\n",
      "\n",
      "doc: 10 instances: 5\n",
      "{'tokens': ['[CLS]', 'â–X', 'ì„ ', 'â–ê²°ì •', 'í•™', 'â–ë“±ì´', 'â–ê°œë°œë˜ì–´', '[MASK]', '[MASK]', 'â–ë¶„ì„', 'ì—', 'â–ìˆì–´ì„œ', 'â–ë§¤ìš°', 'â–ì¤‘ìš”í•œ', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', 'â–ë“±ë„', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', 'â–íƒ„', 'ì†Œë¡œ', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì€', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', '[MASK]', '[MASK]', 'â–ì§€ê¸ˆì€', 'â–ìœ ê¸°', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [7, 8, 39, 40, 52, 53, 59, 60, 62], 'mask_label': ['â–ìœ ê¸°', 'â–í™”í•©ë¬¼', 'â–í™”í•©', 'ë¬¼ì„', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜', 'â–ìœ ê¸°']}\n",
      "{'tokens': ['[CLS]', 'â–X', 'ì„ ', 'â–ê²°ì •', 'í•™', 'â–ë“±ì´', 'â–ê°œë°œë˜ì–´', 'â–ìœ ê¸°', '[MASK]', '[MASK]', '[MASK]', 'â–ìˆì–´ì„œ', 'â–ë§¤ìš°', 'â–ì¤‘ìš”í•œ', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', '[MASK]', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', 'â–íƒ„', 'ì†Œë¡œ', '[MASK]', 'â–í™”í•©', 'ë¬¼ì„', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', 'â–ìœ ê¸°', '[MASK]', '[MASK]', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', '[MASK]', '[MASK]', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜', 'â–ì§€ê¸ˆì€', 'â–ìœ ê¸°', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [8, 9, 10, 25, 38, 48, 49, 57, 58], 'mask_label': ['â–í™”í•©ë¬¼', 'â–ë¶„ì„', 'ì—', 'â–ë“±ë„', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì€', 'â–í™”í•©', 'ë¬¼ì„']}\n",
      "\n",
      "doc: 10 instances: 5\n",
      "{'tokens': ['[CLS]', 'â–X', 'ì„ ', 'â–ê²°ì •', 'í•™', 'â–ë“±ì´', 'â–ê°œë°œë˜ì–´', 'â–ìœ ê¸°', 'â–í™”í•©ë¬¼', 'â–ë¶„ì„', 'ì—', 'â–ìˆì–´ì„œ', 'â–ë§¤ìš°', '[MASK]', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–í”Œë¼ìŠ¤í‹±', ',', '[MASK]', '[MASK]', '[MASK]', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', '[MASK]', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', 'â–íƒ„', 'ì†Œë¡œ', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì€', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜', '[MASK]', 'â–ìœ ê¸°', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [13, 19, 20, 21, 22, 23, 24, 25, 61], 'mask_label': ['â–ì¤‘ìš”í•œ', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', 'â–ë“±ë„', 'â–ì§€ê¸ˆì€']}\n",
      "{'tokens': ['[CLS]', 'â–X', 'ì„ ', 'â–ê²°ì •', 'í•™', 'â–ë“±ì´', 'â–ê°œë°œë˜ì–´', 'â–ìœ ê¸°', 'â–í™”í•©ë¬¼', 'â–ë¶„ì„', 'ì—', 'â–ìˆì–´ì„œ', 'â–ë§¤ìš°', 'â–ì¤‘ìš”í•œ', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', 'â–ë“±ë„', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', 'â–íƒ„', 'ì†Œë¡œ', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', '[MASK]', 'â–ìœ ê¸°', '[MASK]', '[MASK]', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜', 'â–ì§€ê¸ˆì€', 'â–ìœ ê¸°', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [15, 16, 42, 43, 44, 45, 46, 48, 49], 'mask_label': ['â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', 'â–í™”í•©', 'ë¬¼ì€']}\n",
      "\n",
      "doc: 31 instances: 15\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', 'â–ê²°ì •', 'í•™', 'â–ë“±ì´', 'â–ê°œë°œë˜ì–´', 'â–ìœ ê¸°', 'â–í™”í•©ë¬¼', 'â–ë¶„ì„', 'ì—', 'â–ìˆì–´ì„œ', 'â–ë§¤ìš°', '[MASK]', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', 'â–ë“±ë„', '[MASK]', '[MASK]', '[MASK]', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', 'â–íƒ„', 'ì†Œë¡œ', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', 'â–ì—°êµ¬í•˜ëŠ”', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì€', 'â–ì‹ë¬¼', 'ì´ë‚˜', '[MASK]', '[MASK]', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜', 'â–ì§€ê¸ˆì€', 'â–ìœ ê¸°', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 11, 13, 26, 27, 28, 52, 53], 'mask_label': ['â–X', 'ì„ ', 'â–ìˆì–´ì„œ', 'â–ì¤‘ìš”í•œ', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë™ë¬¼', 'ë¡œë¶€í„°']}\n",
      "{'tokens': ['[CLS]', 'â–X', 'ì„ ', '[MASK]', '[MASK]', 'â–ë“±ì´', 'â–ê°œë°œë˜ì–´', 'â–ìœ ê¸°', 'â–í™”í•©ë¬¼', 'â–ë¶„ì„', 'ì—', 'â–ìˆì–´ì„œ', '[MASK]', '[MASK]', 'â–ë°©ë²•ìœ¼ë¡œ', 'â–ìë¦¬ì¡ì•˜ë‹¤', '.', 'â–í”Œë¼ìŠ¤í‹±', ',', 'â–í•©ì„±', 'ì„¬ìœ ', 'ë“±ì˜', 'â–ê³ ë¶„', 'ì', 'ë¬¼ì§ˆ', 'â–ë“±ë„', 'â–ìœ ê¸°', 'í™”', 'í•™ì—ì„œ', 'â–ë‹¤ë£¨', 'ì–´ì§„ë‹¤', '.', '[SEP]', 'â–ìœ ê¸°', 'í™”', 'í•™ì€', '[MASK]', '[MASK]', 'â–ì´ë£¨ì–´ì§„', 'â–í™”í•©', 'ë¬¼ì„', '[MASK]', 'â–ë¶„', 'ê³¼', 'ì´ë‹¤', '.', 'â–ì›ë˜', 'â–ìœ ê¸°', 'â–í™”í•©', 'ë¬¼ì€', 'â–ì‹ë¬¼', 'ì´ë‚˜', 'â–ë™ë¬¼', 'ë¡œë¶€í„°', 'â–ì¶”ì¶œ', 'í•´', 'ë‚¸', 'â–í™”í•©', 'ë¬¼ì„', 'â–ëœ»', 'í•˜ì˜€ìœ¼ë‚˜', 'â–ì§€ê¸ˆì€', 'â–ìœ ê¸°', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [3, 4, 12, 13, 36, 37, 41, 48, 49], 'mask_label': ['â–ê²°ì •', 'í•™', 'â–ë§¤ìš°', 'â–ì¤‘ìš”í•œ', 'â–íƒ„', 'ì†Œë¡œ', 'â–ì—°êµ¬í•˜ëŠ”', 'â–í™”í•©', 'ë¬¼ì€']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instance ìƒì„± ê¸°ëŠ¥ í™•ì¸\n",
    "count = 5\n",
    "\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = []  # ë‹¨ë½ ë‹¨ìœ„ë¡œ ë¬¸ì„œ ì €ì¥\n",
    "    for line in tqdm(in_f, total=total):\n",
    "        line = line.strip()\n",
    "        if line == \"\":  # lineì´ ë¹ˆì¤„ ì¼ ê²½ìš° (ìƒˆë¡œìš´ ë‹¨ë½ì„ ì˜ë¯¸ í•¨)\n",
    "            if 0 < len(doc):\n",
    "                instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "                # save\n",
    "                print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "                print(instances[0])\n",
    "                print(instances[-1])\n",
    "                print()\n",
    "                doc = []\n",
    "                if 0 < count:  # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œ ë¶€ë¶„ ì²˜ë¦¬ í•¨\n",
    "                    count -= 1\n",
    "                else:\n",
    "                    break\n",
    "        else:  # docì— ì €ì¥\n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "    if 0 < len(doc):  # ë§ˆì§€ë§‰ì— ì²˜ë¦¬ë˜ì§€ ì•Šì€ docê°€ ìˆëŠ” ê²½ìš°\n",
    "        instances = create_pretrain_instances(doc, 128)\n",
    "        # save\n",
    "        print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "        print(instances[0])\n",
    "        print(instances[-1])\n",
    "        print()\n",
    "        doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3d1d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\" pretrain ë°ì´í„° ìƒì„± \"\"\"\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "        for instance in instances:\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "\n",
    "    # íŠ¹ìˆ˜ë¬¸ì 7ê°œë¥¼ ì œì™¸í•œ vocab_list ìƒì„±\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):\n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "\n",
    "    # line count í™•ì¸\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            doc = []\n",
    "            for line in tqdm(in_f, total=line_cnt):\n",
    "                line = line.strip()\n",
    "                if line == \"\":  # lineì´ ë¹ˆì¤„ ì¼ ê²½ìš° (ìƒˆë¡œìš´ ë‹¨ë½ì„ ì˜ë¯¸ í•¨)\n",
    "                    if 0 < len(doc):\n",
    "                        save_pretrain_instances(out_f, doc)\n",
    "                        doc = []\n",
    "                else:  # lineì´ ë¹ˆì¤„ì´ ì•„ë‹ ê²½ìš° tokenize í•´ì„œ docì— ì €ì¥\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "            if 0 < len(doc):  # ë§ˆì§€ë§‰ì— ì²˜ë¦¬ë˜ì§€ ì•Šì€ docê°€ ìˆëŠ” ê²½ìš°\n",
    "                save_pretrain_instances(out_f, doc)\n",
    "                doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66a179e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5ad2aae1394edda1e8e2894a724c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrain_json_path = os.getenv('HOME')+'/aiffel/bert_pretrain/data/bert_pre_train.json'\n",
    "\n",
    "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "744f87db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862285"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¼ì¸ìˆ˜\n",
    "total = 0\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95c86e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 0,\n",
       " 0,\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seq = 128\n",
    "# [CLS], tokens_a, [SEP], tokens_b, [SEP]\n",
    "max_seq = n_seq - 3\n",
    "\n",
    "# ë§Œì•½ ì¼ë°˜ì ì¸ Numpy Arrayì—ë‹¤ ë°ì´í„°ë¥¼ ë¡œë”©í•œë‹¤ë©´ ì´ë ‡ê²Œ ë˜ê² ì§€ë§Œ\n",
    "# enc_tokens = np.zeros((total, n_seq), np.int32)\n",
    "# dec_tokens = np.zeros((total, n_seq), np.int32)\n",
    "# labels_nsp = np.zeros((total,), np.int32)\n",
    "# labels_mlm = np.zeros((total, n_seq), np.int32)\n",
    "\n",
    "# np.memmapì„ ì‚¬ìš©í•˜ë©´ ë©”ëª¨ë¦¬ë¥¼ ì ì€ ë©”ëª¨ë¦¬ì—ì„œë„ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ê°€ ê°€ëŠ¥ í•¨\n",
    "enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "\n",
    "enc_tokens[0], enc_tokens[-1], segments[0], segments[-1], labels_nsp[0], labels_nsp[-1], labels_mlm[0], labels_mlm[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d627e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7857c23e149640079261834b26429814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/862285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['[CLS]', 'â–íƒœì–´ë‚¬ë‹¤', '.', 'â–ì¡°ì§€ì•„', 'â–ê³µê³¼', 'ëŒ€í•™êµë¥¼', 'â–ì¡¸ì—…í•˜ì˜€ë‹¤', '.', 'â–ê·¸', '[MASK]', 'â–í•´êµ°ì—', 'â–ë“¤ì–´ê°€', 'â–ì „í•¨', 'Â·', 'ì›ì', 'ë ¥', 'Â·', 'ì ', 'ìˆ˜', 'í•¨ì˜', 'â–ìŠ¹ë¬´', 'ì›ìœ¼ë¡œ', 'â–ì¼í•˜ì˜€ë‹¤', '.', 'â–1953', 'ë…„', 'â–ë¯¸êµ­', 'â–í•´êµ°', 'â–ëŒ€', 'ìœ„ë¡œ', 'â–ì˜ˆí¸', 'í•˜ì˜€ê³ ', 'â–ì´í›„', 'â–ë•…', 'ì½©', 'Â·', 'ë©´', 'í™”', 'â–ë“±ì„', 'â–ê°€', 'ê¿”', 'â–ë§ì€', 'â–ëˆì„', 'â–ë²Œ', 'ì—ˆë‹¤', '.', 'â–ê·¸ì˜', 'â–ë³„ëª…ì´', '[MASK]', '[MASK]', '[MASK]', 'â–ë†ë¶€', '\"', 'â–(', 'P', 'ean', 'ut', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'â–ì•Œë ¤ì¡Œë‹¤', '.', '[SEP]', 'â–ëŠ¦', 'ë˜ë©´ì„œ', '[MASK]', 'â–ì£¼', 'â–ìƒì›', 'â–ì˜ì›', 'â–ì„ ê±°ì—ì„œ', 'â–ë‚™ì„ ', 'í•˜ë‚˜', 'â–ê·¸', 'â–ì„ ê±°ê°€', 'â–ë¶€ì •', 'ì„ ê±°', 'â–', 'ì˜€', 'ìŒì„', 'â–ì…ì¦', 'í•˜ê²Œ', 'â–ë˜ì–´', 'â–ë‹¹ì„ ', 'ë˜ê³ ', ',', 'â–1966', 'ë…„', 'â–ì¡°ì§€ì•„', 'â–ì£¼', 'â–ì§€ì‚¬', 'â–ì„ ê±°ì—', 'â–ë‚™ì„ ', 'í•˜ì§€ë§Œ', '[MASK]', '[MASK]', 'â–ì¡°ì§€ì•„', 'â–ì£¼', 'â–ì§€', 'ì‚¬ë¥¼', 'â–ì—­ì„í–ˆë‹¤', '.', '[MASK]', 'â–ë˜ê¸°', 'â–ì „', 'â–ì¡°ì§€ì•„', 'ì£¼', 'â–ìƒì›ì˜', 'ì›ì„', 'â–ë‘', 'ë²ˆ', 'â–ì—°', 'ì„', 'í–ˆìœ¼ë©°', ',', 'â–1971', 'ë…„ë¶€í„°', '[MASK]', '[MASK]', 'â–ì¡°ì§€ì•„', 'â–ì§€', 'ì‚¬ë¡œ', 'â–ê·¼ë¬´í–ˆë‹¤', '.', 'â–ì¡°ì§€ì•„', '[MASK]', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [9, 48, 49, 50, 57, 58, 59, 60, 61, 65, 66, 67, 95, 96, 103, 118, 119, 126], 'mask_label': ['â–í›„', 'â–\"', 'ë•…', 'ì½©', 'â–F', 'ar', 'mer', ')', 'ë¡œ', 'â–1962', 'ë…„', 'â–ì¡°ì§€ì•„', 'â–1970', 'ë…„', 'â–ëŒ€í†µë ¹ì´', 'â–1975', 'ë…„ê¹Œì§€', 'â–ì£¼ì§€']}\n",
      "enc_token: [5, 1605, 27599, 5551, 14146, 15991, 8637, 27599, 13, 6, 25987, 2247, 15033, 27873, 14475, 27813, 27873, 28196, 27636, 10185, 16285, 1232, 22935, 27599, 4777, 27625, 243, 2780, 14, 1509, 22095, 414, 165, 1697, 28290, 27873, 27703, 27683, 593, 21, 29007, 399, 5540, 813, 17, 27599, 307, 16905, 6, 6, 6, 19041, 27718, 98, 27878, 15784, 2543, 6, 6, 6, 6, 6, 4578, 27599, 4, 4427, 1239, 6, 37, 11234, 2378, 5249, 9858, 3294, 13, 20590, 2386, 2163, 27596, 27671, 969, 8047, 173, 607, 2387, 317, 27604, 3926, 27625, 5551, 37, 18995, 8198, 9858, 1447, 6, 6, 5551, 37, 18, 451, 4267, 27599, 6, 6436, 25, 5551, 27646, 18205, 928, 157, 27821, 61, 27773, 530, 27604, 3372, 523, 6, 6, 5551, 18, 982, 13264, 27599, 5551, 6, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mlm: [    0     0     0     0     0     0     0     0     0    81     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "   103 28313 28290     0     0     0     0     0     0   309   337  5771\n",
      " 27616 27603     0     0     0  3715 27625  5551     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0  1921\n",
      " 27625     0     0     0     0     0     0  4864     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0  3409   673\n",
      "     0     0     0     0     0     0  5053     0]\n",
      "\n",
      "{'tokens': ['[CLS]', 'â–1976', 'ë…„', 'â–ëŒ€í†µë ¹', 'â–ì„ ê±°ì—', 'â–ë¯¼ì£¼ë‹¹', 'â–í›„ë³´ë¡œ', 'â–ì¶œë§ˆí•˜ì—¬', 'â–ë„ë•', 'ì£¼ì˜', 'â–ì •ì±…ìœ¼ë¡œ', 'â–ë‚´ì„¸ì›Œ', ',', '[MASK]', '[MASK]', 'â–ëˆ„ë¥´ê³ ', 'â–ë‹¹ì„ ë˜ì—ˆë‹¤', '.', 'â–ì¹´í„°', 'â–ëŒ€í†µë ¹ì€', 'â–ì—ë„ˆì§€', 'â–ê°œë°œì„', 'â–ì´‰êµ¬', 'í–ˆìœ¼ë‚˜', 'â–ê³µí™”', 'ë‹¹ì˜', 'â–ë°˜ëŒ€ë¡œ', 'â–ë¬´ì‚°ë˜ì—ˆë‹¤', '.', '[SEP]', 'â–ì¹´', 'í„°ëŠ”', 'â–ì´ì§‘', 'íŠ¸ì™€', 'â–ì´ìŠ¤ë¼ì—˜', 'ì„', 'â–ì¡°ì •', 'í•˜ì—¬', ',', 'â–ìº í”„', 'â–ë°ì´ë¹„', 'ë“œì—ì„œ', 'â–ì•ˆ', 'ì™€', 'ë¥´', '[MASK]', '[MASK]', 'â–ëŒ€í†µë ¹ê³¼', 'â–ë©”', 'ë‚˜', 'í—´', 'â–ë² ', 'ê¸´', 'â–ìˆ˜ìƒ', 'ê³¼', 'â–í•¨ê»˜', 'â–ì¤‘ë™', '[MASK]', 'â–ìœ„í•œ', 'â–ìº í”„', 'ë°ì´', 'ë¹„', 'ë“œ', 'â–í˜‘ì •ì„', 'â–ì²´ê²°í–ˆë‹¤', '.', 'â–ê·¸ëŸ¬ë‚˜', 'â–ì´ê²ƒì€', 'â–ê³µí™”', 'ë‹¹ê³¼', 'â–ë¯¸êµ­ì˜', 'â–ìœ ëŒ€ì¸', '[MASK]', 'â–ë°˜ë°œì„', 'â–ì¼ìœ¼ì¼°ë‹¤', '.', 'â–1979', 'ë…„', 'â–ë°±ì•…', 'ê´€ì—ì„œ', 'â–ì–‘êµ­', 'â–ê°„ì˜', 'â–í‰í™”', 'ì¡°ì•½', 'ìœ¼ë¡œ', '[MASK]', '[MASK]', '[MASK]', 'â–ë˜í•œ', 'â–ì†Œë ¨ê³¼', 'â–ì œ', '2', 'ì°¨', 'â–ì „ëµ', 'â–ë¬´ê¸°', '[MASK]', 'â–í˜‘', 'ìƒì—', 'â–ì¡°ì¸', 'í–ˆë‹¤', '.', 'â–ì¹´', 'í„°ëŠ”', '[MASK]', '[MASK]', '[MASK]', 'â–ë‹¹ì‹œ', '[MASK]', 'â–ë“±', 'â–ì¸ê¶Œ', 'â–í›„ì§„', 'êµ­ì˜', 'â–êµ­ë¯¼ë“¤ì˜', 'â–ì¸', 'ê¶Œì„', 'â–ì§€í‚¤ê¸°', 'â–ìœ„í•´', 'â–ë…¸ë ¥', 'í–ˆìœ¼ë©°', ',', '[MASK]', 'â–ì´í›„', 'â–ê³„ì†í•´ì„œ', 'â–ë„ë•', 'ì •', 'ì¹˜ë¥¼', 'â–ë‚´ì„¸', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [13, 14, 45, 46, 51, 52, 57, 72, 73, 85, 86, 87, 95, 103, 104, 105, 107, 120], 'mask_label': ['â–í¬', 'ë“œë¥¼', 'â–ì‚¬ë‹¤', 'íŠ¸', 'â–ë² ', 'ê¸´', 'â–í‰í™”ë¥¼', 'â–ë‹¨ì²´ì˜', 'â–ë°˜ë°œì„', 'â–ì´ëŒ', 'ì–´ì¡Œë‹¤', '.', 'â–ì œí•œ', 'â–1970', 'ë…„ëŒ€', 'â–í›„ë°˜', 'â–ëŒ€í•œë¯¼êµ­', 'â–ì·¨ì„']}\n",
      "enc_token: [5, 3306, 27625, 663, 8198, 4867, 4896, 19160, 6244, 238, 22033, 19990, 27604, 6, 6, 10071, 7965, 27599, 25250, 5906, 3634, 8085, 9747, 1003, 4460, 1547, 4771, 18474, 27599, 4, 207, 4612, 2703, 3604, 3426, 27607, 3358, 54, 27604, 10251, 3640, 3552, 172, 27665, 27699, 6, 6, 13799, 334, 27637, 29887, 271, 28099, 1011, 27644, 280, 8021, 6, 521, 10251, 4282, 27694, 27681, 15990, 19102, 27599, 330, 1487, 4460, 4040, 679, 7455, 6, 21408, 6564, 27599, 2995, 27625, 10312, 6749, 13195, 2714, 2793, 8993, 9, 6, 6, 6, 276, 23197, 30, 27619, 27751, 2835, 3841, 6, 617, 1824, 15876, 31, 27599, 207, 4612, 6, 6, 6, 316, 6, 50, 5636, 17092, 137, 18896, 42, 917, 15177, 231, 3375, 530, 27604, 6, 165, 6357, 6244, 27642, 1233, 5890, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mlm: [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0   119  1486     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0  7025 27677     0\n",
      "     0     0     0   271 28099     0     0     0     0 14237     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      " 15747 21408     0     0     0     0     0     0     0     0     0     0\n",
      "     0  1435  2521 27599     0     0     0     0     0     0     0  1956\n",
      "     0     0     0     0     0     0     0  1921   596  1840     0   410\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "  2659     0     0     0     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', ',', 'â–1982', 'ë…„ê¹Œì§€', 'â–3', 'ë‹¨', 'ê³„ì—', 'â–ê±¸ì³', 'â–ì£¼í•œë¯¸', 'êµ°ì„', 'â–ì² ìˆ˜', 'í•˜ê¸°ë¡œ', 'â–í–ˆë‹¤', '.', 'â–ê·¸ëŸ¬ë‚˜', 'â–ì£¼í•œë¯¸', 'êµ°', 'ì‚¬ë ¹', 'ë¶€ì™€', 'â–ì •ë³´', 'ê¸°ê´€', 'Â·', 'ì˜', 'íšŒì˜', '[MASK]', '[MASK]', 'â–ë¶€ë”ª', 'í˜€', 'â–ì£¼í•œë¯¸', 'êµ°ì€', 'â–ì™„ì „', 'ì² ', 'ìˆ˜', 'â–ëŒ€ì‹ ', 'â–6,000', 'ëª…ì„', 'â–ê°ì¶•', 'í•˜ëŠ”', 'â–ë°', 'â–ê·¸ì³¤ë‹¤', '.', 'â–ë˜í•œ', 'â–ë°•ì •í¬', 'â–ì •ê¶Œì˜', 'â–ì¸ê¶Œ', 'â–ë¬¸ì œ', 'â–ë“±', 'ê³¼ì˜', 'â–ë…¼ë€', 'ìœ¼ë¡œ', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'â–ëƒˆ', 'ìœ¼ë‚˜', ',', 'â–1979', 'ë…„', 'â–6', 'ì›”', 'â–í•˜', 'ìˆœ', ',', 'â–ëŒ€í•œë¯¼êµ­ì„', 'â–ë°©ë¬¸í•˜ì—¬', 'â–ê´€ê³„ê°€', 'â–ë‹¤ì†Œ', 'â–íšŒë³µ', 'ë˜ì—ˆë‹¤', '.', '[SEP]', 'â–ê·¸ëŸ¬ë‚˜', '[MASK]', 'â–ì´ë€', 'â–ë¯¸êµ­', 'â–ëŒ€ì‚¬ê´€', '[MASK]', '[MASK]', 'â–ì‚¬ê±´ì—ì„œ', 'â–ì¸', 'ì§ˆ', '[MASK]', 'â–ì‹¤íŒ¨ë¥¼', 'â–ì´ìœ ë¡œ', '[MASK]', '[MASK]', 'â–ëŒ€í†µë ¹', 'â–ì„ ê±°ì—ì„œ', 'â–ê³µí™”', 'ë‹¹ì˜', 'â–ë¡œ', 'ë„ë“œ', 'â–ë ˆì´', 'ê±´', 'â–í›„ë³´', 'ì—ê²Œ', 'â–', 'ì ¸', 'â–ê²°êµ­', 'â–ì¬', 'ì„ ì—', 'â–ì‹¤íŒ¨í–ˆë‹¤', '.', 'â–ë˜í•œ', 'â–ì„ê¸°', '[MASK]', 'â–í„°', 'ì§„', 'â–ì†Œë ¨ì˜', 'â–ì•„í”„ê°€ë‹ˆìŠ¤íƒ„', 'â–ì¹¨ê³µ', 'â–ì‚¬ê±´ìœ¼ë¡œ', 'â–ì¸í•´', 'â–1980', 'ë…„', '[MASK]', 'â–ì˜¬ë¦¼í”½ì—', 'â–ë°˜ê³µ', 'êµ­ê°€', 'ë“¤ì˜', '[MASK]', '[MASK]', '[MASK]', 'â–ë‚´ì„¸', 'ì› ë‹¤', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [24, 25, 50, 51, 52, 53, 73, 74, 77, 78, 82, 85, 86, 106, 116, 121, 122, 123], 'mask_label': ['â–ë°˜', 'ëŒ€ì—', 'â–ë¶ˆ', 'í˜‘', 'í™”', 'ìŒì„', 'â–ì£¼', 'â–ì´ë€', 'â–ì¸', 'ì§ˆ', 'â–êµ¬ì¶œ', 'â–1980', 'ë…„', 'â–ë§ê¸°ì—', 'â–í•˜ê³„', 'â–ë³´ì´', 'ì½§', 'ì„']}\n",
      "enc_token: [5, 27604, 2760, 673, 49, 27737, 1949, 1633, 24438, 1262, 5337, 2390, 345, 27599, 330, 24438, 27722, 3069, 2576, 1071, 1468, 27873, 27601, 511, 6, 6, 11574, 28178, 24438, 941, 4626, 27917, 27636, 1083, 23453, 859, 26346, 38, 189, 11330, 27599, 276, 5298, 13574, 5636, 550, 50, 786, 2408, 9, 6, 6, 6, 6, 15139, 191, 27604, 2995, 27625, 125, 27662, 27, 27946, 27604, 16187, 14905, 4857, 5421, 3332, 43, 27599, 4, 330, 6, 3290, 243, 18590, 6, 6, 23937, 42, 27892, 6, 22684, 1827, 6, 6, 663, 5249, 4460, 1547, 194, 8631, 1169, 27803, 958, 113, 27596, 27944, 875, 174, 2087, 9510, 27599, 276, 11034, 6, 870, 27713, 5569, 7676, 3232, 6322, 751, 1640, 27625, 6, 5825, 13948, 4398, 247, 6, 6, 6, 5890, 1853, 27599, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 0\n",
      "label_mlm: [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "   141   867     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0   128 27993 27683   969     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0    37  3290     0     0    42 27892     0     0     0 11560     0\n",
      "     0  1640 27625     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0 12145     0\n",
      "     0     0     0     0     0     0     0     0  2219     0     0     0\n",
      "     0  3052 28805 27607     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', ',', 'â–ë°•ì •í¬', 'â–ëŒ€í†µë ¹ì´', 'â–ê¸°ë¬˜', 'éŸ¶', 'â–ì¤‘ì•™ì •ë³´', 'ë¶€', 'ì¥ì—', 'â–ì˜í•´', 'â–ì‚´í•´', 'ëœ', 'â–ê²ƒì—', 'â–ëŒ€í•´', 'â–ê·¸ëŠ”', 'â–ì´', 'â–ì‚¬ê±´ìœ¼ë¡œ', 'â–í°', 'â–ì¶©ê²©ì„', 'â–ë°›ì•˜ìœ¼ë©°', ',', '[MASK]', '[MASK]', 'â–ë°´', 'ìŠ¤', 'â–êµ­ë¬´', 'ì¥', 'ê´€ì„', 'â–ì¡°', 'ë¬¸ì‚¬', 'ì ˆë¡œ', 'â–íŒŒê²¬í–ˆë‹¤', '.', 'â–12', 'Â·', '12', '[MASK]', 'â–ë°˜ë€', 'ê³¼', 'â–5.', '17', 'â–ì¿ ë°íƒ€', 'ì—', '[MASK]', 'â–ì´ˆê¸°ì—ëŠ”', 'â–ê°•í•˜ê²Œ', 'â–ë¹„ë‚œ', 'í–ˆìœ¼ë‚˜', ',', 'â–ë¯¸êµ­', '[MASK]', 'â–ì‹ êµ°', 'ë¶€ë¥¼', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'â–ìˆì—ˆê³ ', 'â–ê²°êµ­', 'â–ë¬µ', 'ì¸', 'í•˜ëŠ”', '[MASK]', 'â–íƒœë„ë¥¼', 'â–ë³´ì´ê²Œ', 'â–ëë‹¤', '.', '[SEP]', 'â–í‡´ì„', 'â–ì´í›„', 'â–ë¯¼ê°„', 'â–ìì›ì„', 'â–ì ê·¹', 'â–í™œìš©í•œ', 'â–ë¹„ì˜ë¦¬', 'â–ê¸°êµ¬', 'ì¸', 'â–ì¹´í„°', 'â–ì¬', 'ë‹¨ì„', 'â–ì„¤ë¦½í•œ', '[MASK]', '[MASK]', 'â–ì‹¤í˜„', 'ì„', 'â–ìœ„í•´', 'â–ì œ', 'â–3', 'ì„¸ê³„ì˜', '[MASK]', '[MASK]', 'â–í™œë™', 'â–ë°', 'â–ê¸°ë‹ˆ', 'â–ë²Œ', 'ë ˆ', 'ì—', 'â–ì˜í•œ', 'â–ë“œë¼', 'ì¿¤', 'ì¿ ë¥´', 'ìŠ¤', 'â–ì§ˆë³‘', 'â–ë°©', 'ì¬ë¥¼', 'â–ì¥ì•ˆ', 'â–í˜ì¼ë‹¤', '.', 'â–ë¯¸êµ­ì˜', 'â–ë¹ˆê³¤', 'ì¸µ', 'â–ì§€ì›', 'â–í™œë™', ',', 'â–ì‚¬ë‘ì˜', 'â–ì§‘', 'ì§“', 'ê¸°', 'â–ìš´ë™', ',', 'â–êµ­ì œ', 'â–ë¶„ìŸ', 'â–ì¤‘ì¬', 'â–ë“±ì˜', 'â–í™œë™ë„', 'â–í–ˆë‹¤', '.', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [4, 5, 21, 22, 36, 43, 50, 53, 54, 55, 56, 62, 77, 81, 82, 89, 90, 105], 'mask_label': ['â–ê¹€ì¬', 'ê·œ', 'â–ì‚¬ì´', 'ëŸ¬ìŠ¤', 'â–êµ°ì‚¬', 'â–ëŒ€í•´', 'â–ì •ë¶€ê°€', 'â–ì„¤ë“', 'í•˜ëŠ”ë°', ',', 'â–í•œê³„ê°€', 'â–ë“¯í•œ', 'â–ì¹´í„°', 'â–ë’¤', 'â–ë¯¼ì£¼ì£¼ì˜', 'â–ì„ ê±°', 'â–ê°ì‹œ', 'â–ìœ„í•´']}\n",
      "enc_token: [5, 27604, 5298, 4864, 27387, 31931, 18525, 27638, 1312, 355, 2591, 27711, 2057, 433, 202, 8, 6322, 459, 10688, 5325, 27604, 6, 6, 1228, 27626, 4444, 27651, 1657, 53, 27181, 17544, 26520, 27599, 196, 27873, 1335, 6, 2342, 27644, 11262, 1695, 14078, 27600, 6, 6797, 7015, 3560, 1003, 27604, 243, 6, 26826, 1191, 6, 6, 6, 6, 2492, 875, 5374, 27628, 38, 6, 11162, 16915, 3842, 27599, 4, 13826, 165, 3174, 17304, 2929, 20639, 16068, 6673, 27628, 25250, 174, 1574, 7301, 6, 6, 5031, 27607, 231, 30, 49, 21655, 6, 6, 375, 228, 18137, 813, 27740, 27600, 1332, 17378, 28956, 16453, 27626, 5225, 95, 4445, 15108, 19607, 27599, 679, 14197, 28083, 770, 375, 27604, 14003, 313, 28333, 27614, 887, 27604, 605, 4476, 13267, 507, 27328, 345, 27599, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mlm: [    0     0     0     0  9918 27958     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0   328  2086     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "  1250     0     0     0     0     0     0   433     0     0     0     0\n",
      "     0     0  3840     0     0  5523  1294 27604 20984     0     0     0\n",
      "     0     0 10180     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0 25250     0     0     0   339  9889     0\n",
      "     0     0     0     0     0   822  7049     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0   231     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', 'â–ì¹´í„°', 'â–í–‰ì •ë¶€', 'â–ì´í›„', 'â–ë¯¸êµ­ì´', 'â–ë¶', 'í•µ', 'â–ìœ„ê¸°', ',', 'â–ì½”ì†Œë³´', 'â–ì „ìŸ', ',', 'â–ì´ë¼í¬', 'â–ì „ìŸê³¼', 'â–ê°™ì´', 'â–ë¯¸êµ­ì´', '[MASK]', '[MASK]', 'â–ìµœí›„', 'ë¡œ', 'â–ì„ íƒí•˜ëŠ”', 'â–ì „í†µì ', 'â–ì‚¬ê³ ë¥¼', 'â–ë²„ë¦¬ê³ ', 'â–ë‚˜ì´ì—', 'â–í–‰ë™ì„', 'â–ì„ í–‰', 'í•˜ëŠ”', 'â–í–‰ìœ„ì—', 'â–ëŒ€í•´', 'â–ê¹Šì€', 'â–ìœ ', 'ê°ì„', 'â–í‘œì‹œ', 'â–í•˜ë©°', 'â–ë¯¸êµ­ì˜', 'â–êµ°ì‚¬ì ', 'â–í™œë™ì—', 'â–ê°•í•œ', 'â–ë°˜ëŒ€', 'â–ì…ì¥ì„', 'â–ë³´ì´ê³ ', 'â–ìˆë‹¤', '.', '[SEP]', 'â–íŠ¹íˆ', 'â–êµ­ì œ', 'â–ë¶„ìŸ', '[MASK]', 'â–ìœ„í•´', 'â–ë¶í•œì˜', 'â–ê¹€ì¼ì„±', ',', 'â–ì•„ì´', 'í‹°ì˜', 'â–ì„¸', 'ë“œ', 'ë¼ìŠ¤', 'â–ì¥êµ°', ',', 'â–íŒ”', 'ë ˆì¸', 'ìŠ¤íƒ€', 'ì¸ì˜', '[MASK]', '[MASK]', '[MASK]', 'â–ë³´ìŠ¤', 'ë‹ˆì•„ì˜', 'â–ì„¸ë¥´ë¹„ì•„', 'ê³„', 'â–ì •ê¶Œ', 'â–ê°™ì´', 'â–ë¯¸êµ­', 'â–ì •ë¶€ì—', 'â–ëŒ€í•´', 'â–í˜‘ìƒì„', 'â–ê±°ë¶€', 'í•˜ë©´ì„œ', 'â–ì‚¬íƒœ', 'ì˜', 'â–ìœ„ê¸°ë¥¼', 'â–ì´ˆë˜', 'í•œ', 'â–ì¸ë¬¼', 'â–ë°', 'â–ë‹¨ì²´ë¥¼', 'â–ì§ì ‘', '[MASK]', 'â–ë¶„ìŸ', 'ì˜', '[MASK]', 'â–ê·¼ë³¸ì ìœ¼ë¡œ', 'â–í•´ê²°í•˜ê¸°', 'â–ìœ„í•´', 'â–í˜ì¼ë‹¤', '.', 'â–ì´', 'â–ê³¼ì •ì—ì„œ', 'â–ë¯¸êµ­', 'â–í–‰ì •', 'ë¶€ì™€', 'â–ê°ˆë“±ì„', '[MASK]', 'â–í–ˆì§€ë§Œ', ',', 'â–ì „ì§', 'â–ëŒ€í†µë ¹ì˜', 'â–ê¶Œí•œ', 'ê³¼', '[MASK]', '[MASK]', '[MASK]', 'â–ì¸ì‚¬', 'ë“¤ì˜', '[MASK]', '[MASK]', '[MASK]', 'â–ë‚˜ê°”ë‹¤', '.', 'â–1978', 'ë…„ì—', 'â–ì±„', 'ê²°', 'ëœ', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 18, 19, 26, 50, 66, 67, 68, 90, 93, 105, 112, 113, 114, 117, 118, 119], 'mask_label': ['â–ì¹´', 'í„°ëŠ”', 'â–êµ°ì‚¬ì ', 'â–í–‰ë™ì„', 'â–êµ°ì‚¬ì ', 'â–ì¡°ì •ì„', 'â–í•˜', 'ë§ˆìŠ¤', ',', 'â–ë§Œë‚˜', 'â–ì›ì¸ì„', 'â–ë³´ì´ê¸°ë„', 'â–ì¬', 'ì•¼', 'â–ìœ ëª…', 'â–í™œì•½ìœ¼ë¡œ', 'â–í•´ê²°', 'í•´']}\n",
      "enc_token: [5, 6, 6, 25250, 21862, 165, 8424, 251, 28166, 10622, 27604, 26202, 506, 27604, 6157, 17305, 733, 8424, 6, 6, 12241, 27603, 26028, 15644, 13098, 8275, 7441, 5616, 16374, 38, 19690, 433, 4508, 46, 2196, 2466, 1368, 679, 9641, 8253, 2632, 1216, 5168, 7010, 28, 27599, 4, 698, 605, 4476, 6, 231, 9305, 11444, 27604, 520, 10694, 74, 27681, 1951, 4379, 27604, 961, 5346, 936, 692, 6, 6, 6, 6076, 4174, 4543, 27704, 5752, 733, 243, 6633, 433, 12149, 2324, 421, 4597, 27601, 11239, 8200, 27612, 1178, 228, 19762, 1069, 6, 4476, 27601, 6, 24806, 13425, 231, 19607, 27599, 8, 2208, 243, 895, 2576, 12627, 6, 3379, 27604, 5605, 5744, 3753, 27644, 6, 6, 6, 3329, 247, 6, 6, 6, 9946, 27599, 3331, 169, 481, 27783, 27711, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mlm: [    0   207  4612     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0  9641  5616     0     0     0     0\n",
      "     0     0  9641     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0 23144     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0    27  3678 27604     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0  2142     0     0 13635     0     0\n",
      "     0     0     0     0     0     0     0     0     0 23828     0     0\n",
      "     0     0     0     0   174 27775   939     0     0 17462  2317 27645\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n",
      "{'tokens': ['[CLS]', 'â–ë¶í•œì—', 'â–ëŒ€í•œ', 'â–ë¯¸êµ­ì˜', 'â–êµ°ì‚¬ì ', 'â–í–‰ë™ì´', 'â–ì„', 'ë°•', 'í–ˆìœ¼ë‚˜', ',', '[MASK]', 'â–ì „ì§', 'â–ëŒ€í†µë ¹', 'ìœ¼ë¡œëŠ”', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'â–ë¯¸êµ­ê³¼', 'â–ë¶', '[MASK]', 'â–ì¤‘ì¬', 'ì—', 'â–í°', 'â–ê¸°ì—¬ë¥¼', 'â–í•´', 'â–ìœ„ê¸°ë¥¼', 'â–í•´ê²°', 'í–ˆë‹¤ëŠ”', '[MASK]', 'â–ë°›ì•˜ë‹¤', '.', 'â–ë˜í•œ', 'â–ì´', 'â–ë•Œ', '[MASK]', 'â–ëŒ€í†µë ¹ê³¼', 'ë§', 'â–ì£¼', 'ì„ì˜', 'â–ë§Œë‚¨', 'ì„', 'â–ì£¼ì„ ', 'í–ˆë‹¤', '.', 'â–í•˜ì§€ë§Œ', 'â–ê·¸ë¡œë¶€í„°', 'â–ìˆ˜', 'ì£¼ì¼', 'â–í›„', 'â–ê¹€ì¼', 'ì„±ì´', 'â–ê°‘ìê¸°', 'â–ì‚¬ë§í•˜ì—¬', 'â–ê¹€ì¼', 'ì„±ê³¼', 'â–ê¹€ì˜ì‚¼', 'ì˜', 'â–ì •ìƒíšŒë‹´', 'ì€', 'â–ì´ë£¨ì–´ì§€ì§€', 'â–ëª»í–ˆë‹¤', '.', '[SEP]', 'â–ë¯¸êµ­ì˜', 'â–ê´€', 'íƒ€ë‚˜', 'ëª¨', 'â–ìˆ˜ìš©', 'ì†Œ', 'â–ë¬¸ì œ', ',', 'â–ì„¸ê³„ì˜', 'â–ì¸ê¶Œ', 'ë¬¸ì œ', 'ì—ì„œë„', 'â–ê´€ì‹¬ì´', 'â–ê¹Š', 'ì–´', 'â–ìœ ì—”', 'ì—', 'â–ìœ ì—”', 'ì¸ê¶Œ', 'ê³ ë“±', 'íŒ', 'ë¬´', 'ê´€ì˜', 'â–ì œë„ë¥¼', 'â–ì‹œí–‰', 'í•˜ë„ë¡', 'â–ë…¸ë ¥', 'í•˜ì—¬', 'â–ë…ì¬', 'ìë“¤ì˜', 'â–ì¸ê¶Œ', 'â–ìœ ', 'ë¦°', 'ì—', 'â–ëŒ€í•´', 'â–ì œ', 'ì•½ì„', 'â–í•˜ê³ ', ',', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'â–ë§Œë“œëŠ”', 'â–ë°', 'â–ê¸°ì—¬', 'í•˜ì—¬', 'â–ë…ì¬', 'ìë“¤', 'â–ê°™ì€', 'â–ì¸ê¶Œ', 'ìœ ', 'ë¦°', 'ë²”ì£„', 'ìë¥¼', 'â–ì¬íŒ', 'ì†Œë¡œ', 'â–íšŒ', 'ë¶€', 'í•˜ì—¬', 'â–êµ­ì œì ì¸', 'â–ì²˜ë²Œì„', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [10, 14, 15, 16, 17, 18, 21, 30, 31, 32, 35, 36, 38, 65, 104, 105, 106, 107], 'mask_label': ['â–ë¯¸êµ­', 'â–ì²˜ìŒìœ¼ë¡œ', 'â–ë¶í•œ', 'ì„', 'â–ë°©ë¬¸', 'í•˜ê³ ', 'â–ì–‘êµ­ì˜', 'â–í‰ê°€ë¥¼', 'â–ë°›ì•˜ë‹¤', '.', 'â–ë•Œ', 'â–ê¹€ì˜ì‚¼', 'â–ê¹€ì¼ì„±', 'â–ë¯¸êµ­ì˜', 'â–êµ­ì œ', 'í˜•ì‚¬', 'ì¬íŒ', 'ì†Œë¥¼']}\n",
      "enc_token: [5, 25086, 92, 679, 9641, 18507, 273, 27914, 1003, 27604, 6, 5605, 663, 1030, 6, 6, 6, 6, 6, 5672, 251, 6, 13267, 27600, 459, 13856, 87, 11239, 2317, 2351, 6, 772, 27599, 276, 8, 84, 6, 13799, 29164, 37, 5361, 11842, 27607, 25754, 31, 27599, 589, 14313, 19, 10106, 81, 4636, 684, 5908, 26809, 4636, 1693, 9133, 27601, 27509, 27613, 13475, 2041, 27599, 4, 679, 88, 8011, 27716, 2237, 27688, 550, 27604, 5467, 5636, 5515, 643, 8181, 1910, 27633, 3708, 27600, 3708, 12972, 5059, 27841, 27725, 2429, 6520, 2404, 1816, 3375, 54, 7559, 2653, 5636, 46, 27870, 27600, 433, 30, 3297, 644, 27604, 6, 6, 6, 6, 3002, 189, 2187, 54, 7559, 3989, 226, 5636, 27690, 27870, 8822, 690, 2474, 2661, 270, 27638, 54, 12835, 19956, 4]\n",
      "segment: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "label_nsp: 1\n",
      "label_mlm: [    0     0     0     0     0     0     0     0     0     0   243     0\n",
      "     0     0  1307  1876 27607  2017    48     0     0 25764     0     0\n",
      "     0     0     0     0     0     0  4549   772 27599     0     0    84\n",
      "  9133     0 11444     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0   679     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0   605 17905  4731  1358\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145/767648317.py:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
      "/tmp/ipykernel_145/767648317.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
      "/tmp/ipykernel_145/767648317.py:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "# ë¼ì¸ ë‹¨ìœ„ë¡œ ì²˜ë¦¬\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for i, line in enumerate(tqdm(f, total=total)):\n",
    "        if 5 < i:  # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œ 5ê°œë§Œ í™•ì¸\n",
    "            break\n",
    "        data = json.loads(line)\n",
    "        # encoder token\n",
    "        enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "        enc_token += [0] * (n_seq - len(enc_token))\n",
    "        # segment\n",
    "        segment = data[\"segment\"]\n",
    "        segment += [0] * (n_seq - len(segment))\n",
    "        # nsp label\n",
    "        label_nsp = data[\"is_next\"]\n",
    "        # mlm label\n",
    "        mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "        mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "        label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "        label_mlm[mask_idx] = mask_label\n",
    "\n",
    "        print(data)\n",
    "        print(\"enc_token:\", enc_token)\n",
    "        print(\"segment:\", segment)\n",
    "        print(\"label_nsp:\", label_nsp)\n",
    "        print(\"label_mlm:\", label_mlm)\n",
    "        print()\n",
    "\n",
    "        assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "        enc_tokens[i] = enc_token\n",
    "        segments[i] = segment\n",
    "        labels_nsp[i] = label_nsp\n",
    "        labels_mlm[i] = label_mlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c430de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    í•™ìŠµì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ë¡œë“œ\n",
    "    :param vocab: vocab\n",
    "    :param filename: ì „ì²˜ë¦¬ëœ json íŒŒì¼\n",
    "    :param n_seq: ì‹œí€€ìŠ¤ ê¸¸ì´ (number of sequence)\n",
    "    :param count: ë°ì´í„° ìˆ˜ ì œí•œ (Noneì´ë©´ ì „ì²´)\n",
    "    :return enc_tokens: encoder inputs\n",
    "    :return segments: segment inputs\n",
    "    :return labels_nsp: nsp labels\n",
    "    :return labels_mlm: mlm labels\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            # ë°ì´í„° ìˆ˜ ì œí•œ\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "    \n",
    "    # np.memmapì„ ì‚¬ìš©í•˜ë©´ ë©”ëª¨ë¦¬ë¥¼ ì ì€ ë©”ëª¨ë¦¬ì—ì„œë„ ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ê°€ ê°€ëŠ¥ í•¨\n",
    "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            # encoder token\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "            # segment\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "            # nsp label\n",
    "            label_nsp = data[\"is_next\"]\n",
    "            # mlm label\n",
    "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i] = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f61e3fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3722cc43dcec48df91c7a078d9971460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/862285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145/2049745891.py:42: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
      "/tmp/ipykernel_145/2049745891.py:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
      "/tmp/ipykernel_145/2049745891.py:44: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ ë¡œë”© #128000ê±´ë§Œ ë©”ëª¨ë¦¬ì— ë¡œë”©\n",
    "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=918189)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dfec618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([    5,  1605, 27599,  5551, 14146, 15991,  8637, 27599,    13,\n",
       "             6, 25987,  2247, 15033, 27873, 14475, 27813, 27873, 28196,\n",
       "         27636, 10185, 16285,  1232, 22935, 27599,  4777, 27625,   243,\n",
       "          2780,    14,  1509, 22095,   414,   165,  1697, 28290, 27873,\n",
       "         27703, 27683,   593,    21, 29007,   399,  5540,   813,    17,\n",
       "         27599,   307, 16905,     6,     6,     6, 19041, 27718,    98,\n",
       "         27878, 15784,  2543,     6,     6,     6,     6,     6,  4578,\n",
       "         27599,     4,  4427,  1239,     6,    37, 11234,  2378,  5249,\n",
       "          9858,  3294,    13, 20590,  2386,  2163, 27596, 27671,   969,\n",
       "          8047,   173,   607,  2387,   317, 27604,  3926, 27625,  5551,\n",
       "            37, 18995,  8198,  9858,  1447,     6,     6,  5551,    37,\n",
       "            18,   451,  4267, 27599,     6,  6436,    25,  5551, 27646,\n",
       "         18205,   928,   157, 27821,    61, 27773,   530, 27604,  3372,\n",
       "           523,     6,     6,  5551,    18,   982, 13264, 27599,  5551,\n",
       "             6,     4], dtype=int32),\n",
       " memmap([    5,    55, 27674, 27689,     4,    55, 27674,  2149,   356,\n",
       "         28039, 21883, 27665,  9155,    10,     6,   610,  1628, 27599,\n",
       "         31820,  3521,   356, 28039, 21883, 27986, 27838,  2006,  6014,\n",
       "           265,  7337, 27867, 23842,   375,  6481, 27599,     6,     6,\n",
       "             6,     6,   757,    38,     6,   601, 10563, 24390, 17878,\n",
       "           356,  5747,  4296, 27665, 23113,  1079,   485,  5692,  4308,\n",
       "         27739,    16, 27599,     4,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 1,\n",
       " 1,\n",
       " memmap([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            81,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,   103, 28313, 28290,     0,     0,     0,\n",
       "             0,     0,     0,   309,   337,  5771, 27616, 27603,     0,\n",
       "             0,     0,  3715, 27625,  5551,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,  1921, 27625,     0,     0,\n",
       "             0,     0,     0,     0,  4864,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,  3409,   673,     0,     0,     0,     0,     0,     0,\n",
       "          5053,     0], dtype=int32),\n",
       " memmap([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0, 24711,     0,     0,     0,\n",
       "          8737, 16246,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,   318,  1595,\n",
       "          1041,   774,     0,     0,  8556,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0], dtype=int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì²˜ìŒê³¼ ë§ˆì§€ë§‰ í™•ì¸\n",
    "pre_train_inputs[0][0], pre_train_inputs[0][-1], pre_train_inputs[1][0], pre_train_inputs[1][-1], pre_train_labels[0][0], pre_train_labels[0][-1], pre_train_labels[1][0], pre_train_labels[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bcb80c",
   "metadata": {},
   "source": [
    "## 5. BERT ëª¨ë¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "369266e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "091f050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation í•¨ìˆ˜\n",
    "    :param x: ì…ë ¥ ê°’\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1 + K.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "431dddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer ìƒì„±\n",
    "    :param stddev: ìƒì„±í•  ëœë¤ ë³€ìˆ˜ì˜ í‘œì¤€í¸ì°¨\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer ìƒì„±\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d8e5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    jsonì„ config í˜•íƒœë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        fileì—ì„œ Configë¥¼ ìƒì„± í•¨\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b47a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shaed Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        ìƒì„±ì\n",
    "        :param config: Config ê°ì²´\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight ìƒì„±\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer ì‹¤í–‰\n",
    "        :param inputs: ì…ë ¥\n",
    "        :param mode: ì‹¤í–‰ ëª¨ë“œ\n",
    "        :return: embedding or linear ì‹¤í–‰ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        # modeê°€ embeddingì¼ ê²½ìš° embedding lookup ì‹¤í–‰\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # modeê°€ linearì¼ ê²½ìš° linear ì‹¤í–‰\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # modeê°€ ê¸°íƒ€ì¼ ê²½ìš° ì˜¤ë¥˜ ë°œìƒ\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: ì…ë ¥\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear ì‹¤í–‰\n",
    "        :param inputs: ì…ë ¥\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3e9a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Positional Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        ìƒì„±ì\n",
    "        :param config: Config ê°ì²´\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer ì‹¤í–‰\n",
    "        :param inputs: ì…ë ¥\n",
    "        :return embed: positional embedding lookup ê²°ê³¼\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e219fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        ìƒì„±ì\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer ì‹¤í–‰\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: ì‹¤í–‰ ëª¨ë“œ\n",
    "        :return attn_out: attention ì‹¤í–‰ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b2ca37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        ìƒì„±ì\n",
    "        :param config: Config ê°ì²´\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer ì‹¤í–‰\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: ì‹¤í–‰ ëª¨ë“œ\n",
    "        :return attn_out: attention ì‹¤í–‰ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
    "        # transpose and liner\n",
    "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "        \n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48aa5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        ìƒì„±ì\n",
    "        :param config: Config ê°ì²´\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer ì‹¤í–‰\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward ì‹¤í–‰ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "006d0b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        ìƒì„±ì\n",
    "        :param config: Config ê°ì²´\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer ì‹¤í–‰\n",
    "        :param enc_embed: enc_embed ë˜ëŠ” ì´ì „ EncoderLayerì˜ ì¶œë ¥\n",
    "        :param self_mask: enc_tokensì˜ pad mask\n",
    "        :return enc_out: EncoderLayer ì‹¤í–‰ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "490ac79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        ìƒì„±ì\n",
    "        :param config: Config ê°ì²´\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionalEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer ì‹¤í–‰\n",
    "        :param inputs: (enc_tokens, segments)\n",
    "        :return logits: dec_tokensì— ëŒ€í•œ ë‹¤ìŒ í† í° ì˜ˆì¸¡ ê²°ê³¼ logits\n",
    "        \"\"\"\n",
    "        enc_tokens, segments = inputs\n",
    "\n",
    "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: ì…ë ¥ tokens\n",
    "        :param segments: ì…ë ¥ segments\n",
    "        :return embed: embedding ê²°ê³¼\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8168ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer class ì •ì˜\n",
    "class PooledOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    " \n",
    "    def call(self, inputs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4db2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pre_train(config):\n",
    "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
    "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
    "\n",
    "    bert = BERT(config)\n",
    "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
    "\n",
    "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
    "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
    "\n",
    "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d82f61ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 256,\n",
       " 'n_vocab': 32007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfcf0046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2/2 [==============================] - 4s 16ms/step - loss: 11.2227 - nsp_loss: 0.7743 - mlm_loss: 10.4484 - nsp_acc: 0.5000 - mlm_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 10.0172 - nsp_loss: 0.6251 - mlm_loss: 9.3921 - nsp_acc: 0.8000 - mlm_acc: 0.0200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f95c3001910>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seq = 10\n",
    "\n",
    "# make test inputs\n",
    "enc_tokens = np.random.randint(0, len(vocab), (10, n_seq))\n",
    "segments = np.random.randint(0, 2, (10, n_seq))\n",
    "labels_nsp = np.random.randint(0, 2, (10,))\n",
    "labels_mlm = np.random.randint(0, len(vocab), (10, n_seq))\n",
    "\n",
    "test_model = build_model_pre_train(config)\n",
    "test_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=[\"acc\"])\n",
    "\n",
    "# test model fit\n",
    "test_model.fit((enc_tokens, segments), (labels_nsp, labels_mlm), epochs=2, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c94087",
   "metadata": {},
   "source": [
    "## 6. pretrain ì§„í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6183dc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    loss ê³„ì‚° í•¨ìˆ˜\n",
    "    :param y_true: ì •ë‹µ (bs, n_seq)\n",
    "    :param y_pred: ì˜ˆì¸¡ ê°’ (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # loss ê³„ì‚°\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    # pad(0) ì¸ ë¶€ë¶„ mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return loss * 20  # mlmì„ ë” ì˜ í•™ìŠµí•˜ë„ë¡ 20ë°° ì¦ê°€ ì‹œí‚´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f13f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    acc ê³„ì‚° í•¨ìˆ˜\n",
    "    :param y_true: ì •ë‹µ (bs, n_seq)\n",
    "    :param y_pred: ì˜ˆì¸¡ ê°’ (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # ì •ë‹µ ì—¬ë¶€ í™•ì¸\n",
    "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
    "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
    "    # pad(0) ì¸ ë¶€ë¶„ mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
    "    matches *= mask\n",
    "    # ì •í™•ë„ ê³„ì‚°\n",
    "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95aca402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    CosineSchedule Class\n",
    "    \"\"\"\n",
    "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        ìƒì„±ì\n",
    "        :param train_steps: í•™ìŠµ step ì´ í•©\n",
    "        :param warmup_steps: warmup steps\n",
    "        :param max_lr: ìµœëŒ€ learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0 < warmup_steps < train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.train_steps = train_steps\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        \"\"\"\n",
    "        learning rate ê³„ì‚°\n",
    "        :param step_num: í˜„ì¬ step number\n",
    "        :retrun: ê³„ì‚°ëœ learning rate\n",
    "        \"\"\"\n",
    "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
    "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
    "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
    "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
    "        return (state * lr1 + (1 - state) * lr2) * self.max_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ecff50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute lr \n",
    "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
    "lrs = []\n",
    "for step_num in range(4000):\n",
    "    lrs.append(test_schedule(float(step_num)).numpy())\n",
    "\n",
    "# draw\n",
    "plt.plot(lrs, 'r-', label='learning_rate')\n",
    "plt.xlabel('Step')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4cb01d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_tokens (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segments (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BERT)                     ((None, 256), (None, 10629632    enc_tokens[0][0]                 \n",
      "                                                                 segments[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlm (Softmax)                   (None, None, 32007)  0           bert[0][1]                       \n",
      "==================================================================================================\n",
      "Total params: 10,695,936\n",
      "Trainable params: 10,695,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ìƒì„±\n",
    "pre_train_model = build_model_pre_train(config)\n",
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d06f40fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 67370\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# compile\n",
    "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6c97a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13474/13474 [==============================] - 3852s 286ms/step - loss: 16.0219 - nsp_loss: 0.5226 - mlm_loss: 15.4994 - nsp_acc: 0.7538 - mlm_lm_acc: 0.1438\n",
      "\n",
      "Epoch 00001: mlm_lm_acc improved from -inf to 0.14377, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 2/5\n",
      "13474/13474 [==============================] - 3868s 287ms/step - loss: 11.7545 - nsp_loss: 0.4930 - mlm_loss: 11.2615 - nsp_acc: 0.7806 - mlm_lm_acc: 0.2615\n",
      "\n",
      "Epoch 00002: mlm_lm_acc improved from 0.14377 to 0.26147, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 3/5\n",
      "13474/13474 [==============================] - 3868s 287ms/step - loss: 10.7860 - nsp_loss: 0.4865 - mlm_loss: 10.2995 - nsp_acc: 0.7891 - mlm_lm_acc: 0.2950\n",
      "\n",
      "Epoch 00003: mlm_lm_acc improved from 0.26147 to 0.29504, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 4/5\n",
      "13474/13474 [==============================] - 3868s 287ms/step - loss: 10.2868 - nsp_loss: 0.4822 - mlm_loss: 9.8046 - nsp_acc: 0.7971 - mlm_lm_acc: 0.3125\n",
      "\n",
      "Epoch 00004: mlm_lm_acc improved from 0.29504 to 0.31253, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 5/5\n",
      "  578/13474 [>.............................] - ETA: 1:01:44 - loss: 10.0125 - nsp_loss: 0.4799 - mlm_loss: 9.5326 - nsp_acc: 0.8024 - mlm_lm_acc: 0.3213"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_145/4016136003.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{model_dir}/bert_pre_train.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mlm_lm_acc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_train_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_train_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_train_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save weights callback\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
    "# train\n",
    "history = pre_train_model.fit(pre_train_inputs, pre_train_labels, epochs=epochs, batch_size=batch_size, callbacks=[save_weights])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876b1d76",
   "metadata": {},
   "source": [
    "# íšŒê³ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6399a09",
   "metadata": {},
   "source": [
    "- ì‹œê°„ ë¶€ì¡±ìœ¼ë¡œ ì¸í•˜ì—¬ í›ˆë ¨ì„ ì¤‘ê°„ì— ì¤‘ë‹¨ì‹œì¼°ë‹¤.\n",
    "- ë¯¸ë¦¬ë¯¸ë¦¬ ë…¸ë“œë¥¼ ëë‚´ì§€ ëª»í•œ ì ì„ ë°˜ì„±í•œë‹¤.\n",
    "- epoch ì´ 4ê¹Œì§€ ì§„í–‰í•˜ì˜€ì„ ë•Œ nsp_loss ëŠ” ë¯¸ì„¸í•œ ê°’ì´ì§€ë§Œ ê°ì†Œí•˜ì˜€ê³  nsp_acc ëŠ” ì¦ê°€í•˜ì˜€ë‹¤.\n",
    "- ì´ë¥¼ ë³´ë©´ ì„±ëŠ¥ì´ ì¡°ê¸ˆì”© í–¥ìƒë˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.\n",
    "- nsp ëŠ” next sentence predictionìœ¼ë¡œ ë‹¤ìŒ ë¬¸ì¥ì„ ì–¼ë§ˆë‚˜ ì˜ ì˜ˆì¸¡í•  ê²ƒì¸ì§€ì— ëŒ€í•œ ìˆ˜ì¹˜ë¡œ ì¶”ì¸¡ëœë‹¤.\n",
    "- í›ˆë ¨ì‹œê°„ì´ ê½¤ ì˜¤ë˜ê±¸ë¦¬ëŠ” ê²ƒì´ transformer ë³´ë‹¤ ë” ì§„í™”ëœ ëª¨ë¸ì´ê¸´ í•˜ì§€ë§Œ íš¨ìœ¨ì´ ì¢‹ì„ì§€ ì˜ì‹¬ëœë‹¤.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
