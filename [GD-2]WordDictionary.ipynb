{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d582829d",
   "metadata": {},
   "source": [
    "# [GD-02]WordDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c7499",
   "metadata": {},
   "source": [
    "## 라이브러리 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18beea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.22.2\n",
      "3.4.3\n",
      "0.5.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import konlpy\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(plt.__version__)\n",
    "print(konlpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a632f28e",
   "metadata": {},
   "source": [
    "## SentencePiece 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352e711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3108906",
   "metadata": {},
   "source": [
    "## SentencePiece 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc3dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 스텝 \n",
    "# filtered_corpus를 위한 요약\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "path_to_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko'\n",
    "\n",
    "with open(path_to_file, \"r\") as f: \n",
    "    raw = f.read().splitlines() # 줄 단위로 읽어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c651293c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_654/1943799563.py:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sentence_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "\n",
    "for sen in raw:\n",
    "    length = len(sen)\n",
    "    \n",
    "    # 문장 최소 길이 찾기\n",
    "    if min_len > length: \n",
    "        min_len = length\n",
    "    \n",
    "    # 문장 최대 길이 찾기\n",
    "    if max_len < length: \n",
    "        max_len = length\n",
    "        \n",
    "    \n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "cleaned_corpus = list(set(raw))  # set를 사용해서 중복을 제거합니다.\n",
    "\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cebb8d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp --model_prefix=korean_spm --vocab_size=8000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
      "  input_format: \n",
      "  model_prefix: korean_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 77590 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5079802\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.95% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1319\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.9995\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 77590 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 176795 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 77590\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 241182\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 241182 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=93808 obj=14.8611 num_tokens=530931 num_tokens/piece=5.65976\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=83222 obj=13.5216 num_tokens=533486 num_tokens/piece=6.4104\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=62408 obj=13.5582 num_tokens=554869 num_tokens/piece=8.89099\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=62357 obj=13.5154 num_tokens=555301 num_tokens/piece=8.90519\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=46766 obj=13.6977 num_tokens=583543 num_tokens/piece=12.4779\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=46766 obj=13.6548 num_tokens=583593 num_tokens/piece=12.479\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=35074 obj=13.8914 num_tokens=614352 num_tokens/piece=17.5159\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=35074 obj=13.8406 num_tokens=614386 num_tokens/piece=17.5169\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=26305 obj=14.1327 num_tokens=646390 num_tokens/piece=24.5729\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=26305 obj=14.0776 num_tokens=646424 num_tokens/piece=24.5742\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=19728 obj=14.4108 num_tokens=680165 num_tokens/piece=34.4771\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=19728 obj=14.3488 num_tokens=680202 num_tokens/piece=34.479\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=14796 obj=14.7201 num_tokens=715226 num_tokens/piece=48.3391\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=14796 obj=14.6487 num_tokens=715228 num_tokens/piece=48.3393\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=11097 obj=15.0839 num_tokens=751803 num_tokens/piece=67.7483\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=11097 obj=15.0033 num_tokens=751803 num_tokens/piece=67.7483\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8800 obj=15.3984 num_tokens=781516 num_tokens/piece=88.8086\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8800 obj=15.3245 num_tokens=781525 num_tokens/piece=88.8097\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: korean_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: korean_spm.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 376725 Mar 23 09:22 korean_spm.model\r\n",
      "-rw-r--r-- 1 root root 146094 Mar 23 09:22 korean_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:   # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.\n",
    "# input: 입력 corpus\n",
    "# prefix: 저장할 모델 이름\n",
    "# vocab_size: vocab 개수 (기본 8,000)\n",
    "\n",
    "\n",
    "!ls -l korean_spm*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec79372",
   "metadata": {},
   "source": [
    "SentencePiece 모델 학습이 완료된 후 koreanspm.model 파일과 koreanspm.vocab vocabulary 파일이 생성되었음을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed10be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1255, 11, 304, 7, 3606, 11, 285, 38, 3]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ab2dd",
   "metadata": {},
   "source": [
    "## Tokenizer 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05933be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))   # 숫자로 임베딩\n",
    "\n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]  \n",
    "        \n",
    "        word_index.update({idx:word})   # 생성된 vocab 파일을 읽어와 { : } 형태를 가지는 word_index 사전과 \n",
    "        index_word.update({word:idx})   # { : } 형태를 가지는 index_word 사전을 생성하고 함께 반환\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "754d50c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1957 5607    5    4 7975 2012    3    0    0    0    0    0    0    0]\n",
      " [ 108 1658  101    4    0  470   11    4   14    0 2002    3    3    3]]\n"
     ]
    }
   ],
   "source": [
    "#sp_tokenize(s, corpus) 사용예제\n",
    "\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor, word_index, index_word = sp_tokenize(s, my_corpus)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b37660",
   "metadata": {},
   "source": [
    "## 네이버 영화리뷰 감정 분석 문제에 SentencePiece 적용해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782d6c8",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247e2c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/e9t/nsmc.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b430d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['synopses.json',\n",
       " 'ratings.txt',\n",
       " 'ratings_test.txt',\n",
       " 'README.md',\n",
       " 'raw',\n",
       " 'code',\n",
       " '.git',\n",
       " 'ratings_train.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('nsmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "299e42ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_table(\"nsmc/\"+\"ratings_train.txt\")\n",
    "test_data = pd.read_table(\"nsmc/\"+\"ratings_test.txt\")\n",
    "\n",
    "display(train_data.head())\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae68dfc",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "259a8043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 유니크 : 146182\n",
      "타겟데이터 유니크 :  2\n"
     ]
    }
   ],
   "source": [
    "print(\"학습데이터 유니크 :\",train_data['document'].nunique()) #  약 4,000개의 중복 샘플이 존재\n",
    "print(\"타겟데이터 유니크 : \",train_data['label'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b2986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복데이터 제거\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True) # drop_duplicates 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50c3e5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 146183\n"
     ]
    }
   ],
   "source": [
    "# 학습데이터 개수 다시 확인\n",
    "print('총 샘플의 수 :',len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764e5a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# document에 null 값이 있는지 확인\n",
    "print(train_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bcb0e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25857</th>\n",
       "      <td>2172111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id document  label\n",
       "25857  2172111      NaN      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어느 위치에 누락값이 있는지 확인\n",
    "train_data.loc[train_data.document.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "977cb820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Null값 제거\n",
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ab47464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_654/789371173.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 한글과 공백을 제외하고 모두 제거\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 한글과 공백을 제외하고 모두 제거\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7108013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            0\n",
      "document    789\n",
      "label         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_654/1591183560.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace('^ +', \"\")\n"
     ]
    }
   ],
   "source": [
    "# 바뀐 데이터 내부에 null값이 있는지 다시 확인\n",
    "\n",
    "# white space 데이터를 empty value로 변경\n",
    "train_data['document'] = train_data['document'].str.replace('^ +', \"\") \n",
    "train_data['document'].replace('', np.nan, inplace=True)\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ac205db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145393\n"
     ]
    }
   ],
   "source": [
    "# null 데이터 삭제\n",
    "train_data = train_data.dropna(how = 'any')\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12bc2298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 테스트용 샘플의 개수 : 48852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_654/3707744765.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
      "/tmp/ipykernel_654/3707744765.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n"
     ]
    }
   ],
   "source": [
    "# 테스트데이터에도 동일한 과정 진행\n",
    "test_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
    "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
    "test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n",
    "test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
    "test_data = test_data.dropna(how='any') # Null 값 제거\n",
    "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1543edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 145393 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        145393 non-null  int64 \n",
      " 1   document  145393 non-null  object\n",
      " 2   label     145393 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 4.4+ MB\n",
      "==================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48852 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        48852 non-null  int64 \n",
      " 1   document  48852 non-null  object\n",
      " 2   label     48852 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "train_data.info()\n",
    "print(\"=\"*50)\n",
    "test_data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a694fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7898805</td>\n",
       "      <td>음악이 주가 된 최고의 음악영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                   document  label\n",
       "0  6270596                                        굳 ㅋ      1\n",
       "2  8544678           뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                  지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n",
       "4  6723715  만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠      0\n",
       "5  7898805                          음악이 주가 된 최고의 음악영화      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 :  145393\n",
      "테스트데이터 :  48852\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "display(train_data.head())\n",
    "display(test_data.head())\n",
    "\n",
    "print(\"훈련데이터 : \",len(train_data))\n",
    "print(\"테스트데이터 : \",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23c7e545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 140\n",
      "문장의 평균 길이: 33\n",
      "sentence_length :  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_654/2857138701.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sentence_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 길이 분포 확인하기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in train_data['document']:\n",
    "    length = len(sen)\n",
    "    \n",
    "    # 문장 최소 길이 찾기\n",
    "    if min_len > length: \n",
    "        min_len = length\n",
    "    \n",
    "    # 문장 최대 길이 찾기\n",
    "    if max_len < length: \n",
    "        max_len = length\n",
    "        \n",
    "    # 전체 문장을 합치면 길이가 얼마나 될까요?\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(train_data))\n",
    "\n",
    "# 전체 길이만큼 0벡터 ==> 길이에 따른 문장의 수를 저장하기 위해 먼저 0으로 이루어진 리스트를 만든다!!\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "print(\"sentence_length : \",sentence_length)\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# raw는 위에서 다운로드한 데이터셋!! 전체 길이와 상관없음\n",
    "for sen in train_data['document']:\n",
    "    sentence_length[len(sen)-1] += 1 # 0으로 이루어진 벡터에 문장 count를 더한 뒤 넣는다.\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0) # 너비는 1.0씩 늘어나도록 설정\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d8944",
   "metadata": {},
   "source": [
    "#### -> 40 이하 데이터 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9438969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 40이하로 한정해 데이터를 만듭니다.\n",
    "\n",
    "# 이렇게 하면 document 내용만 list로 전달됨 \n",
    "train_list = [s for s in train_data['document'] if (len(s) <= 40)]\n",
    "test_list = [s for s in test_data['document'] if (len(s) <= 40)]\n",
    "\n",
    "train_list = list(set(train_list))\n",
    "test_list = list(set(test_list))\n",
    "\n",
    "train_df = pd.DataFrame(train_list)\n",
    "test_df = pd.DataFrame(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "080a646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이 40이하인 데이터를 기존 데이터와 병합합니다.\n",
    "\n",
    "new_train_df = pd.merge(train_data, train_df, how='inner', left_on='document', right_on=0)\n",
    "new_test_df = pd.merge(test_data, test_df, how='inner', left_on='document', right_on=0)\n",
    "\n",
    "train_data = new_train_df[['id', 'document', 'label']]\n",
    "test_data = new_test_df[['id', 'document', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "338a52fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5403919</td>\n",
       "      <td>막 걸음마 뗀 세부터 초등학교 학년생인 살용영화ㅋㅋㅋ별반개도 아까움</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                               document  label\n",
       "0   9976970                      아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312             흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                      너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019              교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   5403919  막 걸음마 뗀 세부터 초등학교 학년생인 살용영화ㅋㅋㅋ별반개도 아까움      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7898805</td>\n",
       "      <td>음악이 주가 된 최고의 음악영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6315043</td>\n",
       "      <td>진정한 쓰레기</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                          document  label\n",
       "0  6270596                               굳 ㅋ      1\n",
       "1  8544678  뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n",
       "2  6825595         지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n",
       "3  7898805                 음악이 주가 된 최고의 음악영화      1\n",
       "4  6315043                           진정한 쓰레기      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 :  110924\n",
      "테스트데이터 :  37291\n"
     ]
    }
   ],
   "source": [
    "display(train_data.head())\n",
    "display(test_data.head())\n",
    "\n",
    "print(\"훈련데이터 : \",len(train_data))\n",
    "print(\"테스트데이터 : \",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f9e1f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document와 label을 나눠봅시다.\n",
    "X_train,X_train_word_index, X_train_index_word = sp_tokenize(s, train_data['document'])\n",
    "X_test,X_test_word_index, X_test_index_word = sp_tokenize(s, test_data['document'])\n",
    "# 현재 list 상태 ==> ndarray로 바꿔주기\n",
    "y_train = np.array(list(train_data['label']))\n",
    "y_test = np.array(list(test_data['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95c6fa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 138  106 2662  918 4930    4 4930  839   69  553  517 2630    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   4 7660  465 1773  144   14  440 3232 2763 1800  177  410  394   41\n",
      "  4251    4   11 7571   29 2410  242   69    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [1343  444    0  257  229  585   94  144   10 1978    5  999  640  245\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[   4 7889    4    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   4 7826  165   25 1105  349  107  180 5502  162 4305  645    4 3412\n",
      "    10  106  381 7630 2509    0   89    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 190  419  103   10  533  429 2104  953  175  510 1026   72   14 3204\n",
      "   181    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:3])\n",
    "print(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0408148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n",
      "[1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:3])\n",
    "print(y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55ed8505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 : 110924\n",
      "타겟데이터 : 110924\n"
     ]
    }
   ],
   "source": [
    "print(\"학습데이터 :\",len(X_train))\n",
    "print(\"타겟데이터 :\",len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5095d755",
   "metadata": {},
   "source": [
    "### 훈련데이터와 검증데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdfdca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_input, val_input, train_target, val_target = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c38706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3534   11 2913    6   59  698    6 5136   24  174   65 2981  114  906\n",
      "     5 1565 6182   31 1610  560  680    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [1545  358  916   30 6371   30  818  105   30 2313 7899   30  629  347\n",
      "  7988   38    4   27  147   27  988   39  637   29  211   14 2082 6046\n",
      "    29    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 219 4178  248    4 2428   42    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3135   52    7 3346   65  844   16 1861  214 6656  348 4140  453    4\n",
      "  3475  253 5466   17 2918  136   11    4 7440  144  525    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [2791 3420   17 3795 1076   24  742  342    5 2511 6683 2231  210    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [7229  239  242 3325 5065 2041   10 1800 2675  553  517    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_input[:3])\n",
    "print(val_input[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3181c499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3534   11 2913    6   59  698    6 5136   24  174   65 2981  114  906\n",
      "     5 1565 6182   31 1610  560  680    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [1545  358  916   30 6371   30  818  105   30 2313 7899   30  629  347\n",
      "  7988   38    4   27  147   27  988   39  637   29  211   14 2082 6046\n",
      "    29    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 219 4178  248    4 2428   42    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3135   52    7 3346   65  844   16 1861  214 6656  348 4140  453    4\n",
      "  3475  253 5466   17 2918  136   11    4 7440  144  525    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [2791 3420   17 3795 1076   24  742  342    5 2511 6683 2231  210    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [7229  239  242 3325 5065 2041   10 1800 2675  553  517    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# 패딩 맞추기\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_seq = pad_sequences(train_input, maxlen=40, padding='post')\n",
    "val_seq = pad_sequences(val_input, maxlen=40, padding='post')\n",
    "print(train_seq[:3])\n",
    "print(val_seq[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe56b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순환신경망 모델 선언\n",
    "\n",
    "from tensorflow import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(8000,16))\n",
    "model.add(keras.layers.LSTM(8))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0466b057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 128,881\n",
      "Trainable params: 128,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42d45618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2774/2774 [==============================] - 59s 20ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 2/10\n",
      "2774/2774 [==============================] - 57s 20ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 3/10\n",
      "2774/2774 [==============================] - 57s 20ms/step - loss: 0.6878 - accuracy: 0.5125 - val_loss: 0.6201 - val_accuracy: 0.6496\n",
      "Epoch 4/10\n",
      "2774/2774 [==============================] - 57s 21ms/step - loss: 0.5131 - accuracy: 0.7542 - val_loss: 0.4333 - val_accuracy: 0.7952\n",
      "Epoch 5/10\n",
      "2774/2774 [==============================] - 56s 20ms/step - loss: 0.4064 - accuracy: 0.8159 - val_loss: 0.4239 - val_accuracy: 0.8047\n",
      "Epoch 6/10\n",
      "2774/2774 [==============================] - 57s 20ms/step - loss: 0.3756 - accuracy: 0.8294 - val_loss: 0.4049 - val_accuracy: 0.8153\n",
      "Epoch 7/10\n",
      "2774/2774 [==============================] - 57s 20ms/step - loss: 0.3512 - accuracy: 0.8425 - val_loss: 0.3954 - val_accuracy: 0.8186\n",
      "Epoch 8/10\n",
      "2774/2774 [==============================] - 57s 21ms/step - loss: 0.3325 - accuracy: 0.8527 - val_loss: 0.4180 - val_accuracy: 0.8011\n",
      "Epoch 9/10\n",
      "2774/2774 [==============================] - 57s 20ms/step - loss: 0.3176 - accuracy: 0.8616 - val_loss: 0.4054 - val_accuracy: 0.8163\n",
      "Epoch 10/10\n",
      "2774/2774 [==============================] - 57s 21ms/step - loss: 0.3046 - accuracy: 0.8684 - val_loss: 0.4269 - val_accuracy: 0.8185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6b6bb98b0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_input, \n",
    "          train_target, \n",
    "          epochs=10, \n",
    "          validation_data=(val_input, val_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b40f639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 - 5s - loss: 0.4298 - accuracy: 0.8201\n",
      "[0.4298189580440521, 0.8200638294219971]\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test,  y_test, verbose=2)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edde592",
   "metadata": {},
   "source": [
    "### SentencePiece의 다른 옵션의 경우와 비교하여 분석¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5e2ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모델 하이퍼 파라미터를 바꿔서 성능 비교\n",
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "from tensorflow import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size,100))\n",
    "model.add(keras.layers.LSTM(128)) # LSTM 레이어 증가\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34f9eb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,118,289\n",
      "Trainable params: 1,118,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a99e42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1479/1479 [==============================] - 165s 111ms/step - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6932 - val_acc: 0.4970\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49696, saving model to best_model.h5\n",
      "Epoch 2/20\n",
      "1479/1479 [==============================] - 164s 111ms/step - loss: 0.6932 - acc: 0.4986 - val_loss: 0.6934 - val_acc: 0.4970\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.49696\n",
      "Epoch 3/20\n",
      "1479/1479 [==============================] - 166s 112ms/step - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6932 - val_acc: 0.4970\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.49696\n",
      "Epoch 4/20\n",
      "1479/1479 [==============================] - 165s 111ms/step - loss: 0.6915 - acc: 0.5069 - val_loss: 0.6439 - val_acc: 0.6524\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.49696 to 0.65242, saving model to best_model.h5\n",
      "Epoch 5/20\n",
      "1479/1479 [==============================] - 164s 111ms/step - loss: 0.6829 - acc: 0.5474 - val_loss: 0.6752 - val_acc: 0.5881\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.65242\n",
      "Epoch 6/20\n",
      "1479/1479 [==============================] - 165s 112ms/step - loss: 0.6793 - acc: 0.5679 - val_loss: 0.6905 - val_acc: 0.5243\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.65242\n",
      "Epoch 7/20\n",
      "1479/1479 [==============================] - 164s 111ms/step - loss: 0.6907 - acc: 0.5184 - val_loss: 0.6925 - val_acc: 0.5061\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.65242\n",
      "Epoch 8/20\n",
      "1479/1479 [==============================] - 163s 110ms/step - loss: 0.6914 - acc: 0.5050 - val_loss: 0.6904 - val_acc: 0.5156\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.65242\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Early Stopping과 CheckPoint 사용하여 과적합 방지\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                   mode='min', \n",
    "                   verbose=1, \n",
    "                   patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', \n",
    "                     monitor='val_acc', \n",
    "                     mode='max', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True)\n",
    "\n",
    "# 모델 하이퍼 파라미터 설정\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc'])\n",
    "history = model.fit(train_input, \n",
    "                    train_target, \n",
    "                    epochs=20, \n",
    "                    callbacks=[es, mc], \n",
    "                    batch_size=60, \n",
    "                    validation_data=(val_input, val_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09d2aa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166/1166 [==============================] - 27s 23ms/step - loss: 0.6439 - acc: 0.6516\n",
      "\n",
      " 테스트 정확도: 0.6516\n"
     ]
    }
   ],
   "source": [
    "# 가장 좋았던 모델 불러오기\n",
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46d268b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 예측 함수\n",
    "def sentiment_predict(new_sentence):\n",
    "    s = spm.SentencePieceProcessor()\n",
    "    s.Load('korean_spm.model')\n",
    "    tensor = []\n",
    "    tensor.append(s.EncodeAsIds(new_sentence))\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    score = float(loaded_model.predict(tensor)) # 학습된 모델을 기반으로 인풋으로 들어온 모델을 예측\n",
    "    if(score > 0.5):\n",
    "        print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
    "    else:\n",
    "        print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a12cf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.07% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict(\"재미있음\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b78812a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.41% 확률로 부정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict(\"재미없음\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf42ca9",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eab4e1",
   "metadata": {},
   "source": [
    "LSTM학습모델 : loss 0.43 accuracy 0.82  \n",
    "LSTM학습모델 하이퍼파라미터 변경 : loss 0.64 accuracy 0.65  \n",
    "하이퍼파라미터 변경은 큰 영향을 주지않았다.  \n",
    "\n",
    "예측확률이 생각보다 좋지않다.  \n",
    "짧은 리뷰들도 전처리로 정리 한 후 학습하면 더 좋아질 것으로 예상한다.  \n",
    "mecab 토크나이저를 사용하면 또 다른 결과가 나올 것이다.  \n",
    "\n",
    "[참고블로그](https://piaojian.tistory.com/35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
